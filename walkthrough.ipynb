{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "path = \"/Volumes/WD Green/dev/git/pdf_ocr/pdf-ocr/inputs/2857439.pdf\"\n",
    "\n",
    "md_text = pymupdf4llm.to_markdown(path)\n",
    "print(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def reconstruct_markdown(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_md = []\n",
    "\n",
    "    for page in doc:\n",
    "        # Récupère les blocs de texte triés (haut-gauche vers bas-droite)\n",
    "        # 'sort=True' gère souvent déjà l'ordre de lecture naturel\n",
    "        blocks = page.get_text(\"blocks\", sort=True)\n",
    "        \n",
    "        for b in blocks:\n",
    "            x0, y0, x1, y1, text, block_no, block_type = b\n",
    "            \n",
    "            if block_type == 0:  # C'est un bloc de texte\n",
    "                clean_text = text.strip()\n",
    "                if not clean_text: continue\n",
    "                \n",
    "                # Exemple de logique de style simple :\n",
    "                # Si le bloc est très à gauche, c'est peut-être un titre ou une puce\n",
    "                if x0 < 100 and len(clean_text) < 50:\n",
    "                    full_md.append(f\"### {clean_text}\\n\")\n",
    "                else:\n",
    "                    full_md.append(f\"{clean_text}\\n\")\n",
    "        \n",
    "        full_md.append(\"\\n---\\n\") # Séparateur de page\n",
    "    \n",
    "    return \"\\n\".join(full_md)\n",
    "\n",
    "md_output = reconstruct_markdown(path)\n",
    "print(md_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moi32xu0ihr",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_ocr import pdf_to_spatial_text\n",
    "\n",
    "output = pdf_to_spatial_text(\"inputs/2857439.pdf\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4i3qj1yp7qc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for fname in sorted(os.listdir(\"inputs\")):\n",
    "    if not fname.endswith(\".pdf\"):\n",
    "        continue\n",
    "    path = os.path.join(\"inputs\", fname)\n",
    "    text = pdf_to_spatial_text(path)\n",
    "    lines = text.split(\"\\n\")\n",
    "    max_width = max((len(l) for l in lines), default=0)\n",
    "    print(f\"{fname:50s}  lines={len(lines):4d}  max_width={max_width:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ja98ihg0ty",
   "metadata": {},
   "source": [
    "## Compressed Spatial Text\n",
    "\n",
    "`compress_spatial_text()` produces a token-efficient representation by classifying page regions (tables, headings, text blocks, key-value pairs) and rendering them as markdown tables and flowing text instead of whitespace-heavy grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "idb5df8kpmf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_ocr import compress_spatial_text, pdf_to_spatial_text\n",
    "\n",
    "pdf = \"inputs/2857439.pdf\"\n",
    "\n",
    "spatial = pdf_to_spatial_text(pdf)\n",
    "compressed = compress_spatial_text(pdf)\n",
    "\n",
    "print(spatial)\n",
    "print(compress,ed)\n",
    "print(f\"\\n--- Compression: {len(spatial)} chars → {len(compressed)} chars ({(1 - len(compressed)/len(spatial))*100:.0f}% reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fl46cmb0yjk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(f\"{'File':<50} {'Spatial':>8} {'Compressed':>10} {'Reduction':>10}\")\n",
    "print(\"-\" * 82)\n",
    "\n",
    "for fname in sorted(os.listdir(\"inputs\")):\n",
    "    if not fname.endswith(\".pdf\"):\n",
    "        continue\n",
    "    path = os.path.join(\"inputs\", fname)\n",
    "    s = pdf_to_spatial_text(path)\n",
    "    c = compress_spatial_text(path)\n",
    "    reduction = (1 - len(c) / len(s)) * 100 if len(s) > 0 else 0\n",
    "    print(f\"{fname:<50} {len(s):>8} {len(c):>10} {reduction:>9.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovuvmoji2f",
   "metadata": {},
   "source": [
    "## Table Interpretation\n",
    "\n",
    "`interpret_table()` takes compressed text and a **canonical schema** describing the columns your application expects, then uses an LLM pipeline to extract structured records.\n",
    "\n",
    "The schema maps inconsistent PDF column names (e.g. \"Ship Name\", \"Vessel\", \"Vessel Name\") to stable canonical names via aliases. Two modes are available:\n",
    "\n",
    "- **2-step** (`interpret_table`) — parse table structure first, then map to schema. Step 2 is **batched**: each page's parsed rows are split into chunks (default 20 rows) so the LLM produces complete output without truncation. All batches across all pages run concurrently.\n",
    "- **Single-shot** (`interpret_table_single_shot`) — one LLM call per page. Faster for simple flat tables, but cannot batch and may truncate on dense pages (50+ rows).\n",
    "\n",
    "Both modes **auto-split** multi-page input (pages joined by `\\f`) and process all pages **concurrently** via `asyncio.gather()`. The return value is a `dict[int, MappedTable]` keyed by 1-indexed page number — each page gets its own complete result (records, unmapped columns, mapping notes, metadata). Records contain only canonical schema fields.\n",
    "\n",
    "Use `to_records(result)` to flatten all pages into a single `list[dict]`, or `to_records_by_page(result)` for `{page: [dicts]}`.\n",
    "\n",
    "### Vision-based schema inference (optional)\n",
    "\n",
    "Some PDFs have dense tables with stacked/multi-line headers where text extraction produces **garbled or concatenated column names** (e.g. `\"7:00:00 PM BUNGE\"` or `\"33020 WHEAT\"` as single text runs). For these cases, pass `pdf_path=` to `interpret_table()` to enable a vision pre-step:\n",
    "\n",
    "```\n",
    "Step 0 (vision):  page image + compressed text → InferredTableSchema\n",
    "Step 1 (guided):  compressed text + InferredTableSchema → ParsedTable\n",
    "Step 2 (unchanged): ParsedTable → MappedTable\n",
    "```\n",
    "\n",
    "The vision step renders each PDF page as an image and uses a vision-capable LLM to read the correct column headers from the visual layout, then step 1 uses that schema to correctly split compound values. When `pdf_path` is omitted, the pipeline behaves exactly as before (no vision overhead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pvubmndte5j",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the canonical schema as a plain dict (e.g. loaded from a JSON file).\n",
    "# CanonicalSchema.from_dict() converts it into the typed dataclass.\n",
    "#\n",
    "# Note: \"port\" has no aliases — it will be inferred from context (section headers,\n",
    "# document title, or repeated contextual values) rather than matched to a column name.\n",
    "schema_dict = {\n",
    "    \"description\": \"Shipping stem vessel loading records\",\n",
    "    \"columns\": [\n",
    "        {\"name\": \"load_port\",            \"type\": \"string\", \"description\": \"Loading port name\", \"aliases\": [\"Port\"]},\n",
    "        {\"name\": \"vessel_name\",     \"type\": \"string\", \"description\": \"Name of the vessel\",             \"aliases\": [\"Name of Ship\"]},\n",
    "        {\"name\": \"unique_shipping_slot_id\", \"type\": \"string\", \"description\": \"Reference number\",               \"aliases\": [\"Unique Slot Reference Number\"]},\n",
    "        {\"name\": \"shipper\",        \"type\": \"string\", \"description\": \"Exporting company\",              \"aliases\": [\"Exporter\"]},\n",
    "        {\"name\": \"commodity\",       \"type\": \"string\", \"description\": \"Type of commodity\",              \"aliases\": [\"Commodity\"]},\n",
    "        {\"name\": \"tons\", \"type\": \"int\",    \"description\": \"Quantity in metric tonnes\",      \"aliases\": [\"Quantity(tonnes)\"]},\n",
    "        {\"name\": \"eta\",             \"type\": \"string\", \"description\": \"Estimated time of arrival\",      \"aliases\": [\"Date ETA of Ship To\"]},\n",
    "        {\"name\": \"status\",          \"type\": \"string\", \"description\": \"Loading status\",                 \"aliases\": [\"Status\", \"Load Status\"]},\n",
    "    ],\n",
    "}\n",
    "\n",
    "schema = CanonicalSchema.from_dict(schema_dict)\n",
    "\n",
    "print(f\"Schema: {schema.description}\")\n",
    "print(f\"Columns ({len(schema.columns)}):\")\n",
    "for col in schema.columns:\n",
    "    print(f\"  {col.name:20s}  {col.type:6s}  aliases={col.aliases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naakfdlktr",
   "metadata": {},
   "source": [
    "## Multi-page auto-split with batching\n",
    "\n",
    "`compress_spatial_text()` joins pages with `\\f` (form-feed). When `interpret_table()` receives multi-page input, it splits on `\\f` and processes all pages **concurrently**.\n",
    "\n",
    "Step 2 (schema mapping) is **batched** — each page's parsed rows are split into chunks of `batch_size` rows (default 20) before calling the LLM. This prevents truncation on dense pages with many data rows. All batches across all pages run concurrently via `asyncio.gather()`.\n",
    "\n",
    "The result is a `dict[int, MappedTable]` keyed by 1-indexed page number. Each page has its own `records`, `unmapped_columns`, `mapping_notes`, and `metadata`. Use `to_records()` to flatten or `to_records_by_page()` for page-grouped dicts.\n",
    "\n",
    "Below we run the full pipeline on `shipping-stem-2025-11-13.pdf` (3 pages, 180+ records) — no manual splitting needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "txfb2oacg6",
   "metadata": {},
   "source": [
    "## Vision-based interpretation (garbled-header PDFs)\n",
    "\n",
    "The Bunge loading statement has dense stacked headers where text extraction produces concatenated spans. Passing `pdf_path=` enables the vision pipeline: each page is rendered as an image, a vision LLM infers the correct column structure, and the guided parser uses that schema to split compound values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63zvg58zso",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from pdf_ocr import (\n",
    "    compress_spatial_text,\n",
    "    interpret_table,\n",
    "    interpret_table_single_shot,\n",
    "    CanonicalSchema,\n",
    "    ColumnDef,\n",
    "    to_records,\n",
    "    to_records_by_page,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-enabled pipeline on a garbled-header PDF.\n",
    "# The only difference from normal usage is pdf_path= which enables step 0 (vision).\n",
    "\n",
    "newcastle_pdf = \"inputs/2857439.pdf\"\n",
    "compressed_bunge = compress_spatial_text(newcastle_pdf)\n",
    "print(f\"Compressed chars: {len(compressed_bunge)}\")\n",
    "print(compressed_bunge[:500])\n",
    "print(\"...\")\n",
    "\n",
    "# Define a schema suitable for Newcastle loading statements\n",
    "newcastle_schema_dict = {\n",
    "    \"description\": \"Shipping stem vessel loading records\",\n",
    "    \"columns\": [\n",
    "        {\"name\": \"load_port\", \"type\": \"string\", \"description\": \"Loading port name\", \"aliases\": [\"port\"]},\n",
    "        {\"name\": \"vessel_name\", \"type\": \"string\", \"description\": \"Name of the vessel\", \"aliases\": [\"ship name\"]},\n",
    "        {\"name\": \"unique_shipping_slot_id\", \"type\": \"string\", \"description\": \"Reference number\", \"aliases\": [\"unique slot reference number\"]},\n",
    "        {\"name\": \"shipper\", \"type\": \"string\", \"description\": \"Exporting company\", \"aliases\": [\"exporter\"]},\n",
    "        {\"name\": \"commodity\", \"type\": \"string\", \"description\": \"Type of commodity\", \"aliases\": [\"commodity\"]},\n",
    "        {\"name\": \"tons\", \"type\": \"int\", \"description\": \"Quantity in metric tonnes\", \"aliases\": [\"quantity(tonnes)\"]},\n",
    "        {\"name\": \"eta\", \"type\": \"string\", \"description\": \"Estimated time of arrival\", \"aliases\": [\"eta\"]},\n",
    "        {\"name\": \"status\", \"type\": \"string\", \"description\": \"Loading status\", \"aliases\": [\"load status\"]},\n",
    "    ],\n",
    "}\n",
    "\n",
    "newcastle_schema = CanonicalSchema.from_dict(newcastle_schema_dict)\n",
    "\n",
    "# Run WITH vision (pdf_path= enables step 0)\n",
    "result_newcastle = interpret_table(\n",
    "    compressed_bunge,\n",
    "    newcastle_schema,\n",
    "    model=\"openai/gpt-4o\",\n",
    "    pdf_path=newcastle_pdf,\n",
    ")\n",
    "\n",
    "# Result is dict[int, MappedTable] — one entry per page\n",
    "records_newcastle = to_records(result_newcastle)\n",
    "print(f\"Records extracted (vision): {len(records_newcastle)}\")\n",
    "for page, mt in sorted(result_newcastle.items()):\n",
    "    print(f\"Page {page}: {len(mt.records)} records, unmapped={mt.unmapped_columns}\")\n",
    "print(f\"\\n--- First 5 records ---\\n\")\n",
    "for i, rec in enumerate(records_newcastle[:5], 1):\n",
    "    print(f\"[{i}] {rec}\")\n",
    "\n",
    "# Inspect per-page structure: each page has its own records, unmapped_columns, metadata\n",
    "{page: mt.model_dump() for page, mt in result_newcastle.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ngyzjdom4tm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-enabled pipeline on the Bunge PDF (garbled stacked headers).\n",
    "\n",
    "bunge_pdf = \"inputs/Bunge_loadingstatement_2025-09-25.pdf\"\n",
    "compressed_bunge = compress_spatial_text(bunge_pdf)\n",
    "print(f\"Compressed chars: {len(compressed_bunge)}\")\n",
    "print(compressed_bunge[:500])\n",
    "print(\"...\")\n",
    "\n",
    "# Define a schema suitable for Bunge loading statements\n",
    "bunge_schema_dict = {\n",
    "    \"description\": \"Shipping stem vessel loading records\",\n",
    "    \"columns\": [\n",
    "        {\"name\": \"load_port\", \"type\": \"string\", \"description\": \"Loading port name\", \"aliases\": [\"Port\"]},\n",
    "        {\"name\": \"vessel_name\", \"type\": \"string\", \"description\": \"Name of the vessel\", \"aliases\": [\"Name of Ship\"]},\n",
    "        {\"name\": \"unique_shipping_slot_id\", \"type\": \"string\", \"description\": \"Reference number\", \"aliases\": [\"Unique Slot Reference Number\"]},\n",
    "        {\"name\": \"shipper\", \"type\": \"string\", \"description\": \"Exporting company\", \"aliases\": [\"Exporter\"]},\n",
    "        {\"name\": \"commodity\", \"type\": \"string\", \"description\": \"Type of commodity\", \"aliases\": [\"Commodity\"]},\n",
    "        {\"name\": \"tons\", \"type\": \"int\",    \"description\": \"Quantity in metric tonnes\", \"aliases\": [\"Quantity(tonnes)\"]},\n",
    "        {\"name\": \"eta\", \"type\": \"string\", \"description\": \"Estimated time of arrival\", \"aliases\": [\"Date ETA of Ship To\"]},\n",
    "        {\"name\": \"status\", \"type\": \"string\", \"description\": \"Loading status\", \"aliases\": [\"Status\", \"Load Status\"]},\n",
    "    ],\n",
    "}\n",
    "\n",
    "bunge_schema = CanonicalSchema.from_dict(bunge_schema_dict)\n",
    "\n",
    "# Run WITH vision (pdf_path= enables step 0)\n",
    "result_bunge = interpret_table(\n",
    "    compressed_bunge,\n",
    "    bunge_schema,\n",
    "    model=\"openai/gpt-4o\",\n",
    "    pdf_path=bunge_pdf,\n",
    ")\n",
    "\n",
    "# Result is dict[int, MappedTable] — one entry per page\n",
    "records_bunge = to_records(result_bunge)\n",
    "print(f\"Records extracted (vision): {len(records_bunge)}\")\n",
    "for page, mt in sorted(result_bunge.items()):\n",
    "    print(f\"Page {page}: {len(mt.records)} records, unmapped={mt.unmapped_columns}\")\n",
    "print(f\"\\n--- First 5 records ---\\n\")\n",
    "for i, rec in enumerate(records_bunge[:5], 1):\n",
    "    print(f\"[{i}] {rec}\")\n",
    "\n",
    "# Inspect per-page structure: each page has its own records, unmapped_columns, metadata\n",
    "{page: mt.model_dump() for page, mt in result_bunge.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-enabled pipeline on the Bunge PDF (garbled stacked headers).\n",
    "\n",
    "cbh_pdf = \"inputs/CBH Shipping Stem 26092025.pdf\"\n",
    "compressed_cbh = compress_spatial_text(cbh_pdf)\n",
    "print(f\"Compressed chars: {len(compressed_cbh)}\")\n",
    "print(compressed_cbh[:500])\n",
    "print(\"...\")\n",
    "\n",
    "# Define a schema suitable for Bunge loading statements\n",
    "cbh_schema_dict = {\n",
    "    \"description\": \"Shipping stem vessel loading records\",\n",
    "    \"columns\": [\n",
    "        {\"name\": \"load_port\", \"type\": \"string\", \"description\": \"Loading port name, not captured in the original schema but present inside the header\", \"aliases\": []},\n",
    "        {\"name\": \"vessel_name\", \"type\": \"string\", \"description\": \"Name of the vessel\", \"aliases\": [\"vessel name\"]},\n",
    "        {\"name\": \"unique_shipping_slot_id\", \"type\": \"string\", \"description\": \"Reference number\", \"aliases\": [\"vna #\"]},\n",
    "        {\"name\": \"shipper\", \"type\": \"string\", \"description\": \"Exporting company\", \"aliases\": [\"client\"]},\n",
    "        {\"name\": \"commodity\", \"type\": \"string\", \"description\": \"Type of commodity\", \"aliases\": [\"Commodity\"]},\n",
    "        {\"name\": \"tons\", \"type\": \"int\",    \"description\": \"Quantity in metric tonnes\", \"aliases\": [\"volume\"]},\n",
    "        {\"name\": \"eta\", \"type\": \"string\", \"description\": \"Estimated time of arrival\", \"aliases\": [\"ETA\"]},\n",
    "        {\"name\": \"status\", \"type\": \"string\", \"description\": \"Loading status\", \"aliases\": [\"Status\", \"Loading Status\"]},\n",
    "    ],\n",
    "}\n",
    "\n",
    "cbh_schema = CanonicalSchema.from_dict(cbh_schema_dict)\n",
    "\n",
    "# Run WITH vision (pdf_path= enables step 0)\n",
    "result_cbh = interpret_table(\n",
    "    compressed_cbh,\n",
    "    cbh_schema,\n",
    "    model=\"openai/gpt-4o\",\n",
    "    pdf_path=cbh_pdf,\n",
    ")\n",
    "\n",
    "# Result is dict[int, MappedTable] — one entry per page\n",
    "records_cbh = to_records(result_cbh)\n",
    "print(f\"Records extracted (vision): {len(records_cbh)}\")\n",
    "for page, mt in sorted(result_cbh.items()):\n",
    "    print(f\"Page {page}: {len(mt.records)} records, unmapped={mt.unmapped_columns}\")\n",
    "print(f\"\\n--- First 5 records ---\\n\")\n",
    "for i, rec in enumerate(records_cbh[:5], 1):\n",
    "    print(f\"[{i}] {rec}\")\n",
    "\n",
    "# Inspect per-page structure: each page has its own records, unmapped_columns, metadata\n",
    "{page: mt.model_dump() for page, mt in result_cbh.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fahgdot7id",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pdf_ocr.interpret:Vision enabled: rendering 7 page(s) from inputs/document (1).pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed chars: 7593\n",
      "|Unique Slot Reference Number|QB2061036115|QB3126604877|\n",
      "|---|---|---|\n",
      "|Name of ship|DARYA DIYA|MH ADAGIO|\n",
      "|Date at which nomination was|04-07-2025|03-06-2025|\n",
      "\n",
      "received\n",
      "\n",
      "Time at which nomination was\t03:17:00 PM\t02:23:00 PM\n",
      "\n",
      "received\n",
      "\n",
      "Date at which nomination was\t04-07-2025\t03-06-2025\n",
      "\n",
      "accepted\n",
      "\n",
      "Time at which nomination was\t03:30:00 PM\t02:36:00 PM\n",
      "\n",
      "accepted\n",
      "\n",
      "|Port|Brisbane|Brisbane|\n",
      "|---|---|---|\n",
      "|Date of ETA of Ship From|15-09-2025|21-07-2025|\n",
      "|Time of ETA of Ship From|02:53:00 PM|11:43:00 AM|\n",
      "\n",
      "...\n",
      "2026-02-02T19:10:40.214 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction InferTableSchemaFromImage\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 8138ms. StopReason: stop. Tokens(in/out): 2011/218\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table structure analyst. You are given:\n",
      "    1. An image of a PDF page containing a table\n",
      "    2. Compressed text extracted from the same page (which may have parsing errors)\n",
      "    \n",
      "    Your task: determine the COMPLETE table column structure by combining\n",
      "    evidence from BOTH the image and the compressed text.\n",
      "    \n",
      "    CRITICAL: Dense tables with small fonts often have narrow columns that are\n",
      "    easy to miss visually. You MUST cross-validate your column list against the\n",
      "    data rows in the compressed text.\n",
      "    \n",
      "    Steps:\n",
      "    1. Count the pipe-separated cells in the FIRST data row of the compressed\n",
      "       text (the row after the |---|---| separator). This gives you the MINIMUM\n",
      "       number of columns — some cells may be concatenated (two values joined\n",
      "       into one cell), so the actual column count may be HIGHER.\n",
      "    2. Find the table header area in the image. Read EVERY column header left\n",
      "       to right. Pay special attention to narrow single-word columns between\n",
      "       wider multi-word columns — these are commonly missed.\n",
      "       - For stacked/multi-line headers, combine the labels into one name\n",
      "         (e.g. a column whose header reads \"Start\" on line 1 and \"Date\" on\n",
      "         line 2 becomes \"Start Date\").\n",
      "    3. Cross-reference with the garbled header lines in the compressed text\n",
      "       (the lines above the pipe table). Header fragments like individual\n",
      "       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n",
      "       columns that may appear narrow in the image.\n",
      "    4. Verify: your column_count MUST be >= the number of pipe-separated cells\n",
      "       in the data rows. If it is less, you have missed columns — re-examine\n",
      "       the image and text headers.\n",
      "    5. Note how many header rows exist and any structural observations,\n",
      "       including which data cells appear concatenated (e.g. \"42 Smith\"\n",
      "       containing values for two columns).\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Column headers as they visually appear in the table, left to right. For multi-line headers, combine stacked labels into a single name per column (e.g. 'Date / Arrival' or 'Quantity MT').\n",
      "      column_names: string[],\n",
      "      // Total number of data columns\n",
      "      column_count: int,\n",
      "      // Number of header rows (1 for flat, >1 for stacked/multi-line headers)\n",
      "      header_levels: int,\n",
      "      // Observations about the header structure: merged cells, stacked labels, visual groupings, etc.\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[43muser: \u001b[0m\u001b[2m<image_placeholder base64>Compressed text (for reference — may contain errors):\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB3582536041|QB1566785655|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TBA|TBA|\n",
      "    |Date at which nomination was|29-04-2025|30-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t01:00:00 PM\t08:14:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t02-05-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t02:59:00 PM\t02:30:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|15-12-2025|01-01-2026|\n",
      "    |Time of ETA of Ship From|04:02:00 PM|04:05:00 PM|\n",
      "    |Date of ETA of Ship To|30-12-2025|15-01-2026|\n",
      "    |Time of ETA of Ship To|04:03:00 PM|04:06:00 PM|\n",
      "    \n",
      "    Date ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Date of ETD of Ship\n",
      "    \n",
      "    Time of ETD of Ship\n",
      "    \n",
      "    |Exporter|Louis Dreyfus Company|ADM Trading Australia Pty|\n",
      "    |---|---|---|\n",
      "    ||Grains Australia Pty Ltd|Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Chickpeas|QBT Chickpeas|\n",
      "    \n",
      "    \"Loading \"\"commenced\"\" or\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\n",
      "    \n",
      "    Time Loading Completed\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of Ship\",\n",
      "        \"Date Nomination Received\",\n",
      "        \"Time Nomination Received\",\n",
      "        \"Date Nomination Accepted\",\n",
      "        \"Time Nomination Accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity (tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Loading Status\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table has clear header labels with no visible merging or stacked headers. However, some column headers are represented in multiple lines in the image.\"\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class InferredTableSchema)---\u001b[0m\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of Ship\",\n",
      "        \"Date Nomination Received\",\n",
      "        \"Time Nomination Received\",\n",
      "        \"Date Nomination Accepted\",\n",
      "        \"Time Nomination Accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity (tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Loading Status\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table has clear header labels with no visible merging or stacked headers. However, some column headers are represented in multiple lines in the image.\"\n",
      "    }\n",
      "2026-02-02T19:10:42.050 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction InferTableSchemaFromImage\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 9979ms. StopReason: stop. Tokens(in/out): 2006/236\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table structure analyst. You are given:\n",
      "    1. An image of a PDF page containing a table\n",
      "    2. Compressed text extracted from the same page (which may have parsing errors)\n",
      "    \n",
      "    Your task: determine the COMPLETE table column structure by combining\n",
      "    evidence from BOTH the image and the compressed text.\n",
      "    \n",
      "    CRITICAL: Dense tables with small fonts often have narrow columns that are\n",
      "    easy to miss visually. You MUST cross-validate your column list against the\n",
      "    data rows in the compressed text.\n",
      "    \n",
      "    Steps:\n",
      "    1. Count the pipe-separated cells in the FIRST data row of the compressed\n",
      "       text (the row after the |---|---| separator). This gives you the MINIMUM\n",
      "       number of columns — some cells may be concatenated (two values joined\n",
      "       into one cell), so the actual column count may be HIGHER.\n",
      "    2. Find the table header area in the image. Read EVERY column header left\n",
      "       to right. Pay special attention to narrow single-word columns between\n",
      "       wider multi-word columns — these are commonly missed.\n",
      "       - For stacked/multi-line headers, combine the labels into one name\n",
      "         (e.g. a column whose header reads \"Start\" on line 1 and \"Date\" on\n",
      "         line 2 becomes \"Start Date\").\n",
      "    3. Cross-reference with the garbled header lines in the compressed text\n",
      "       (the lines above the pipe table). Header fragments like individual\n",
      "       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n",
      "       columns that may appear narrow in the image.\n",
      "    4. Verify: your column_count MUST be >= the number of pipe-separated cells\n",
      "       in the data rows. If it is less, you have missed columns — re-examine\n",
      "       the image and text headers.\n",
      "    5. Note how many header rows exist and any structural observations,\n",
      "       including which data cells appear concatenated (e.g. \"42 Smith\"\n",
      "       containing values for two columns).\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Column headers as they visually appear in the table, left to right. For multi-line headers, combine stacked labels into a single name per column (e.g. 'Date / Arrival' or 'Quantity MT').\n",
      "      column_names: string[],\n",
      "      // Total number of data columns\n",
      "      column_count: int,\n",
      "      // Number of header rows (1 for flat, >1 for stacked/multi-line headers)\n",
      "      header_levels: int,\n",
      "      // Observations about the header structure: merged cells, stacked labels, visual groupings, etc.\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[43muser: \u001b[0m\u001b[2m<image_placeholder base64>Compressed text (for reference — may contain errors):\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB5345742564|QB2687807116|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TBA|TBA|\n",
      "    |Date at which nomination was|30-04-2025|30-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t08:14:00 PM\t08:14:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t02-05-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t02:30:00 PM\t02:30:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|01-12-2025|15-11-2025|\n",
      "    |Time of ETA of Ship From|04:04:00 PM|04:04:00 PM|\n",
      "    |Date of ETA of Ship To|15-12-2025|30-11-2025|\n",
      "    |Time of ETA of Ship To|04:05:00 PM|04:04:00 PM|\n",
      "    \n",
      "    Date ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Date of ETD of Ship\n",
      "    \n",
      "    Time of ETD of Ship\n",
      "    \n",
      "    |Exporter|ADM Trading Australia Pty|ADM Trading Australia Pty|\n",
      "    |---|---|---|\n",
      "    ||Ltd|Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Chickpeas|QBT Chickpeas|\n",
      "    \n",
      "    \"Loading \"\"commenced\"\" or\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\n",
      "    \n",
      "    Time Loading Completed\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table contains multiple columns, some of which are specific to dates and times. Data rows may have concatenated text split unevenly in the text extraction.\"\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class InferredTableSchema)---\u001b[0m\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table contains multiple columns, some of which are specific to dates and times. Data rows may have concatenated text split unevenly in the text extraction.\"\n",
      "    }\n",
      "2026-02-02T19:10:42.050 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction InferTableSchemaFromImage\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 9978ms. StopReason: stop. Tokens(in/out): 2102/240\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table structure analyst. You are given:\n",
      "    1. An image of a PDF page containing a table\n",
      "    2. Compressed text extracted from the same page (which may have parsing errors)\n",
      "    \n",
      "    Your task: determine the COMPLETE table column structure by combining\n",
      "    evidence from BOTH the image and the compressed text.\n",
      "    \n",
      "    CRITICAL: Dense tables with small fonts often have narrow columns that are\n",
      "    easy to miss visually. You MUST cross-validate your column list against the\n",
      "    data rows in the compressed text.\n",
      "    \n",
      "    Steps:\n",
      "    1. Count the pipe-separated cells in the FIRST data row of the compressed\n",
      "       text (the row after the |---|---| separator). This gives you the MINIMUM\n",
      "       number of columns — some cells may be concatenated (two values joined\n",
      "       into one cell), so the actual column count may be HIGHER.\n",
      "    2. Find the table header area in the image. Read EVERY column header left\n",
      "       to right. Pay special attention to narrow single-word columns between\n",
      "       wider multi-word columns — these are commonly missed.\n",
      "       - For stacked/multi-line headers, combine the labels into one name\n",
      "         (e.g. a column whose header reads \"Start\" on line 1 and \"Date\" on\n",
      "         line 2 becomes \"Start Date\").\n",
      "    3. Cross-reference with the garbled header lines in the compressed text\n",
      "       (the lines above the pipe table). Header fragments like individual\n",
      "       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n",
      "       columns that may appear narrow in the image.\n",
      "    4. Verify: your column_count MUST be >= the number of pipe-separated cells\n",
      "       in the data rows. If it is less, you have missed columns — re-examine\n",
      "       the image and text headers.\n",
      "    5. Note how many header rows exist and any structural observations,\n",
      "       including which data cells appear concatenated (e.g. \"42 Smith\"\n",
      "       containing values for two columns).\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Column headers as they visually appear in the table, left to right. For multi-line headers, combine stacked labels into a single name per column (e.g. 'Date / Arrival' or 'Quantity MT').\n",
      "      column_names: string[],\n",
      "      // Total number of data columns\n",
      "      column_count: int,\n",
      "      // Number of header rows (1 for flat, >1 for stacked/multi-line headers)\n",
      "      header_levels: int,\n",
      "      // Observations about the header structure: merged cells, stacked labels, visual groupings, etc.\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[43muser: \u001b[0m\u001b[2m<image_placeholder base64>Compressed text (for reference — may contain errors):\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB0357578736|QB7412357677|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TOMINI OROSHI|UBC TAKORADI|\n",
      "    |Date at which nomination was|29-05-2025|16-05-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t02:19:00 PM\t05:41:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t29-05-2025\t16-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t07:06:00 PM\t08:26:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|16-06-2025|01-06-2025|\n",
      "    |Time of ETA of Ship From|11:57:00 AM|11:56:00 AM|\n",
      "    |Date of ETA of Ship To|22-06-2025|15-06-2025|\n",
      "    |Time of ETA of Ship To|11:57:00 AM|11:56:00 AM|\n",
      "    |Date ETA of Grain Loading|19-06-2025|05-06-2025|\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\t01:28:00 PM\t11:41:00 AM\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    |Date of ETD of Ship|22-06-2025|07-06-2025|\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship|04:30:00 AM|07:00:00 PM|\n",
      "    |Exporter|Wilmar Trading Australia|Wilmar Trading Australia|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Sorghum|QBT Sorghum|\n",
      "    |\"Loading \"\"commenced\"\" or|Completed|Completed|\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\t21-06-2025\t07-06-2025\n",
      "    \n",
      "    Time Loading Completed\t08:30:00 PM\t02:48:00 PM\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m{\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\"\n",
      "      ],\n",
      "      \"column_count\": 21,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The headers are complex and some are repeated in multiple lines in the compressed text, such as date and time of events. Some might be missed due to narrow spacing. Ensure correct association of date and time with events.\"\n",
      "    }\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class InferredTableSchema)---\u001b[0m\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\"\n",
      "      ],\n",
      "      \"column_count\": 21,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The headers are complex and some are repeated in multiple lines in the compressed text, such as date and time of events. Some might be missed due to narrow spacing. Ensure correct association of date and time with events.\"\n",
      "    }\n",
      "2026-02-02T19:10:42.071 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction InferTableSchemaFromImage\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 9999ms. StopReason: stop. Tokens(in/out): 2066/240\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table structure analyst. You are given:\n",
      "    1. An image of a PDF page containing a table\n",
      "    2. Compressed text extracted from the same page (which may have parsing errors)\n",
      "    \n",
      "    Your task: determine the COMPLETE table column structure by combining\n",
      "    evidence from BOTH the image and the compressed text.\n",
      "    \n",
      "    CRITICAL: Dense tables with small fonts often have narrow columns that are\n",
      "    easy to miss visually. You MUST cross-validate your column list against the\n",
      "    data rows in the compressed text.\n",
      "    \n",
      "    Steps:\n",
      "    1. Count the pipe-separated cells in the FIRST data row of the compressed\n",
      "       text (the row after the |---|---| separator). This gives you the MINIMUM\n",
      "       number of columns — some cells may be concatenated (two values joined\n",
      "       into one cell), so the actual column count may be HIGHER.\n",
      "    2. Find the table header area in the image. Read EVERY column header left\n",
      "       to right. Pay special attention to narrow single-word columns between\n",
      "       wider multi-word columns — these are commonly missed.\n",
      "       - For stacked/multi-line headers, combine the labels into one name\n",
      "         (e.g. a column whose header reads \"Start\" on line 1 and \"Date\" on\n",
      "         line 2 becomes \"Start Date\").\n",
      "    3. Cross-reference with the garbled header lines in the compressed text\n",
      "       (the lines above the pipe table). Header fragments like individual\n",
      "       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n",
      "       columns that may appear narrow in the image.\n",
      "    4. Verify: your column_count MUST be >= the number of pipe-separated cells\n",
      "       in the data rows. If it is less, you have missed columns — re-examine\n",
      "       the image and text headers.\n",
      "    5. Note how many header rows exist and any structural observations,\n",
      "       including which data cells appear concatenated (e.g. \"42 Smith\"\n",
      "       containing values for two columns).\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Column headers as they visually appear in the table, left to right. For multi-line headers, combine stacked labels into a single name per column (e.g. 'Date / Arrival' or 'Quantity MT').\n",
      "      column_names: string[],\n",
      "      // Total number of data columns\n",
      "      column_count: int,\n",
      "      // Number of header rows (1 for flat, >1 for stacked/multi-line headers)\n",
      "      header_levels: int,\n",
      "      // Observations about the header structure: merged cells, stacked labels, visual groupings, etc.\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[43muser: \u001b[0m\u001b[2m<image_placeholder base64>Compressed text (for reference — may contain errors):\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB7157365064|QB5815500230|\n",
      "    |---|---|---|\n",
      "    |Name of ship|SOUTHGATE|TBA|\n",
      "    |Date at which nomination was|16-04-2025|29-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t08:05:00 PM\t01:00:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t17-04-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t05:36:00 AM\t02:59:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|05-05-2025|10-11-2025|\n",
      "    |Time of ETA of Ship From|01:40:00 PM|04:00:00 PM|\n",
      "    |Date of ETA of Ship To|12-05-2025|20-11-2025|\n",
      "    |Time of ETA of Ship To|01:40:00 PM|04:00:00 PM|\n",
      "    |Date ETA of Grain Loading|09-05-2025||\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading Commencement: 10:47:00 AM\n",
      "    \n",
      "    |Date of ETD of Ship|13-05-2025||\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship|09:00:00 AM||\n",
      "    |Exporter|Wilmar Trading Australia|Louis Dreyfus Company|\n",
      "    \n",
      "    Grains Australia Pty Ltd\n",
      "    \n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |---|---|---|\n",
      "    |Commodity|QBT Sorghum|QBT Chickpeas|\n",
      "    |\"Loading \"\"commenced\"\" or|Completed||\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed: 13-05-2025\n",
      "    Time Loading Completed Notes: 04:35:00 AM\n",
      "    Last updated on:: 30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"\\\"Loading commenced or completed\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"Some column headers have multiline descriptions. The layout suggests merged cells in the physical table, which might not be evident in the compressed text. Text also shows signs of being split across lines for clarity.\"\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class InferredTableSchema)---\u001b[0m\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"\\\"Loading commenced or completed\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"Some column headers have multiline descriptions. The layout suggests merged cells in the physical table, which might not be evident in the compressed text. Text also shows signs of being split across lines for clarity.\"\n",
      "    }\n",
      "2026-02-02T19:10:42.869 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction InferTableSchemaFromImage\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 10798ms. StopReason: stop. Tokens(in/out): 2016/230\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table structure analyst. You are given:\n",
      "    1. An image of a PDF page containing a table\n",
      "    2. Compressed text extracted from the same page (which may have parsing errors)\n",
      "    \n",
      "    Your task: determine the COMPLETE table column structure by combining\n",
      "    evidence from BOTH the image and the compressed text.\n",
      "    \n",
      "    CRITICAL: Dense tables with small fonts often have narrow columns that are\n",
      "    easy to miss visually. You MUST cross-validate your column list against the\n",
      "    data rows in the compressed text.\n",
      "    \n",
      "    Steps:\n",
      "    1. Count the pipe-separated cells in the FIRST data row of the compressed\n",
      "       text (the row after the |---|---| separator). This gives you the MINIMUM\n",
      "       number of columns — some cells may be concatenated (two values joined\n",
      "       into one cell), so the actual column count may be HIGHER.\n",
      "    2. Find the table header area in the image. Read EVERY column header left\n",
      "       to right. Pay special attention to narrow single-word columns between\n",
      "       wider multi-word columns — these are commonly missed.\n",
      "       - For stacked/multi-line headers, combine the labels into one name\n",
      "         (e.g. a column whose header reads \"Start\" on line 1 and \"Date\" on\n",
      "         line 2 becomes \"Start Date\").\n",
      "    3. Cross-reference with the garbled header lines in the compressed text\n",
      "       (the lines above the pipe table). Header fragments like individual\n",
      "       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n",
      "       columns that may appear narrow in the image.\n",
      "    4. Verify: your column_count MUST be >= the number of pipe-separated cells\n",
      "       in the data rows. If it is less, you have missed columns — re-examine\n",
      "       the image and text headers.\n",
      "    5. Note how many header rows exist and any structural observations,\n",
      "       including which data cells appear concatenated (e.g. \"42 Smith\"\n",
      "       containing values for two columns).\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Column headers as they visually appear in the table, left to right. For multi-line headers, combine stacked labels into a single name per column (e.g. 'Date / Arrival' or 'Quantity MT').\n",
      "      column_names: string[],\n",
      "      // Total number of data columns\n",
      "      column_count: int,\n",
      "      // Number of header rows (1 for flat, >1 for stacked/multi-line headers)\n",
      "      header_levels: int,\n",
      "      // Observations about the header structure: merged cells, stacked labels, visual groupings, etc.\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[43muser: \u001b[0m\u001b[2m<image_placeholder base64>Compressed text (for reference — may contain errors):\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB2771655637|QB1541470610|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TBA|TBA|\n",
      "    |Date at which nomination was|29-04-2025|29-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t01:00:00 PM\t01:00:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t02-05-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t02:59:00 PM\t02:59:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|21-11-2025|01-12-2025|\n",
      "    |Time of ETA of Ship From|04:01:00 PM|04:02:00 PM|\n",
      "    |Date of ETA of Ship To|30-11-2025|15-12-2025|\n",
      "    |Time of ETA of Ship To|04:01:00 PM|04:02:00 PM|\n",
      "    \n",
      "    Date ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Date of ETD of Ship\n",
      "    \n",
      "    Time of ETD of Ship\n",
      "    \n",
      "    |Exporter|Louis Dreyfus Company|Louis Dreyfus Company|\n",
      "    |---|---|---|\n",
      "    ||Grains Australia Pty Ltd|Grains Australia Pty Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Chickpeas|QBT Chickpeas|\n",
      "    \n",
      "    \"Loading \"\"commenced\"\" or\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\n",
      "    \n",
      "    Time Loading Completed\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of Ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity (tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 21,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table consists of multiple fields, some with two lines of information. For instance, 'Exporter' includes two separate lines for company and subsidiary. Loading and completion times are additional columns.\"\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class InferredTableSchema)---\u001b[0m\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of Ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity (tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 21,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table consists of multiple fields, some with two lines of information. For instance, 'Exporter' includes two separate lines for company and subsidiary. Loading and completion times are additional columns.\"\n",
      "    }\n",
      "2026-02-02T19:10:43.634 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction InferTableSchemaFromImage\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 11563ms. StopReason: stop. Tokens(in/out): 2054/247\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table structure analyst. You are given:\n",
      "    1. An image of a PDF page containing a table\n",
      "    2. Compressed text extracted from the same page (which may have parsing errors)\n",
      "    \n",
      "    Your task: determine the COMPLETE table column structure by combining\n",
      "    evidence from BOTH the image and the compressed text.\n",
      "    \n",
      "    CRITICAL: Dense tables with small fonts often have narrow columns that are\n",
      "    easy to miss visually. You MUST cross-validate your column list against the\n",
      "    data rows in the compressed text.\n",
      "    \n",
      "    Steps:\n",
      "    1. Count the pipe-separated cells in the FIRST data row of the compressed\n",
      "       text (the row after the |---|---| separator). This gives you the MINIMUM\n",
      "       number of columns — some cells may be concatenated (two values joined\n",
      "       into one cell), so the actual column count may be HIGHER.\n",
      "    2. Find the table header area in the image. Read EVERY column header left\n",
      "       to right. Pay special attention to narrow single-word columns between\n",
      "       wider multi-word columns — these are commonly missed.\n",
      "       - For stacked/multi-line headers, combine the labels into one name\n",
      "         (e.g. a column whose header reads \"Start\" on line 1 and \"Date\" on\n",
      "         line 2 becomes \"Start Date\").\n",
      "    3. Cross-reference with the garbled header lines in the compressed text\n",
      "       (the lines above the pipe table). Header fragments like individual\n",
      "       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n",
      "       columns that may appear narrow in the image.\n",
      "    4. Verify: your column_count MUST be >= the number of pipe-separated cells\n",
      "       in the data rows. If it is less, you have missed columns — re-examine\n",
      "       the image and text headers.\n",
      "    5. Note how many header rows exist and any structural observations,\n",
      "       including which data cells appear concatenated (e.g. \"42 Smith\"\n",
      "       containing values for two columns).\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Column headers as they visually appear in the table, left to right. For multi-line headers, combine stacked labels into a single name per column (e.g. 'Date / Arrival' or 'Quantity MT').\n",
      "      column_names: string[],\n",
      "      // Total number of data columns\n",
      "      column_count: int,\n",
      "      // Number of header rows (1 for flat, >1 for stacked/multi-line headers)\n",
      "      header_levels: int,\n",
      "      // Observations about the header structure: merged cells, stacked labels, visual groupings, etc.\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[43muser: \u001b[0m\u001b[2m<image_placeholder base64>Compressed text (for reference — may contain errors):\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB2061036115|QB3126604877|\n",
      "    |---|---|---|\n",
      "    |Name of ship|DARYA DIYA|MH ADAGIO|\n",
      "    |Date at which nomination was|04-07-2025|03-06-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t03:17:00 PM\t02:23:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t04-07-2025\t03-06-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t03:30:00 PM\t02:36:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|15-09-2025|21-07-2025|\n",
      "    |Time of ETA of Ship From|02:53:00 PM|11:43:00 AM|\n",
      "    |Date of ETA of Ship To|30-09-2025|31-07-2025|\n",
      "    |Time of ETA of Ship To|02:54:00 PM|11:43:00 AM|\n",
      "    |Date ETA of Grain Loading||24-07-2025|\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading Commencement: 12:55:00 AM\n",
      "    \n",
      "    |Date of ETD of Ship||26-07-2025|\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship||11:00:00 AM|\n",
      "    |Exporter|Arrow Commodities Pty Ltd|Arrow Commodities Pty Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Wheat|QBT Wheat|\n",
      "    |\"Loading \"\"commenced\"\" or||Completed|\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed: 25-07-2025\n",
      "    Time Loading Completed Notes: 09:13:00 PM\n",
      "    Last updated on:: 30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"\\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"Some headers span multiple lines in text, such as 'Date at which nomination was received'. Compressed text suggests some values may be missing or concatenated, but table structure is maintained.\"\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class InferredTableSchema)---\u001b[0m\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"\\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"Some headers span multiple lines in text, such as 'Date at which nomination was received'. Compressed text suggests some values may be missing or concatenated, but table structure is maintained.\"\n",
      "    }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pdf_ocr.interpret:Step 0 page 1: inferred 22 columns: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', '\"Loading \"\"commenced\"\" or \"\"completed\"\"\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:Step 0 page 2: inferred 22 columns: ['Unique Slot Reference Number', 'Name of Ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', '\"Loading \"commenced\" or \"completed\"\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:Step 0 page 3: inferred 21 columns: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', 'Loading \"commenced\" or \"completed\"', 'Date Loading Completed', 'Time Loading Completed']\n",
      "INFO:pdf_ocr.interpret:Step 0 page 4: inferred 22 columns: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', '\"Loading commenced or completed\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:Step 0 page 5: inferred 21 columns: ['Unique Slot Reference Number', 'Name of Ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity (tonnes)', 'Commodity', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:Step 0 page 6: inferred 22 columns: ['Unique Slot Reference Number', 'Name of Ship', 'Date Nomination Received', 'Time Nomination Received', 'Date Nomination Accepted', 'Time Nomination Accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity (tonnes)', 'Commodity', 'Loading Status', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:Step 0 page 7: inferred 22 columns: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', 'Loading \"commenced\" or \"completed\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-02T19:10:44.322 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction InferTableSchemaFromImage\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 12250ms. StopReason: stop. Tokens(in/out): 2098/267\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table structure analyst. You are given:\n",
      "    1. An image of a PDF page containing a table\n",
      "    2. Compressed text extracted from the same page (which may have parsing errors)\n",
      "    \n",
      "    Your task: determine the COMPLETE table column structure by combining\n",
      "    evidence from BOTH the image and the compressed text.\n",
      "    \n",
      "    CRITICAL: Dense tables with small fonts often have narrow columns that are\n",
      "    easy to miss visually. You MUST cross-validate your column list against the\n",
      "    data rows in the compressed text.\n",
      "    \n",
      "    Steps:\n",
      "    1. Count the pipe-separated cells in the FIRST data row of the compressed\n",
      "       text (the row after the |---|---| separator). This gives you the MINIMUM\n",
      "       number of columns — some cells may be concatenated (two values joined\n",
      "       into one cell), so the actual column count may be HIGHER.\n",
      "    2. Find the table header area in the image. Read EVERY column header left\n",
      "       to right. Pay special attention to narrow single-word columns between\n",
      "       wider multi-word columns — these are commonly missed.\n",
      "       - For stacked/multi-line headers, combine the labels into one name\n",
      "         (e.g. a column whose header reads \"Start\" on line 1 and \"Date\" on\n",
      "         line 2 becomes \"Start Date\").\n",
      "    3. Cross-reference with the garbled header lines in the compressed text\n",
      "       (the lines above the pipe table). Header fragments like individual\n",
      "       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n",
      "       columns that may appear narrow in the image.\n",
      "    4. Verify: your column_count MUST be >= the number of pipe-separated cells\n",
      "       in the data rows. If it is less, you have missed columns — re-examine\n",
      "       the image and text headers.\n",
      "    5. Note how many header rows exist and any structural observations,\n",
      "       including which data cells appear concatenated (e.g. \"42 Smith\"\n",
      "       containing values for two columns).\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Column headers as they visually appear in the table, left to right. For multi-line headers, combine stacked labels into a single name per column (e.g. 'Date / Arrival' or 'Quantity MT').\n",
      "      column_names: string[],\n",
      "      // Total number of data columns\n",
      "      column_count: int,\n",
      "      // Number of header rows (1 for flat, >1 for stacked/multi-line headers)\n",
      "      header_levels: int,\n",
      "      // Observations about the header structure: merged cells, stacked labels, visual groupings, etc.\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[43muser: \u001b[0m\u001b[2m<image_placeholder base64>Compressed text (for reference — may contain errors):\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB1148678055|QB5305788574|\n",
      "    |---|---|---|\n",
      "    |Name of ship|MONOCEROS|CETUS SEI|\n",
      "    |Date at which nomination was|05-06-2025|16-06-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t04:49:00 PM\t02:59:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t05-06-2025\t16-06-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t05:00:00 PM\t02:59:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|21-07-2025|30-06-2025|\n",
      "    |Time of ETA of Ship From|11:41:00 AM|02:59:00 PM|\n",
      "    |Date of ETA of Ship To|31-07-2025|05-07-2025|\n",
      "    |Time of ETA of Ship To|11:41:00 AM|03:00:00 PM|\n",
      "    |Date ETA of Grain Loading|27-07-2025|01-07-2025|\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\t10:21:00 PM\t09:35:00 AM\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    |Date of ETD of Ship|31-07-2025|03-07-2025|\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship|02:54:00 AM|03:20:00 PM|\n",
      "    |Exporter|Robinson Grain|Wilmar Trading Australia|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Sorghum|QBT Sorghum|\n",
      "    |\"Loading \"\"commenced\"\" or|Completed|Completed|\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\t30-07-2025\t03-07-2025\n",
      "    \n",
      "    Time Loading Completed\t01:56:00 PM\t03:28:00 AM\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\", \n",
      "        \"Name of Ship\", \n",
      "        \"Date at which nomination was received\", \n",
      "        \"Time at which nomination was received\", \n",
      "        \"Date at which nomination was accepted\", \n",
      "        \"Time at which nomination was accepted\", \n",
      "        \"Port\", \n",
      "        \"Date of ETA of Ship From\", \n",
      "        \"Time of ETA of Ship From\", \n",
      "        \"Date of ETA of Ship To\", \n",
      "        \"Time of ETA of Ship To\", \n",
      "        \"Date ETA of Grain Loading Commencement\", \n",
      "        \"Time ETA of Grain Loading Commencement\", \n",
      "        \"Date of ETD of Ship\", \n",
      "        \"Time of ETD of Ship\", \n",
      "        \"Exporter\", \n",
      "        \"Quantity(tonnes)\", \n",
      "        \"Commodity\", \n",
      "        \"\\\"Loading \\\"commenced\\\" or \\\"completed\\\"\\\"\", \n",
      "        \"Date Loading Completed\", \n",
      "        \"Time Loading Completed\", \n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table has a single header level. Each column represents distinct fields as evidenced by the detailed itemization of dates and times concerning shipments and nominations. Observations around completion status are labeled in a descriptive manner.\"\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class InferredTableSchema)---\u001b[0m\n",
      "    {\n",
      "      \"column_names\": [\n",
      "        \"Unique Slot Reference Number\",\n",
      "        \"Name of Ship\",\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Port\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date of ETA of Ship To\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Exporter\",\n",
      "        \"Quantity(tonnes)\",\n",
      "        \"Commodity\",\n",
      "        \"\\\"Loading \\\"commenced\\\" or \\\"completed\\\"\\\"\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"column_count\": 22,\n",
      "      \"header_levels\": 1,\n",
      "      \"notes\": \"The table has a single header level. Each column represents distinct fields as evidenced by the detailed itemization of dates and times concerning shipments and nominations. Observations around completion status are labeled in a descriptive manner.\"\n",
      "    }\n",
      "2026-02-02T19:10:49.398 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction AnalyzeAndParseTableGuided\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 5059ms. StopReason: stop. Tokens(in/out): 1266/493\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table-structure analyst. Given compressed text extracted from a PDF\n",
      "    AND a visual schema describing the correct column structure (inferred from the\n",
      "    page image), parse the table data rows.\n",
      "    \n",
      "    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n",
      "    and header names):\n",
      "    {\n",
      "        \"column_count\": 22,\n",
      "        \"column_names\": [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\",\n",
      "        ],\n",
      "        \"header_levels\": 1,\n",
      "        \"notes\": \"The table contains multiple columns, some of which are specific to dates and times. Data rows may have concatenated text split unevenly in the text extraction.\",\n",
      "    }\n",
      "    \n",
      "    The compressed text below may have parsing artifacts: column headers may be\n",
      "    garbled or values from adjacent columns may be concatenated into a single\n",
      "    cell. Use the visual schema's column_names and column_count to:\n",
      "    - Correctly identify which part of the text corresponds to which column\n",
      "    - Split concatenated values when the column count in a row doesn't match\n",
      "      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n",
      "      and \"WHEAT\" if they map to separate columns)\n",
      "    - Use the visual schema's column names as the authoritative header names\n",
      "    \n",
      "    Steps:\n",
      "    1. Use the visual schema to set the correct headers (column_names →\n",
      "       headers.names, header_levels → headers.levels).\n",
      "    2. Determine the table type.\n",
      "    3. Identify any aggregation rows/columns and separate them.\n",
      "    4. Parse every data row into an array of string cell values — the array\n",
      "       length MUST equal visual_schema.column_count for each row.\n",
      "    5. If the text contains multiple table sections separated by labels or headers\n",
      "       (e.g. data grouped by category, region, time period, or any other dimension),\n",
      "       record each section label and which data rows belong to it in the notes field.\n",
      "       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n",
      "    \n",
      "    Important:\n",
      "    - Keep cell values as strings exactly as they appear (do not reformat).\n",
      "    - Exclude header rows and aggregation rows from data_rows.\n",
      "    - Include ALL data rows regardless of cell content.\n",
      "    - If a row has fewer tokens than expected columns, split concatenated\n",
      "      values to reach the correct column count.\n",
      "    - If the table has merged cells or spans, repeat the value for each\n",
      "      spanned column.\n",
      "    \n",
      "    Compressed text:\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB5345742564|QB2687807116|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TBA|TBA|\n",
      "    |Date at which nomination was|30-04-2025|30-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t08:14:00 PM\t08:14:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t02-05-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t02:30:00 PM\t02:30:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|01-12-2025|15-11-2025|\n",
      "    |Time of ETA of Ship From|04:04:00 PM|04:04:00 PM|\n",
      "    |Date of ETA of Ship To|15-12-2025|30-11-2025|\n",
      "    |Time of ETA of Ship To|04:05:00 PM|04:04:00 PM|\n",
      "    \n",
      "    Date ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Date of ETD of Ship\n",
      "    \n",
      "    Time of ETD of Ship\n",
      "    \n",
      "    |Exporter|ADM Trading Australia Pty|ADM Trading Australia Pty|\n",
      "    |---|---|---|\n",
      "    ||Ltd|Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Chickpeas|QBT Chickpeas|\n",
      "    \n",
      "    \"Loading \"\"commenced\"\" or\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\n",
      "    \n",
      "    Time Loading Completed\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \n",
      "    AggregationType\n",
      "    ----\n",
      "    - Total\n",
      "    - Sum\n",
      "    - Min\n",
      "    - Max\n",
      "    - Average\n",
      "    - Count\n",
      "    - None\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      table_type: 'FlatHeader' or 'HierarchicalHeader' or 'PivotedTable' or 'TransposedTable' or 'Unknown',\n",
      "      headers: {\n",
      "        // Number of header levels (1 for flat, >1 for hierarchical)\n",
      "        levels: int,\n",
      "        // Header names per level, outer = level, inner = columns\n",
      "        names: [\n",
      "          string[]\n",
      "        ],\n",
      "      },\n",
      "      // Present only if the table contains aggregation rows/columns\n",
      "      aggregations: {\n",
      "        type: AggregationType,\n",
      "        // 'row' or 'column' — the axis along which aggregation runs\n",
      "        axis: string,\n",
      "        // Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\n",
      "        labels: string[],\n",
      "      } or null,\n",
      "      // All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\n",
      "      data_rows: [\n",
      "        string[]\n",
      "      ],\n",
      "      // Any caveats or observations about the table structure\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB5345742564\",\n",
      "          \"TBA\",\n",
      "          \"30-04-2025\",\n",
      "          \"08:14:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"01-12-2025\",\n",
      "          \"04:04:00 PM\",\n",
      "          \"15-12-2025\",\n",
      "          \"04:05:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"ADM Trading Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB2687807116\",\n",
      "          \"TBA\",\n",
      "          \"30-04-2025\",\n",
      "          \"08:14:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"15-11-2025\",\n",
      "          \"04:04:00 PM\",\n",
      "          \"30-11-2025\",\n",
      "          \"04:04:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"ADM Trading Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class ParsedTable)---\u001b[0m\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB5345742564\",\n",
      "          \"TBA\",\n",
      "          \"30-04-2025\",\n",
      "          \"08:14:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"01-12-2025\",\n",
      "          \"04:04:00 PM\",\n",
      "          \"15-12-2025\",\n",
      "          \"04:05:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"ADM Trading Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB2687807116\",\n",
      "          \"TBA\",\n",
      "          \"30-04-2025\",\n",
      "          \"08:14:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"15-11-2025\",\n",
      "          \"04:04:00 PM\",\n",
      "          \"30-11-2025\",\n",
      "          \"04:04:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"ADM Trading Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "2026-02-02T19:10:50.357 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction AnalyzeAndParseTableGuided\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 6018ms. StopReason: stop. Tokens(in/out): 1253/484\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table-structure analyst. Given compressed text extracted from a PDF\n",
      "    AND a visual schema describing the correct column structure (inferred from the\n",
      "    page image), parse the table data rows.\n",
      "    \n",
      "    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n",
      "    and header names):\n",
      "    {\n",
      "        \"column_count\": 22,\n",
      "        \"column_names\": [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date Nomination Received\",\n",
      "            \"Time Nomination Received\",\n",
      "            \"Date Nomination Accepted\",\n",
      "            \"Time Nomination Accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity (tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading Status\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\",\n",
      "        ],\n",
      "        \"header_levels\": 1,\n",
      "        \"notes\": \"The table has clear header labels with no visible merging or stacked headers. However, some column headers are represented in multiple lines in the image.\",\n",
      "    }\n",
      "    \n",
      "    The compressed text below may have parsing artifacts: column headers may be\n",
      "    garbled or values from adjacent columns may be concatenated into a single\n",
      "    cell. Use the visual schema's column_names and column_count to:\n",
      "    - Correctly identify which part of the text corresponds to which column\n",
      "    - Split concatenated values when the column count in a row doesn't match\n",
      "      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n",
      "      and \"WHEAT\" if they map to separate columns)\n",
      "    - Use the visual schema's column names as the authoritative header names\n",
      "    \n",
      "    Steps:\n",
      "    1. Use the visual schema to set the correct headers (column_names →\n",
      "       headers.names, header_levels → headers.levels).\n",
      "    2. Determine the table type.\n",
      "    3. Identify any aggregation rows/columns and separate them.\n",
      "    4. Parse every data row into an array of string cell values — the array\n",
      "       length MUST equal visual_schema.column_count for each row.\n",
      "    5. If the text contains multiple table sections separated by labels or headers\n",
      "       (e.g. data grouped by category, region, time period, or any other dimension),\n",
      "       record each section label and which data rows belong to it in the notes field.\n",
      "       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n",
      "    \n",
      "    Important:\n",
      "    - Keep cell values as strings exactly as they appear (do not reformat).\n",
      "    - Exclude header rows and aggregation rows from data_rows.\n",
      "    - Include ALL data rows regardless of cell content.\n",
      "    - If a row has fewer tokens than expected columns, split concatenated\n",
      "      values to reach the correct column count.\n",
      "    - If the table has merged cells or spans, repeat the value for each\n",
      "      spanned column.\n",
      "    \n",
      "    Compressed text:\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB3582536041|QB1566785655|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TBA|TBA|\n",
      "    |Date at which nomination was|29-04-2025|30-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t01:00:00 PM\t08:14:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t02-05-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t02:59:00 PM\t02:30:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|15-12-2025|01-01-2026|\n",
      "    |Time of ETA of Ship From|04:02:00 PM|04:05:00 PM|\n",
      "    |Date of ETA of Ship To|30-12-2025|15-01-2026|\n",
      "    |Time of ETA of Ship To|04:03:00 PM|04:06:00 PM|\n",
      "    \n",
      "    Date ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Date of ETD of Ship\n",
      "    \n",
      "    Time of ETD of Ship\n",
      "    \n",
      "    |Exporter|Louis Dreyfus Company|ADM Trading Australia Pty|\n",
      "    |---|---|---|\n",
      "    ||Grains Australia Pty Ltd|Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Chickpeas|QBT Chickpeas|\n",
      "    \n",
      "    \"Loading \"\"commenced\"\" or\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\n",
      "    \n",
      "    Time Loading Completed\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \n",
      "    AggregationType\n",
      "    ----\n",
      "    - Total\n",
      "    - Sum\n",
      "    - Min\n",
      "    - Max\n",
      "    - Average\n",
      "    - Count\n",
      "    - None\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      table_type: 'FlatHeader' or 'HierarchicalHeader' or 'PivotedTable' or 'TransposedTable' or 'Unknown',\n",
      "      headers: {\n",
      "        // Number of header levels (1 for flat, >1 for hierarchical)\n",
      "        levels: int,\n",
      "        // Header names per level, outer = level, inner = columns\n",
      "        names: [\n",
      "          string[]\n",
      "        ],\n",
      "      },\n",
      "      // Present only if the table contains aggregation rows/columns\n",
      "      aggregations: {\n",
      "        type: AggregationType,\n",
      "        // 'row' or 'column' — the axis along which aggregation runs\n",
      "        axis: string,\n",
      "        // Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\n",
      "        labels: string[],\n",
      "      } or null,\n",
      "      // All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\n",
      "      data_rows: [\n",
      "        string[]\n",
      "      ],\n",
      "      // Any caveats or observations about the table structure\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date Nomination Received\",\n",
      "            \"Time Nomination Received\",\n",
      "            \"Date Nomination Accepted\",\n",
      "            \"Time Nomination Accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity (tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading Status\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB3582536041\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"15-12-2025\",\n",
      "          \"04:02:00 PM\",\n",
      "          \"30-12-2025\",\n",
      "          \"04:03:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Grains Australia Pty Ltd\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB1566785655\",\n",
      "          \"TBA\",\n",
      "          \"30-04-2025\",\n",
      "          \"08:14:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"01-01-2026\",\n",
      "          \"04:05:00 PM\",\n",
      "          \"15-01-2026\",\n",
      "          \"04:06:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"ADM Trading Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class ParsedTable)---\u001b[0m\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date Nomination Received\",\n",
      "            \"Time Nomination Received\",\n",
      "            \"Date Nomination Accepted\",\n",
      "            \"Time Nomination Accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity (tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading Status\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB3582536041\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"15-12-2025\",\n",
      "          \"04:02:00 PM\",\n",
      "          \"30-12-2025\",\n",
      "          \"04:03:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Grains Australia Pty Ltd\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB1566785655\",\n",
      "          \"TBA\",\n",
      "          \"30-04-2025\",\n",
      "          \"08:14:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"01-01-2026\",\n",
      "          \"04:05:00 PM\",\n",
      "          \"15-01-2026\",\n",
      "          \"04:06:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"ADM Trading Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "2026-02-02T19:10:50.565 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction AnalyzeAndParseTableGuided\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 6225ms. StopReason: stop. Tokens(in/out): 1370/619\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table-structure analyst. Given compressed text extracted from a PDF\n",
      "    AND a visual schema describing the correct column structure (inferred from the\n",
      "    page image), parse the table data rows.\n",
      "    \n",
      "    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n",
      "    and header names):\n",
      "    {\n",
      "        \"column_count\": 21,\n",
      "        \"column_names\": [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "        ],\n",
      "        \"header_levels\": 1,\n",
      "        \"notes\": \"The headers are complex and some are repeated in multiple lines in the compressed text, such as date and time of events. Some might be missed due to narrow spacing. Ensure correct association of date and time with events.\",\n",
      "    }\n",
      "    \n",
      "    The compressed text below may have parsing artifacts: column headers may be\n",
      "    garbled or values from adjacent columns may be concatenated into a single\n",
      "    cell. Use the visual schema's column_names and column_count to:\n",
      "    - Correctly identify which part of the text corresponds to which column\n",
      "    - Split concatenated values when the column count in a row doesn't match\n",
      "      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n",
      "      and \"WHEAT\" if they map to separate columns)\n",
      "    - Use the visual schema's column names as the authoritative header names\n",
      "    \n",
      "    Steps:\n",
      "    1. Use the visual schema to set the correct headers (column_names →\n",
      "       headers.names, header_levels → headers.levels).\n",
      "    2. Determine the table type.\n",
      "    3. Identify any aggregation rows/columns and separate them.\n",
      "    4. Parse every data row into an array of string cell values — the array\n",
      "       length MUST equal visual_schema.column_count for each row.\n",
      "    5. If the text contains multiple table sections separated by labels or headers\n",
      "       (e.g. data grouped by category, region, time period, or any other dimension),\n",
      "       record each section label and which data rows belong to it in the notes field.\n",
      "       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n",
      "    \n",
      "    Important:\n",
      "    - Keep cell values as strings exactly as they appear (do not reformat).\n",
      "    - Exclude header rows and aggregation rows from data_rows.\n",
      "    - Include ALL data rows regardless of cell content.\n",
      "    - If a row has fewer tokens than expected columns, split concatenated\n",
      "      values to reach the correct column count.\n",
      "    - If the table has merged cells or spans, repeat the value for each\n",
      "      spanned column.\n",
      "    \n",
      "    Compressed text:\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB0357578736|QB7412357677|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TOMINI OROSHI|UBC TAKORADI|\n",
      "    |Date at which nomination was|29-05-2025|16-05-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t02:19:00 PM\t05:41:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t29-05-2025\t16-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t07:06:00 PM\t08:26:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|16-06-2025|01-06-2025|\n",
      "    |Time of ETA of Ship From|11:57:00 AM|11:56:00 AM|\n",
      "    |Date of ETA of Ship To|22-06-2025|15-06-2025|\n",
      "    |Time of ETA of Ship To|11:57:00 AM|11:56:00 AM|\n",
      "    |Date ETA of Grain Loading|19-06-2025|05-06-2025|\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\t01:28:00 PM\t11:41:00 AM\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    |Date of ETD of Ship|22-06-2025|07-06-2025|\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship|04:30:00 AM|07:00:00 PM|\n",
      "    |Exporter|Wilmar Trading Australia|Wilmar Trading Australia|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Sorghum|QBT Sorghum|\n",
      "    |\"Loading \"\"commenced\"\" or|Completed|Completed|\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\t21-06-2025\t07-06-2025\n",
      "    \n",
      "    Time Loading Completed\t08:30:00 PM\t02:48:00 PM\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \n",
      "    AggregationType\n",
      "    ----\n",
      "    - Total\n",
      "    - Sum\n",
      "    - Min\n",
      "    - Max\n",
      "    - Average\n",
      "    - Count\n",
      "    - None\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      table_type: 'FlatHeader' or 'HierarchicalHeader' or 'PivotedTable' or 'TransposedTable' or 'Unknown',\n",
      "      headers: {\n",
      "        // Number of header levels (1 for flat, >1 for hierarchical)\n",
      "        levels: int,\n",
      "        // Header names per level, outer = level, inner = columns\n",
      "        names: [\n",
      "          string[]\n",
      "        ],\n",
      "      },\n",
      "      // Present only if the table contains aggregation rows/columns\n",
      "      aggregations: {\n",
      "        type: AggregationType,\n",
      "        // 'row' or 'column' — the axis along which aggregation runs\n",
      "        axis: string,\n",
      "        // Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\n",
      "        labels: string[],\n",
      "      } or null,\n",
      "      // All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\n",
      "      data_rows: [\n",
      "        string[]\n",
      "      ],\n",
      "      // Any caveats or observations about the table structure\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB0357578736\", \n",
      "          \"TOMINI OROSHI\", \n",
      "          \"29-05-2025\", \n",
      "          \"02:19:00 PM\", \n",
      "          \"29-05-2025\", \n",
      "          \"07:06:00 PM\",\n",
      "          \"Brisbane\", \n",
      "          \"16-06-2025\", \n",
      "          \"11:57:00 AM\", \n",
      "          \"22-06-2025\", \n",
      "          \"11:57:00 AM\", \n",
      "          \"19-06-2025\", \n",
      "          \"01:28:00 PM\", \n",
      "          \"22-06-2025\", \n",
      "          \"04:30:00 AM\", \n",
      "          \"Wilmar Trading Australia\", \n",
      "          \"30,000\", \n",
      "          \"QBT Sorghum\", \n",
      "          \"Completed\", \n",
      "          \"21-06-2025\", \n",
      "          \"08:30:00 PM\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB7412357677\", \n",
      "          \"UBC TAKORADI\", \n",
      "          \"16-05-2025\", \n",
      "          \"05:41:00 PM\", \n",
      "          \"16-05-2025\", \n",
      "          \"08:26:00 PM\",\n",
      "          \"Brisbane\", \n",
      "          \"01-06-2025\", \n",
      "          \"11:56:00 AM\", \n",
      "          \"15-06-2025\", \n",
      "          \"11:56:00 AM\", \n",
      "          \"05-06-2025\", \n",
      "          \"11:41:00 AM\", \n",
      "          \"07-06-2025\", \n",
      "          \"07:00:00 PM\", \n",
      "          \"Wilmar Trading Australia\", \n",
      "          \"30,000\", \n",
      "          \"QBT Sorghum\", \n",
      "          \"Completed\", \n",
      "          \"07-06-2025\", \n",
      "          \"02:48:00 PM\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class ParsedTable)---\u001b[0m\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB0357578736\",\n",
      "          \"TOMINI OROSHI\",\n",
      "          \"29-05-2025\",\n",
      "          \"02:19:00 PM\",\n",
      "          \"29-05-2025\",\n",
      "          \"07:06:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"16-06-2025\",\n",
      "          \"11:57:00 AM\",\n",
      "          \"22-06-2025\",\n",
      "          \"11:57:00 AM\",\n",
      "          \"19-06-2025\",\n",
      "          \"01:28:00 PM\",\n",
      "          \"22-06-2025\",\n",
      "          \"04:30:00 AM\",\n",
      "          \"Wilmar Trading Australia\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"21-06-2025\",\n",
      "          \"08:30:00 PM\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB7412357677\",\n",
      "          \"UBC TAKORADI\",\n",
      "          \"16-05-2025\",\n",
      "          \"05:41:00 PM\",\n",
      "          \"16-05-2025\",\n",
      "          \"08:26:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"01-06-2025\",\n",
      "          \"11:56:00 AM\",\n",
      "          \"15-06-2025\",\n",
      "          \"11:56:00 AM\",\n",
      "          \"05-06-2025\",\n",
      "          \"11:41:00 AM\",\n",
      "          \"07-06-2025\",\n",
      "          \"07:00:00 PM\",\n",
      "          \"Wilmar Trading Australia\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"07-06-2025\",\n",
      "          \"02:48:00 PM\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "2026-02-02T19:10:50.957 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction AnalyzeAndParseTableGuided\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 6616ms. StopReason: stop. Tokens(in/out): 1330/574\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table-structure analyst. Given compressed text extracted from a PDF\n",
      "    AND a visual schema describing the correct column structure (inferred from the\n",
      "    page image), parse the table data rows.\n",
      "    \n",
      "    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n",
      "    and header names):\n",
      "    {\n",
      "        \"column_count\": 22,\n",
      "        \"column_names\": [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading commenced or completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\",\n",
      "        ],\n",
      "        \"header_levels\": 1,\n",
      "        \"notes\": \"Some column headers have multiline descriptions. The layout suggests merged cells in the physical table, which might not be evident in the compressed text. Text also shows signs of being split across lines for clarity.\",\n",
      "    }\n",
      "    \n",
      "    The compressed text below may have parsing artifacts: column headers may be\n",
      "    garbled or values from adjacent columns may be concatenated into a single\n",
      "    cell. Use the visual schema's column_names and column_count to:\n",
      "    - Correctly identify which part of the text corresponds to which column\n",
      "    - Split concatenated values when the column count in a row doesn't match\n",
      "      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n",
      "      and \"WHEAT\" if they map to separate columns)\n",
      "    - Use the visual schema's column names as the authoritative header names\n",
      "    \n",
      "    Steps:\n",
      "    1. Use the visual schema to set the correct headers (column_names →\n",
      "       headers.names, header_levels → headers.levels).\n",
      "    2. Determine the table type.\n",
      "    3. Identify any aggregation rows/columns and separate them.\n",
      "    4. Parse every data row into an array of string cell values — the array\n",
      "       length MUST equal visual_schema.column_count for each row.\n",
      "    5. If the text contains multiple table sections separated by labels or headers\n",
      "       (e.g. data grouped by category, region, time period, or any other dimension),\n",
      "       record each section label and which data rows belong to it in the notes field.\n",
      "       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n",
      "    \n",
      "    Important:\n",
      "    - Keep cell values as strings exactly as they appear (do not reformat).\n",
      "    - Exclude header rows and aggregation rows from data_rows.\n",
      "    - Include ALL data rows regardless of cell content.\n",
      "    - If a row has fewer tokens than expected columns, split concatenated\n",
      "      values to reach the correct column count.\n",
      "    - If the table has merged cells or spans, repeat the value for each\n",
      "      spanned column.\n",
      "    \n",
      "    Compressed text:\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB7157365064|QB5815500230|\n",
      "    |---|---|---|\n",
      "    |Name of ship|SOUTHGATE|TBA|\n",
      "    |Date at which nomination was|16-04-2025|29-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t08:05:00 PM\t01:00:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t17-04-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t05:36:00 AM\t02:59:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|05-05-2025|10-11-2025|\n",
      "    |Time of ETA of Ship From|01:40:00 PM|04:00:00 PM|\n",
      "    |Date of ETA of Ship To|12-05-2025|20-11-2025|\n",
      "    |Time of ETA of Ship To|01:40:00 PM|04:00:00 PM|\n",
      "    |Date ETA of Grain Loading|09-05-2025||\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading Commencement: 10:47:00 AM\n",
      "    \n",
      "    |Date of ETD of Ship|13-05-2025||\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship|09:00:00 AM||\n",
      "    |Exporter|Wilmar Trading Australia|Louis Dreyfus Company|\n",
      "    \n",
      "    Grains Australia Pty Ltd\n",
      "    \n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |---|---|---|\n",
      "    |Commodity|QBT Sorghum|QBT Chickpeas|\n",
      "    |\"Loading \"\"commenced\"\" or|Completed||\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed: 13-05-2025\n",
      "    Time Loading Completed Notes: 04:35:00 AM\n",
      "    Last updated on:: 30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \n",
      "    AggregationType\n",
      "    ----\n",
      "    - Total\n",
      "    - Sum\n",
      "    - Min\n",
      "    - Max\n",
      "    - Average\n",
      "    - Count\n",
      "    - None\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      table_type: 'FlatHeader' or 'HierarchicalHeader' or 'PivotedTable' or 'TransposedTable' or 'Unknown',\n",
      "      headers: {\n",
      "        // Number of header levels (1 for flat, >1 for hierarchical)\n",
      "        levels: int,\n",
      "        // Header names per level, outer = level, inner = columns\n",
      "        names: [\n",
      "          string[]\n",
      "        ],\n",
      "      },\n",
      "      // Present only if the table contains aggregation rows/columns\n",
      "      aggregations: {\n",
      "        type: AggregationType,\n",
      "        // 'row' or 'column' — the axis along which aggregation runs\n",
      "        axis: string,\n",
      "        // Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\n",
      "        labels: string[],\n",
      "      } or null,\n",
      "      // All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\n",
      "      data_rows: [\n",
      "        string[]\n",
      "      ],\n",
      "      // Any caveats or observations about the table structure\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading commenced or completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB7157365064\",\n",
      "          \"SOUTHGATE\",\n",
      "          \"16-04-2025\",\n",
      "          \"08:05:00 PM\",\n",
      "          \"17-04-2025\",\n",
      "          \"05:36:00 AM\",\n",
      "          \"Brisbane\",\n",
      "          \"05-05-2025\",\n",
      "          \"01:40:00 PM\",\n",
      "          \"12-05-2025\",\n",
      "          \"01:40:00 PM\",\n",
      "          \"09-05-2025\",\n",
      "          \"10:47:00 AM\",\n",
      "          \"13-05-2025\",\n",
      "          \"09:00:00 AM\",\n",
      "          \"Wilmar Trading Australia\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"13-05-2025\",\n",
      "          \"04:35:00 AM\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB5815500230\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"10-11-2025\",\n",
      "          \"04:00:00 PM\",\n",
      "          \"20-11-2025\",\n",
      "          \"04:00:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company Grains Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class ParsedTable)---\u001b[0m\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading commenced or completed\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB7157365064\",\n",
      "          \"SOUTHGATE\",\n",
      "          \"16-04-2025\",\n",
      "          \"08:05:00 PM\",\n",
      "          \"17-04-2025\",\n",
      "          \"05:36:00 AM\",\n",
      "          \"Brisbane\",\n",
      "          \"05-05-2025\",\n",
      "          \"01:40:00 PM\",\n",
      "          \"12-05-2025\",\n",
      "          \"01:40:00 PM\",\n",
      "          \"09-05-2025\",\n",
      "          \"10:47:00 AM\",\n",
      "          \"13-05-2025\",\n",
      "          \"09:00:00 AM\",\n",
      "          \"Wilmar Trading Australia\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"13-05-2025\",\n",
      "          \"04:35:00 AM\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB5815500230\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"10-11-2025\",\n",
      "          \"04:00:00 PM\",\n",
      "          \"20-11-2025\",\n",
      "          \"04:00:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company Grains Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "2026-02-02T19:10:50.958 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction AnalyzeAndParseTableGuided\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 6618ms. StopReason: stop. Tokens(in/out): 1325/579\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table-structure analyst. Given compressed text extracted from a PDF\n",
      "    AND a visual schema describing the correct column structure (inferred from the\n",
      "    page image), parse the table data rows.\n",
      "    \n",
      "    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n",
      "    and header names):\n",
      "    {\n",
      "        \"column_count\": 22,\n",
      "        \"column_names\": [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\",\n",
      "        ],\n",
      "        \"header_levels\": 1,\n",
      "        \"notes\": \"Some headers span multiple lines in text, such as 'Date at which nomination was received'. Compressed text suggests some values may be missing or concatenated, but table structure is maintained.\",\n",
      "    }\n",
      "    \n",
      "    The compressed text below may have parsing artifacts: column headers may be\n",
      "    garbled or values from adjacent columns may be concatenated into a single\n",
      "    cell. Use the visual schema's column_names and column_count to:\n",
      "    - Correctly identify which part of the text corresponds to which column\n",
      "    - Split concatenated values when the column count in a row doesn't match\n",
      "      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n",
      "      and \"WHEAT\" if they map to separate columns)\n",
      "    - Use the visual schema's column names as the authoritative header names\n",
      "    \n",
      "    Steps:\n",
      "    1. Use the visual schema to set the correct headers (column_names →\n",
      "       headers.names, header_levels → headers.levels).\n",
      "    2. Determine the table type.\n",
      "    3. Identify any aggregation rows/columns and separate them.\n",
      "    4. Parse every data row into an array of string cell values — the array\n",
      "       length MUST equal visual_schema.column_count for each row.\n",
      "    5. If the text contains multiple table sections separated by labels or headers\n",
      "       (e.g. data grouped by category, region, time period, or any other dimension),\n",
      "       record each section label and which data rows belong to it in the notes field.\n",
      "       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n",
      "    \n",
      "    Important:\n",
      "    - Keep cell values as strings exactly as they appear (do not reformat).\n",
      "    - Exclude header rows and aggregation rows from data_rows.\n",
      "    - Include ALL data rows regardless of cell content.\n",
      "    - If a row has fewer tokens than expected columns, split concatenated\n",
      "      values to reach the correct column count.\n",
      "    - If the table has merged cells or spans, repeat the value for each\n",
      "      spanned column.\n",
      "    \n",
      "    Compressed text:\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB2061036115|QB3126604877|\n",
      "    |---|---|---|\n",
      "    |Name of ship|DARYA DIYA|MH ADAGIO|\n",
      "    |Date at which nomination was|04-07-2025|03-06-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t03:17:00 PM\t02:23:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t04-07-2025\t03-06-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t03:30:00 PM\t02:36:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|15-09-2025|21-07-2025|\n",
      "    |Time of ETA of Ship From|02:53:00 PM|11:43:00 AM|\n",
      "    |Date of ETA of Ship To|30-09-2025|31-07-2025|\n",
      "    |Time of ETA of Ship To|02:54:00 PM|11:43:00 AM|\n",
      "    |Date ETA of Grain Loading||24-07-2025|\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading Commencement: 12:55:00 AM\n",
      "    \n",
      "    |Date of ETD of Ship||26-07-2025|\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship||11:00:00 AM|\n",
      "    |Exporter|Arrow Commodities Pty Ltd|Arrow Commodities Pty Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Wheat|QBT Wheat|\n",
      "    |\"Loading \"\"commenced\"\" or||Completed|\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed: 25-07-2025\n",
      "    Time Loading Completed Notes: 09:13:00 PM\n",
      "    Last updated on:: 30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \n",
      "    AggregationType\n",
      "    ----\n",
      "    - Total\n",
      "    - Sum\n",
      "    - Min\n",
      "    - Max\n",
      "    - Average\n",
      "    - Count\n",
      "    - None\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      table_type: 'FlatHeader' or 'HierarchicalHeader' or 'PivotedTable' or 'TransposedTable' or 'Unknown',\n",
      "      headers: {\n",
      "        // Number of header levels (1 for flat, >1 for hierarchical)\n",
      "        levels: int,\n",
      "        // Header names per level, outer = level, inner = columns\n",
      "        names: [\n",
      "          string[]\n",
      "        ],\n",
      "      },\n",
      "      // Present only if the table contains aggregation rows/columns\n",
      "      aggregations: {\n",
      "        type: AggregationType,\n",
      "        // 'row' or 'column' �� the axis along which aggregation runs\n",
      "        axis: string,\n",
      "        // Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\n",
      "        labels: string[],\n",
      "      } or null,\n",
      "      // All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\n",
      "      data_rows: [\n",
      "        string[]\n",
      "      ],\n",
      "      // Any caveats or observations about the table structure\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB2061036115\",\n",
      "          \"DARYA DIYA\",\n",
      "          \"04-07-2025\",\n",
      "          \"03:17:00 PM\",\n",
      "          \"04-07-2025\",\n",
      "          \"03:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"15-09-2025\",\n",
      "          \"02:53:00 PM\",\n",
      "          \"30-09-2025\",\n",
      "          \"02:54:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Arrow Commodities Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Wheat\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB3126604877\",\n",
      "          \"MH ADAGIO\",\n",
      "          \"03-06-2025\",\n",
      "          \"02:23:00 PM\",\n",
      "          \"03-06-2025\",\n",
      "          \"02:36:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"21-07-2025\",\n",
      "          \"11:43:00 AM\",\n",
      "          \"31-07-2025\",\n",
      "          \"11:43:00 AM\",\n",
      "          \"24-07-2025\",\n",
      "          \"12:55:00 AM\",\n",
      "          \"26-07-2025\",\n",
      "          \"11:00:00 AM\",\n",
      "          \"Arrow Commodities Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Wheat\",\n",
      "          \"Completed\",\n",
      "          \"25-07-2025\",\n",
      "          \"09:13:00 PM\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class ParsedTable)---\u001b[0m\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB2061036115\",\n",
      "          \"DARYA DIYA\",\n",
      "          \"04-07-2025\",\n",
      "          \"03:17:00 PM\",\n",
      "          \"04-07-2025\",\n",
      "          \"03:30:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"15-09-2025\",\n",
      "          \"02:53:00 PM\",\n",
      "          \"30-09-2025\",\n",
      "          \"02:54:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Arrow Commodities Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Wheat\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB3126604877\",\n",
      "          \"MH ADAGIO\",\n",
      "          \"03-06-2025\",\n",
      "          \"02:23:00 PM\",\n",
      "          \"03-06-2025\",\n",
      "          \"02:36:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"21-07-2025\",\n",
      "          \"11:43:00 AM\",\n",
      "          \"31-07-2025\",\n",
      "          \"11:43:00 AM\",\n",
      "          \"24-07-2025\",\n",
      "          \"12:55:00 AM\",\n",
      "          \"26-07-2025\",\n",
      "          \"11:00:00 AM\",\n",
      "          \"Arrow Commodities Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Wheat\",\n",
      "          \"Completed\",\n",
      "          \"25-07-2025\",\n",
      "          \"09:13:00 PM\",\n",
      "          \"Last updated on:: 30-09-2025 06:00 AM\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "2026-02-02T19:10:52.494 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction AnalyzeAndParseTableGuided\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 8154ms. StopReason: stop. Tokens(in/out): 1270/516\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table-structure analyst. Given compressed text extracted from a PDF\n",
      "    AND a visual schema describing the correct column structure (inferred from the\n",
      "    page image), parse the table data rows.\n",
      "    \n",
      "    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n",
      "    and header names):\n",
      "    {\n",
      "        \"column_count\": 21,\n",
      "        \"column_names\": [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity (tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\",\n",
      "        ],\n",
      "        \"header_levels\": 1,\n",
      "        \"notes\": \"The table consists of multiple fields, some with two lines of information. For instance, 'Exporter' includes two separate lines for company and subsidiary. Loading and completion times are additional columns.\",\n",
      "    }\n",
      "    \n",
      "    The compressed text below may have parsing artifacts: column headers may be\n",
      "    garbled or values from adjacent columns may be concatenated into a single\n",
      "    cell. Use the visual schema's column_names and column_count to:\n",
      "    - Correctly identify which part of the text corresponds to which column\n",
      "    - Split concatenated values when the column count in a row doesn't match\n",
      "      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n",
      "      and \"WHEAT\" if they map to separate columns)\n",
      "    - Use the visual schema's column names as the authoritative header names\n",
      "    \n",
      "    Steps:\n",
      "    1. Use the visual schema to set the correct headers (column_names →\n",
      "       headers.names, header_levels → headers.levels).\n",
      "    2. Determine the table type.\n",
      "    3. Identify any aggregation rows/columns and separate them.\n",
      "    4. Parse every data row into an array of string cell values — the array\n",
      "       length MUST equal visual_schema.column_count for each row.\n",
      "    5. If the text contains multiple table sections separated by labels or headers\n",
      "       (e.g. data grouped by category, region, time period, or any other dimension),\n",
      "       record each section label and which data rows belong to it in the notes field.\n",
      "       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n",
      "    \n",
      "    Important:\n",
      "    - Keep cell values as strings exactly as they appear (do not reformat).\n",
      "    - Exclude header rows and aggregation rows from data_rows.\n",
      "    - Include ALL data rows regardless of cell content.\n",
      "    - If a row has fewer tokens than expected columns, split concatenated\n",
      "      values to reach the correct column count.\n",
      "    - If the table has merged cells or spans, repeat the value for each\n",
      "      spanned column.\n",
      "    \n",
      "    Compressed text:\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB2771655637|QB1541470610|\n",
      "    |---|---|---|\n",
      "    |Name of ship|TBA|TBA|\n",
      "    |Date at which nomination was|29-04-2025|29-04-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t01:00:00 PM\t01:00:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t02-05-2025\t02-05-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t02:59:00 PM\t02:59:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|21-11-2025|01-12-2025|\n",
      "    |Time of ETA of Ship From|04:01:00 PM|04:02:00 PM|\n",
      "    |Date of ETA of Ship To|30-11-2025|15-12-2025|\n",
      "    |Time of ETA of Ship To|04:01:00 PM|04:02:00 PM|\n",
      "    \n",
      "    Date ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Date of ETD of Ship\n",
      "    \n",
      "    Time of ETD of Ship\n",
      "    \n",
      "    |Exporter|Louis Dreyfus Company|Louis Dreyfus Company|\n",
      "    |---|---|---|\n",
      "    ||Grains Australia Pty Ltd|Grains Australia Pty Ltd|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Chickpeas|QBT Chickpeas|\n",
      "    \n",
      "    \"Loading \"\"commenced\"\" or\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\n",
      "    \n",
      "    Time Loading Completed\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \n",
      "    AggregationType\n",
      "    ----\n",
      "    - Total\n",
      "    - Sum\n",
      "    - Min\n",
      "    - Max\n",
      "    - Average\n",
      "    - Count\n",
      "    - None\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      table_type: 'FlatHeader' or 'HierarchicalHeader' or 'PivotedTable' or 'TransposedTable' or 'Unknown',\n",
      "      headers: {\n",
      "        // Number of header levels (1 for flat, >1 for hierarchical)\n",
      "        levels: int,\n",
      "        // Header names per level, outer = level, inner = columns\n",
      "        names: [\n",
      "          string[]\n",
      "        ],\n",
      "      },\n",
      "      // Present only if the table contains aggregation rows/columns\n",
      "      aggregations: {\n",
      "        type: AggregationType,\n",
      "        // 'row' or 'column' — the axis along which aggregation runs\n",
      "        axis: string,\n",
      "        // Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\n",
      "        labels: string[],\n",
      "      } or null,\n",
      "      // All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\n",
      "      data_rows: [\n",
      "        string[]\n",
      "      ],\n",
      "      // Any caveats or observations about the table structure\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity (tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB2771655637\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"21-11-2025\",\n",
      "          \"04:01:00 PM\",\n",
      "          \"30-11-2025\",\n",
      "          \"04:01:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB1541470610\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"01-12-2025\",\n",
      "          \"04:02:00 PM\",\n",
      "          \"15-12-2025\",\n",
      "          \"04:02:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": \"The table text implied multiple fields appeared in one section, specifying two lines of information may apply to 'Exporter'. No additional sections are present.\"\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class ParsedTable)---\u001b[0m\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity (tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB2771655637\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"21-11-2025\",\n",
      "          \"04:01:00 PM\",\n",
      "          \"30-11-2025\",\n",
      "          \"04:01:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB1541470610\",\n",
      "          \"TBA\",\n",
      "          \"29-04-2025\",\n",
      "          \"01:00:00 PM\",\n",
      "          \"02-05-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"01-12-2025\",\n",
      "          \"04:02:00 PM\",\n",
      "          \"15-12-2025\",\n",
      "          \"04:02:00 PM\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"30,000\",\n",
      "          \"QBT Chickpeas\",\n",
      "          \"\",\n",
      "          \"\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": \"The table text implied multiple fields appeared in one section, specifying two lines of information may apply to 'Exporter'. No additional sections are present.\"\n",
      "    }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pdf_ocr.interpret:Step 1 page 1: parsed 2 data rows, 1 header levels, type=TableType.FlatHeader\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 1 headers[0]: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', '\"Loading \"\"commenced\"\" or \"\"completed\"\"\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 1 row[0] (22 cells): ['QB2061036115', 'DARYA DIYA', '04-07-2025', '03:17:00 PM', '04-07-2025', '03:30:00 PM', 'Brisbane', '15-09-2025', '02:53:00 PM', '30-09-2025', '02:54:00 PM', '', '', '', '', 'Arrow Commodities Pty Ltd', '30,000', 'QBT Wheat', '', '', '', 'Last updated on:: 30-09-2025 06:00 AM']\n",
      "INFO:pdf_ocr.interpret:Step 1 page 2: parsed 2 data rows, 1 header levels, type=TableType.FlatHeader\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 2 headers[0]: ['Unique Slot Reference Number', 'Name of Ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', '\"Loading \"commenced\" or \"completed\"\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 2 row[0] (22 cells): ['QB1148678055', 'MONOCEROS', '05-06-2025', '04:49:00 PM', '05-06-2025', '05:00:00 PM', 'Brisbane', '21-07-2025', '11:41:00 AM', '31-07-2025', '11:41:00 AM', '27-07-2025', '10:21:00 PM', '31-07-2025', '02:54:00 AM', 'Robinson Grain', '30,000', 'QBT Sorghum', 'Completed', '30-07-2025', '01:56:00 PM', '']\n",
      "INFO:pdf_ocr.interpret:Step 1 page 3: parsed 2 data rows, 1 header levels, type=TableType.FlatHeader\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 3 headers[0]: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', 'Loading \"commenced\" or \"completed\"', 'Date Loading Completed', 'Time Loading Completed']\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 3 row[0] (21 cells): ['QB0357578736', 'TOMINI OROSHI', '29-05-2025', '02:19:00 PM', '29-05-2025', '07:06:00 PM', 'Brisbane', '16-06-2025', '11:57:00 AM', '22-06-2025', '11:57:00 AM', '19-06-2025', '01:28:00 PM', '22-06-2025', '04:30:00 AM', 'Wilmar Trading Australia', '30,000', 'QBT Sorghum', 'Completed', '21-06-2025', '08:30:00 PM']\n",
      "INFO:pdf_ocr.interpret:Step 1 page 4: parsed 2 data rows, 1 header levels, type=TableType.FlatHeader\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 4 headers[0]: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', '\"Loading commenced or completed\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 4 row[0] (22 cells): ['QB7157365064', 'SOUTHGATE', '16-04-2025', '08:05:00 PM', '17-04-2025', '05:36:00 AM', 'Brisbane', '05-05-2025', '01:40:00 PM', '12-05-2025', '01:40:00 PM', '09-05-2025', '10:47:00 AM', '13-05-2025', '09:00:00 AM', 'Wilmar Trading Australia', '30,000', 'QBT Sorghum', 'Completed', '13-05-2025', '04:35:00 AM', 'Last updated on:: 30-09-2025 06:00 AM']\n",
      "INFO:pdf_ocr.interpret:Step 1 page 5: parsed 2 data rows, 1 header levels, type=TableType.FlatHeader\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 5 headers[0]: ['Unique Slot Reference Number', 'Name of Ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity (tonnes)', 'Commodity', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 5 row[0] (21 cells): ['QB2771655637', 'TBA', '29-04-2025', '01:00:00 PM', '02-05-2025', '02:59:00 PM', 'Brisbane', '21-11-2025', '04:01:00 PM', '30-11-2025', '04:01:00 PM', '', '', '', '', 'Louis Dreyfus Company\\nGrains Australia Pty Ltd', '30,000', 'QBT Chickpeas', '', '', '']\n",
      "INFO:pdf_ocr.interpret:Step 1 page 6: parsed 2 data rows, 1 header levels, type=TableType.FlatHeader\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 6 headers[0]: ['Unique Slot Reference Number', 'Name of Ship', 'Date Nomination Received', 'Time Nomination Received', 'Date Nomination Accepted', 'Time Nomination Accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity (tonnes)', 'Commodity', 'Loading Status', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 6 row[0] (22 cells): ['QB3582536041', 'TBA', '29-04-2025', '01:00:00 PM', '02-05-2025', '02:59:00 PM', 'Brisbane', '15-12-2025', '04:02:00 PM', '30-12-2025', '04:03:00 PM', '', '', '', '', 'Louis Dreyfus Company', '30,000', 'QBT Chickpeas', '', '', '', 'Grains Australia Pty Ltd']\n",
      "INFO:pdf_ocr.interpret:Step 1 page 7: parsed 2 data rows, 1 header levels, type=TableType.FlatHeader\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 7 headers[0]: ['Unique Slot Reference Number', 'Name of ship', 'Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Port', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date of ETA of Ship To', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Exporter', 'Quantity(tonnes)', 'Commodity', 'Loading \"commenced\" or \"completed\"', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "INFO:pdf_ocr.interpret:  Step 1 page 7 row[0] (22 cells): ['QB5345742564', 'TBA', '30-04-2025', '08:14:00 PM', '02-05-2025', '02:30:00 PM', 'Brisbane', '01-12-2025', '04:04:00 PM', '15-12-2025', '04:05:00 PM', '', '', '', '', 'ADM Trading Australia Pty Ltd', '30,000', 'QBT Chickpeas', '', '', '', '']\n",
      "INFO:pdf_ocr.interpret:Step 2: 7 batches from 7 pages (batch_size=20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-02T19:10:53.210 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction AnalyzeAndParseTableGuided\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 8870ms. StopReason: stop. Tokens(in/out): 1369/586\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a table-structure analyst. Given compressed text extracted from a PDF\n",
      "    AND a visual schema describing the correct column structure (inferred from the\n",
      "    page image), parse the table data rows.\n",
      "    \n",
      "    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n",
      "    and header names):\n",
      "    {\n",
      "        \"column_count\": 22,\n",
      "        \"column_names\": [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading \\\"commenced\\\" or \\\"completed\\\"\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\",\n",
      "        ],\n",
      "        \"header_levels\": 1,\n",
      "        \"notes\": \"The table has a single header level. Each column represents distinct fields as evidenced by the detailed itemization of dates and times concerning shipments and nominations. Observations around completion status are labeled in a descriptive manner.\",\n",
      "    }\n",
      "    \n",
      "    The compressed text below may have parsing artifacts: column headers may be\n",
      "    garbled or values from adjacent columns may be concatenated into a single\n",
      "    cell. Use the visual schema's column_names and column_count to:\n",
      "    - Correctly identify which part of the text corresponds to which column\n",
      "    - Split concatenated values when the column count in a row doesn't match\n",
      "      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n",
      "      and \"WHEAT\" if they map to separate columns)\n",
      "    - Use the visual schema's column names as the authoritative header names\n",
      "    \n",
      "    Steps:\n",
      "    1. Use the visual schema to set the correct headers (column_names →\n",
      "       headers.names, header_levels → headers.levels).\n",
      "    2. Determine the table type.\n",
      "    3. Identify any aggregation rows/columns and separate them.\n",
      "    4. Parse every data row into an array of string cell values — the array\n",
      "       length MUST equal visual_schema.column_count for each row.\n",
      "    5. If the text contains multiple table sections separated by labels or headers\n",
      "       (e.g. data grouped by category, region, time period, or any other dimension),\n",
      "       record each section label and which data rows belong to it in the notes field.\n",
      "       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n",
      "    \n",
      "    Important:\n",
      "    - Keep cell values as strings exactly as they appear (do not reformat).\n",
      "    - Exclude header rows and aggregation rows from data_rows.\n",
      "    - Include ALL data rows regardless of cell content.\n",
      "    - If a row has fewer tokens than expected columns, split concatenated\n",
      "      values to reach the correct column count.\n",
      "    - If the table has merged cells or spans, repeat the value for each\n",
      "      spanned column.\n",
      "    \n",
      "    Compressed text:\n",
      "    ---\n",
      "    |Unique Slot Reference Number|QB1148678055|QB5305788574|\n",
      "    |---|---|---|\n",
      "    |Name of ship|MONOCEROS|CETUS SEI|\n",
      "    |Date at which nomination was|05-06-2025|16-06-2025|\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Time at which nomination was\t04:49:00 PM\t02:59:00 PM\n",
      "    \n",
      "    received\n",
      "    \n",
      "    Date at which nomination was\t05-06-2025\t16-06-2025\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    Time at which nomination was\t05:00:00 PM\t02:59:00 PM\n",
      "    \n",
      "    accepted\n",
      "    \n",
      "    |Port|Brisbane|Brisbane|\n",
      "    |---|---|---|\n",
      "    |Date of ETA of Ship From|21-07-2025|30-06-2025|\n",
      "    |Time of ETA of Ship From|11:41:00 AM|02:59:00 PM|\n",
      "    |Date of ETA of Ship To|31-07-2025|05-07-2025|\n",
      "    |Time of ETA of Ship To|11:41:00 AM|03:00:00 PM|\n",
      "    |Date ETA of Grain Loading|27-07-2025|01-07-2025|\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    Time ETA of Grain Loading\t10:21:00 PM\t09:35:00 AM\n",
      "    \n",
      "    Commencement\n",
      "    \n",
      "    |Date of ETD of Ship|31-07-2025|03-07-2025|\n",
      "    |---|---|---|\n",
      "    |Time of ETD of Ship|02:54:00 AM|03:20:00 PM|\n",
      "    |Exporter|Robinson Grain|Wilmar Trading Australia|\n",
      "    |Quantity(tonnes)|30,000|30,000|\n",
      "    |Commodity|QBT Sorghum|QBT Sorghum|\n",
      "    |\"Loading \"\"commenced\"\" or|Completed|Completed|\n",
      "    \n",
      "    \"\"completed\"\"\"\n",
      "    \n",
      "    Date Loading Completed\t30-07-2025\t03-07-2025\n",
      "    \n",
      "    Time Loading Completed\t01:56:00 PM\t03:28:00 AM\n",
      "    \n",
      "    Notes\n",
      "    \n",
      "    Last updated on:\t30-09-2025 06:00 AM\n",
      "    ---\n",
      "    \n",
      "    AggregationType\n",
      "    ----\n",
      "    - Total\n",
      "    - Sum\n",
      "    - Min\n",
      "    - Max\n",
      "    - Average\n",
      "    - Count\n",
      "    - None\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      table_type: 'FlatHeader' or 'HierarchicalHeader' or 'PivotedTable' or 'TransposedTable' or 'Unknown',\n",
      "      headers: {\n",
      "        // Number of header levels (1 for flat, >1 for hierarchical)\n",
      "        levels: int,\n",
      "        // Header names per level, outer = level, inner = columns\n",
      "        names: [\n",
      "          string[]\n",
      "        ],\n",
      "      },\n",
      "      // Present only if the table contains aggregation rows/columns\n",
      "      aggregations: {\n",
      "        type: AggregationType,\n",
      "        // 'row' or 'column' — the axis along which aggregation runs\n",
      "        axis: string,\n",
      "        // Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\n",
      "        labels: string[],\n",
      "      } or null,\n",
      "      // All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\n",
      "      data_rows: [\n",
      "        string[]\n",
      "      ],\n",
      "      // Any caveats or observations about the table structure\n",
      "      notes: string or null,\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading \\\"commenced\\\" or \\\"completed\\\"\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB1148678055\",\n",
      "          \"MONOCEROS\",\n",
      "          \"05-06-2025\",\n",
      "          \"04:49:00 PM\",\n",
      "          \"05-06-2025\",\n",
      "          \"05:00:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"21-07-2025\",\n",
      "          \"11:41:00 AM\",\n",
      "          \"31-07-2025\",\n",
      "          \"11:41:00 AM\",\n",
      "          \"27-07-2025\",\n",
      "          \"10:21:00 PM\",\n",
      "          \"31-07-2025\",\n",
      "          \"02:54:00 AM\",\n",
      "          \"Robinson Grain\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"30-07-2025\",\n",
      "          \"01:56:00 PM\",\n",
      "          \"\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB5305788574\",\n",
      "          \"CETUS SEI\",\n",
      "          \"16-06-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"16-06-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"30-06-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"05-07-2025\",\n",
      "          \"03:00:00 PM\",\n",
      "          \"01-07-2025\",\n",
      "          \"09:35:00 AM\",\n",
      "          \"03-07-2025\",\n",
      "          \"03:20:00 PM\",\n",
      "          \"Wilmar Trading Australia\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"03-07-2025\",\n",
      "          \"03:28:00 AM\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class ParsedTable)---\u001b[0m\n",
      "    {\n",
      "      \"table_type\": \"FlatHeader\",\n",
      "      \"headers\": {\n",
      "        \"levels\": 1,\n",
      "        \"names\": [\n",
      "          [\n",
      "            \"Unique Slot Reference Number\",\n",
      "            \"Name of Ship\",\n",
      "            \"Date at which nomination was received\",\n",
      "            \"Time at which nomination was received\",\n",
      "            \"Date at which nomination was accepted\",\n",
      "            \"Time at which nomination was accepted\",\n",
      "            \"Port\",\n",
      "            \"Date of ETA of Ship From\",\n",
      "            \"Time of ETA of Ship From\",\n",
      "            \"Date of ETA of Ship To\",\n",
      "            \"Time of ETA of Ship To\",\n",
      "            \"Date ETA of Grain Loading Commencement\",\n",
      "            \"Time ETA of Grain Loading Commencement\",\n",
      "            \"Date of ETD of Ship\",\n",
      "            \"Time of ETD of Ship\",\n",
      "            \"Exporter\",\n",
      "            \"Quantity(tonnes)\",\n",
      "            \"Commodity\",\n",
      "            \"\\\"Loading \\\"commenced\\\" or \\\"completed\\\"\\\"\",\n",
      "            \"Date Loading Completed\",\n",
      "            \"Time Loading Completed\",\n",
      "            \"Notes\"\n",
      "          ]\n",
      "        ]\n",
      "      },\n",
      "      \"aggregations\": null,\n",
      "      \"data_rows\": [\n",
      "        [\n",
      "          \"QB1148678055\",\n",
      "          \"MONOCEROS\",\n",
      "          \"05-06-2025\",\n",
      "          \"04:49:00 PM\",\n",
      "          \"05-06-2025\",\n",
      "          \"05:00:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"21-07-2025\",\n",
      "          \"11:41:00 AM\",\n",
      "          \"31-07-2025\",\n",
      "          \"11:41:00 AM\",\n",
      "          \"27-07-2025\",\n",
      "          \"10:21:00 PM\",\n",
      "          \"31-07-2025\",\n",
      "          \"02:54:00 AM\",\n",
      "          \"Robinson Grain\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"30-07-2025\",\n",
      "          \"01:56:00 PM\",\n",
      "          \"\"\n",
      "        ],\n",
      "        [\n",
      "          \"QB5305788574\",\n",
      "          \"CETUS SEI\",\n",
      "          \"16-06-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"16-06-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"Brisbane\",\n",
      "          \"30-06-2025\",\n",
      "          \"02:59:00 PM\",\n",
      "          \"05-07-2025\",\n",
      "          \"03:00:00 PM\",\n",
      "          \"01-07-2025\",\n",
      "          \"09:35:00 AM\",\n",
      "          \"03-07-2025\",\n",
      "          \"03:20:00 PM\",\n",
      "          \"Wilmar Trading Australia\",\n",
      "          \"30,000\",\n",
      "          \"QBT Sorghum\",\n",
      "          \"Completed\",\n",
      "          \"03-07-2025\",\n",
      "          \"03:28:00 AM\",\n",
      "          \"\"\n",
      "        ]\n",
      "      ],\n",
      "      \"notes\": null\n",
      "    }\n",
      "2026-02-02T19:11:04.047 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction MapToCanonicalSchema\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 10803ms. StopReason: stop. Tokens(in/out): 1635/759\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a data mapper. Given a parsed table and a canonical schema, map each data row\n",
      "    to the canonical schema columns.\n",
      "    \n",
      "    Mapping rules:\n",
      "    1. Match source columns to canonical columns using name, aliases, and description.\n",
      "    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n",
      "    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n",
      "    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n",
      "    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n",
      "    6. List any source columns that could not be mapped in unmapped_columns.\n",
      "    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n",
      "       (especially when its aliases list is empty), look for its value in the\n",
      "       surrounding context:\n",
      "       - Section headers or group labels that appear above or between data groups\n",
      "       - Document title, subtitle, or metadata lines\n",
      "       - Repeated contextual values that apply to all rows in a group\n",
      "       When a value is inferred from context, apply it to ALL rows in that section.\n",
      "       The parsed_table's notes field may contain section boundary information.\n",
      "    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n",
      "       metadata explaining:\n",
      "       - Where the value came from (source)\n",
      "       - Why this mapping was chosen (rationale)\n",
      "       - How confident you are (High = direct name/alias match,\n",
      "         Medium = inferred from context with reasonable certainty,\n",
      "         Low = best guess or ambiguous)\n",
      "    9. Set metadata.model to \"openai/gpt-4o\" (it will be provided).\n",
      "    10. If the text had section labels, list them in metadata.sections_detected.\n",
      "    \n",
      "    Parsed table:\n",
      "    {\n",
      "        \"aggregations\": null,\n",
      "        \"data_rows\": [\n",
      "            [\n",
      "                \"QB2771655637\",\n",
      "                \"TBA\",\n",
      "                \"29-04-2025\",\n",
      "                \"01:00:00 PM\",\n",
      "                \"02-05-2025\",\n",
      "                \"02:59:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"21-11-2025\",\n",
      "                \"04:01:00 PM\",\n",
      "                \"30-11-2025\",\n",
      "                \"04:01:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Chickpeas\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "            ],\n",
      "            [\n",
      "                \"QB1541470610\",\n",
      "                \"TBA\",\n",
      "                \"29-04-2025\",\n",
      "                \"01:00:00 PM\",\n",
      "                \"02-05-2025\",\n",
      "                \"02:59:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"01-12-2025\",\n",
      "                \"04:02:00 PM\",\n",
      "                \"15-12-2025\",\n",
      "                \"04:02:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Chickpeas\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "            ],\n",
      "        ],\n",
      "        \"headers\": {\n",
      "            \"levels\": 1,\n",
      "            \"names\": [\n",
      "                [\n",
      "                    \"Unique Slot Reference Number\",\n",
      "                    \"Name of Ship\",\n",
      "                    \"Date at which nomination was received\",\n",
      "                    \"Time at which nomination was received\",\n",
      "                    \"Date at which nomination was accepted\",\n",
      "                    \"Time at which nomination was accepted\",\n",
      "                    \"Port\",\n",
      "                    \"Date of ETA of Ship From\",\n",
      "                    \"Time of ETA of Ship From\",\n",
      "                    \"Date of ETA of Ship To\",\n",
      "                    \"Time of ETA of Ship To\",\n",
      "                    \"Date ETA of Grain Loading Commencement\",\n",
      "                    \"Time ETA of Grain Loading Commencement\",\n",
      "                    \"Date of ETD of Ship\",\n",
      "                    \"Time of ETD of Ship\",\n",
      "                    \"Exporter\",\n",
      "                    \"Quantity (tonnes)\",\n",
      "                    \"Commodity\",\n",
      "                    \"Date Loading Completed\",\n",
      "                    \"Time Loading Completed\",\n",
      "                    \"Notes\",\n",
      "                ],\n",
      "            ],\n",
      "        },\n",
      "        \"notes\": \"The table text implied multiple fields appeared in one section, specifying two lines of information may apply to 'Exporter'. No additional sections are present.\",\n",
      "        \"table_type\": FlatHeader,\n",
      "    }\n",
      "    \n",
      "    Canonical schema:\n",
      "    {\n",
      "        \"columns\": [\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"port\",\n",
      "                ],\n",
      "                \"description\": \"Loading port name\",\n",
      "                \"name\": \"load_port\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"name of ship\",\n",
      "                ],\n",
      "                \"description\": \"Name of the vessel\",\n",
      "                \"name\": \"vessel_name\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"unique slot reference number\",\n",
      "                ],\n",
      "                \"description\": \"Reference number\",\n",
      "                \"name\": \"unique_shipping_slot_id\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"exporter\",\n",
      "                ],\n",
      "                \"description\": \"Exporting company\",\n",
      "                \"name\": \"shipper\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"commodity\",\n",
      "                ],\n",
      "                \"description\": \"Type of commodity\",\n",
      "                \"name\": \"commodity\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"quantity(tonnes)\",\n",
      "                ],\n",
      "                \"description\": \"Quantity in metric tonnes\",\n",
      "                \"name\": \"tons\",\n",
      "                \"type\": \"int\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"date of eta of ship to\",\n",
      "                ],\n",
      "                \"description\": \"Estimated time of arrival\",\n",
      "                \"name\": \"eta\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"Status\",\n",
      "                    \"loading ' commenced' or ' completed'\",\n",
      "                ],\n",
      "                \"description\": \"Loading status\",\n",
      "                \"name\": \"status\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "        ],\n",
      "        \"description\": \"Shipping stem vessel loading records\",\n",
      "    }\n",
      "    \n",
      "    Confidence\n",
      "    ----\n",
      "    - High: Direct column match by name or alias\n",
      "    - Medium: Inferred from context with reasonable certainty (section header, title, etc.)\n",
      "    - Low: Best guess — ambiguous source or weak contextual signal\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Mapped data records conforming to the canonical schema\n",
      "      records: [\n",
      "        {\n",
      "          load_port: string or null,\n",
      "          vessel_name: string or null,\n",
      "          unique_shipping_slot_id: string or null,\n",
      "          shipper: string or null,\n",
      "          commodity: string or null,\n",
      "          tons: int or null,\n",
      "          eta: string or null,\n",
      "          status: string or null,\n",
      "        }\n",
      "      ],\n",
      "      // Source columns that could not be mapped to any canonical column\n",
      "      unmapped_columns: string[],\n",
      "      // Notes about the mapping process, e.g. ambiguous matches or type coercion issues\n",
      "      mapping_notes: string or null,\n",
      "      // Metadata about the interpretation: model used, per-field mapping rationale, detected sections\n",
      "      metadata: {\n",
      "        // Model that produced this result, e.g. 'openai/gpt-4o'\n",
      "        model: string,\n",
      "        // One entry per canonical column, explaining how it was resolved\n",
      "        field_mappings: [\n",
      "          {\n",
      "            // Canonical column name from the schema\n",
      "            column_name: string,\n",
      "            // Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\n",
      "            source: string,\n",
      "            // Brief explanation of why this mapping was chosen\n",
      "            rationale: string,\n",
      "            confidence: Confidence,\n",
      "          }\n",
      "        ],\n",
      "        // Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\n",
      "        sections_detected: string[] or null,\n",
      "      },\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB2771655637\",\n",
      "          \"shipper\": \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-11-30\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB1541470610\",\n",
      "          \"shipper\": \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-12-15\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"The column 'Status' could not be mapped as there is no available data matching its description.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of Ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match with alias 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity (tonnes)\",\n",
      "            \"rationale\": \"Match with 'quantity (tonnes)' after removing parenthesis.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match with alias 'date of eta of ship to'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"N/A\",\n",
      "            \"rationale\": \"No matching column or context clue for 'Loading status'.\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class MappedTable)---\u001b[0m\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB2771655637\",\n",
      "          \"shipper\": \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-11-30\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB1541470610\",\n",
      "          \"shipper\": \"Louis Dreyfus Company\\nGrains Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-12-15\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"The column 'Status' could not be mapped as there is no available data matching its description.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of Ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match with alias 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity (tonnes)\",\n",
      "            \"rationale\": \"Match with 'quantity (tonnes)' after removing parenthesis.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match with alias 'date of eta of ship to'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"N/A\",\n",
      "            \"rationale\": \"No matching column or context clue for 'Loading status'.\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "2026-02-02T19:11:04.615 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction MapToCanonicalSchema\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 11370ms. StopReason: stop. Tokens(in/out): 1700/770\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a data mapper. Given a parsed table and a canonical schema, map each data row\n",
      "    to the canonical schema columns.\n",
      "    \n",
      "    Mapping rules:\n",
      "    1. Match source columns to canonical columns using name, aliases, and description.\n",
      "    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n",
      "    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n",
      "    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n",
      "    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n",
      "    6. List any source columns that could not be mapped in unmapped_columns.\n",
      "    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n",
      "       (especially when its aliases list is empty), look for its value in the\n",
      "       surrounding context:\n",
      "       - Section headers or group labels that appear above or between data groups\n",
      "       - Document title, subtitle, or metadata lines\n",
      "       - Repeated contextual values that apply to all rows in a group\n",
      "       When a value is inferred from context, apply it to ALL rows in that section.\n",
      "       The parsed_table's notes field may contain section boundary information.\n",
      "    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n",
      "       metadata explaining:\n",
      "       - Where the value came from (source)\n",
      "       - Why this mapping was chosen (rationale)\n",
      "       - How confident you are (High = direct name/alias match,\n",
      "         Medium = inferred from context with reasonable certainty,\n",
      "         Low = best guess or ambiguous)\n",
      "    9. Set metadata.model to \"openai/gpt-4o\" (it will be provided).\n",
      "    10. If the text had section labels, list them in metadata.sections_detected.\n",
      "    \n",
      "    Parsed table:\n",
      "    {\n",
      "        \"aggregations\": null,\n",
      "        \"data_rows\": [\n",
      "            [\n",
      "                \"QB0357578736\",\n",
      "                \"TOMINI OROSHI\",\n",
      "                \"29-05-2025\",\n",
      "                \"02:19:00 PM\",\n",
      "                \"29-05-2025\",\n",
      "                \"07:06:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"16-06-2025\",\n",
      "                \"11:57:00 AM\",\n",
      "                \"22-06-2025\",\n",
      "                \"11:57:00 AM\",\n",
      "                \"19-06-2025\",\n",
      "                \"01:28:00 PM\",\n",
      "                \"22-06-2025\",\n",
      "                \"04:30:00 AM\",\n",
      "                \"Wilmar Trading Australia\",\n",
      "                \"30,000\",\n",
      "                \"QBT Sorghum\",\n",
      "                \"Completed\",\n",
      "                \"21-06-2025\",\n",
      "                \"08:30:00 PM\",\n",
      "            ],\n",
      "            [\n",
      "                \"QB7412357677\",\n",
      "                \"UBC TAKORADI\",\n",
      "                \"16-05-2025\",\n",
      "                \"05:41:00 PM\",\n",
      "                \"16-05-2025\",\n",
      "                \"08:26:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"01-06-2025\",\n",
      "                \"11:56:00 AM\",\n",
      "                \"15-06-2025\",\n",
      "                \"11:56:00 AM\",\n",
      "                \"05-06-2025\",\n",
      "                \"11:41:00 AM\",\n",
      "                \"07-06-2025\",\n",
      "                \"07:00:00 PM\",\n",
      "                \"Wilmar Trading Australia\",\n",
      "                \"30,000\",\n",
      "                \"QBT Sorghum\",\n",
      "                \"Completed\",\n",
      "                \"07-06-2025\",\n",
      "                \"02:48:00 PM\",\n",
      "            ],\n",
      "        ],\n",
      "        \"headers\": {\n",
      "            \"levels\": 1,\n",
      "            \"names\": [\n",
      "                [\n",
      "                    \"Unique Slot Reference Number\",\n",
      "                    \"Name of ship\",\n",
      "                    \"Date at which nomination was received\",\n",
      "                    \"Time at which nomination was received\",\n",
      "                    \"Date at which nomination was accepted\",\n",
      "                    \"Time at which nomination was accepted\",\n",
      "                    \"Port\",\n",
      "                    \"Date of ETA of Ship From\",\n",
      "                    \"Time of ETA of Ship From\",\n",
      "                    \"Date of ETA of Ship To\",\n",
      "                    \"Time of ETA of Ship To\",\n",
      "                    \"Date ETA of Grain Loading Commencement\",\n",
      "                    \"Time ETA of Grain Loading Commencement\",\n",
      "                    \"Date of ETD of Ship\",\n",
      "                    \"Time of ETD of Ship\",\n",
      "                    \"Exporter\",\n",
      "                    \"Quantity(tonnes)\",\n",
      "                    \"Commodity\",\n",
      "                    \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "                    \"Date Loading Completed\",\n",
      "                    \"Time Loading Completed\",\n",
      "                ],\n",
      "            ],\n",
      "        },\n",
      "        \"notes\": null,\n",
      "        \"table_type\": FlatHeader,\n",
      "    }\n",
      "    \n",
      "    Canonical schema:\n",
      "    {\n",
      "        \"columns\": [\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"port\",\n",
      "                ],\n",
      "                \"description\": \"Loading port name\",\n",
      "                \"name\": \"load_port\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"name of ship\",\n",
      "                ],\n",
      "                \"description\": \"Name of the vessel\",\n",
      "                \"name\": \"vessel_name\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"unique slot reference number\",\n",
      "                ],\n",
      "                \"description\": \"Reference number\",\n",
      "                \"name\": \"unique_shipping_slot_id\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"exporter\",\n",
      "                ],\n",
      "                \"description\": \"Exporting company\",\n",
      "                \"name\": \"shipper\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"commodity\",\n",
      "                ],\n",
      "                \"description\": \"Type of commodity\",\n",
      "                \"name\": \"commodity\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"quantity(tonnes)\",\n",
      "                ],\n",
      "                \"description\": \"Quantity in metric tonnes\",\n",
      "                \"name\": \"tons\",\n",
      "                \"type\": \"int\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"date of eta of ship to\",\n",
      "                ],\n",
      "                \"description\": \"Estimated time of arrival\",\n",
      "                \"name\": \"eta\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"Status\",\n",
      "                    \"loading ' commenced' or ' completed'\",\n",
      "                ],\n",
      "                \"description\": \"Loading status\",\n",
      "                \"name\": \"status\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "        ],\n",
      "        \"description\": \"Shipping stem vessel loading records\",\n",
      "    }\n",
      "    \n",
      "    Confidence\n",
      "    ----\n",
      "    - High: Direct column match by name or alias\n",
      "    - Medium: Inferred from context with reasonable certainty (section header, title, etc.)\n",
      "    - Low: Best guess — ambiguous source or weak contextual signal\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Mapped data records conforming to the canonical schema\n",
      "      records: [\n",
      "        {\n",
      "          load_port: string or null,\n",
      "          vessel_name: string or null,\n",
      "          unique_shipping_slot_id: string or null,\n",
      "          shipper: string or null,\n",
      "          commodity: string or null,\n",
      "          tons: int or null,\n",
      "          eta: string or null,\n",
      "          status: string or null,\n",
      "        }\n",
      "      ],\n",
      "      // Source columns that could not be mapped to any canonical column\n",
      "      unmapped_columns: string[],\n",
      "      // Notes about the mapping process, e.g. ambiguous matches or type coercion issues\n",
      "      mapping_notes: string or null,\n",
      "      // Metadata about the interpretation: model used, per-field mapping rationale, detected sections\n",
      "      metadata: {\n",
      "        // Model that produced this result, e.g. 'openai/gpt-4o'\n",
      "        model: string,\n",
      "        // One entry per canonical column, explaining how it was resolved\n",
      "        field_mappings: [\n",
      "          {\n",
      "            // Canonical column name from the schema\n",
      "            column_name: string,\n",
      "            // Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\n",
      "            source: string,\n",
      "            // Brief explanation of why this mapping was chosen\n",
      "            rationale: string,\n",
      "            confidence: Confidence,\n",
      "          }\n",
      "        ],\n",
      "        // Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\n",
      "        sections_detected: string[] or null,\n",
      "      },\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TOMINI OROSHI\",\n",
      "          \"unique_shipping_slot_id\": \"QB0357578736\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-06-22\",\n",
      "          \"status\": \"Completed\"\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"UBC TAKORADI\",\n",
      "          \"unique_shipping_slot_id\": \"QB7412357677\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-06-15\",\n",
      "          \"status\": \"Completed\"\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Date values for ETA normalized to ISO format. Tons coerced from string to int.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match with alias 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Direct match with alias 'quantity(tonnes)'. Value coerced to integer.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match with alias 'date of eta of ship to'. Date normalized.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"rationale\": \"Direct match with alias 'loading \\\"commenced\\\" or \\\"completed\\\"'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class MappedTable)---\u001b[0m\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TOMINI OROSHI\",\n",
      "          \"unique_shipping_slot_id\": \"QB0357578736\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-06-22\",\n",
      "          \"status\": \"Completed\"\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"UBC TAKORADI\",\n",
      "          \"unique_shipping_slot_id\": \"QB7412357677\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-06-15\",\n",
      "          \"status\": \"Completed\"\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Date values for ETA normalized to ISO format. Tons coerced from string to int.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match with alias 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Direct match with alias 'quantity(tonnes)'. Value coerced to integer.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match with alias 'date of eta of ship to'. Date normalized.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"rationale\": \"Direct match with alias 'loading \\\"commenced\\\" or \\\"completed\\\"'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "2026-02-02T19:11:05.499 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction MapToCanonicalSchema\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 12253ms. StopReason: stop. Tokens(in/out): 1603/719\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a data mapper. Given a parsed table and a canonical schema, map each data row\n",
      "    to the canonical schema columns.\n",
      "    \n",
      "    Mapping rules:\n",
      "    1. Match source columns to canonical columns using name, aliases, and description.\n",
      "    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n",
      "    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n",
      "    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n",
      "    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n",
      "    6. List any source columns that could not be mapped in unmapped_columns.\n",
      "    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n",
      "       (especially when its aliases list is empty), look for its value in the\n",
      "       surrounding context:\n",
      "       - Section headers or group labels that appear above or between data groups\n",
      "       - Document title, subtitle, or metadata lines\n",
      "       - Repeated contextual values that apply to all rows in a group\n",
      "       When a value is inferred from context, apply it to ALL rows in that section.\n",
      "       The parsed_table's notes field may contain section boundary information.\n",
      "    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n",
      "       metadata explaining:\n",
      "       - Where the value came from (source)\n",
      "       - Why this mapping was chosen (rationale)\n",
      "       - How confident you are (High = direct name/alias match,\n",
      "         Medium = inferred from context with reasonable certainty,\n",
      "         Low = best guess or ambiguous)\n",
      "    9. Set metadata.model to \"openai/gpt-4o\" (it will be provided).\n",
      "    10. If the text had section labels, list them in metadata.sections_detected.\n",
      "    \n",
      "    Parsed table:\n",
      "    {\n",
      "        \"aggregations\": null,\n",
      "        \"data_rows\": [\n",
      "            [\n",
      "                \"QB3582536041\",\n",
      "                \"TBA\",\n",
      "                \"29-04-2025\",\n",
      "                \"01:00:00 PM\",\n",
      "                \"02-05-2025\",\n",
      "                \"02:59:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"15-12-2025\",\n",
      "                \"04:02:00 PM\",\n",
      "                \"30-12-2025\",\n",
      "                \"04:03:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Louis Dreyfus Company\",\n",
      "                \"30,000\",\n",
      "                \"QBT Chickpeas\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Grains Australia Pty Ltd\",\n",
      "            ],\n",
      "            [\n",
      "                \"QB1566785655\",\n",
      "                \"TBA\",\n",
      "                \"30-04-2025\",\n",
      "                \"08:14:00 PM\",\n",
      "                \"02-05-2025\",\n",
      "                \"02:30:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"01-01-2026\",\n",
      "                \"04:05:00 PM\",\n",
      "                \"15-01-2026\",\n",
      "                \"04:06:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"ADM Trading Australia Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Chickpeas\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "            ],\n",
      "        ],\n",
      "        \"headers\": {\n",
      "            \"levels\": 1,\n",
      "            \"names\": [\n",
      "                [\n",
      "                    \"Unique Slot Reference Number\",\n",
      "                    \"Name of Ship\",\n",
      "                    \"Date Nomination Received\",\n",
      "                    \"Time Nomination Received\",\n",
      "                    \"Date Nomination Accepted\",\n",
      "                    \"Time Nomination Accepted\",\n",
      "                    \"Port\",\n",
      "                    \"Date of ETA of Ship From\",\n",
      "                    \"Time of ETA of Ship From\",\n",
      "                    \"Date of ETA of Ship To\",\n",
      "                    \"Time of ETA of Ship To\",\n",
      "                    \"Date ETA of Grain Loading Commencement\",\n",
      "                    \"Time ETA of Grain Loading Commencement\",\n",
      "                    \"Date of ETD of Ship\",\n",
      "                    \"Time of ETD of Ship\",\n",
      "                    \"Exporter\",\n",
      "                    \"Quantity (tonnes)\",\n",
      "                    \"Commodity\",\n",
      "                    \"Loading Status\",\n",
      "                    \"Date Loading Completed\",\n",
      "                    \"Time Loading Completed\",\n",
      "                    \"Notes\",\n",
      "                ],\n",
      "            ],\n",
      "        },\n",
      "        \"notes\": null,\n",
      "        \"table_type\": FlatHeader,\n",
      "    }\n",
      "    \n",
      "    Canonical schema:\n",
      "    {\n",
      "        \"columns\": [\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"port\",\n",
      "                ],\n",
      "                \"description\": \"Loading port name\",\n",
      "                \"name\": \"load_port\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"name of ship\",\n",
      "                ],\n",
      "                \"description\": \"Name of the vessel\",\n",
      "                \"name\": \"vessel_name\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"unique slot reference number\",\n",
      "                ],\n",
      "                \"description\": \"Reference number\",\n",
      "                \"name\": \"unique_shipping_slot_id\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"exporter\",\n",
      "                ],\n",
      "                \"description\": \"Exporting company\",\n",
      "                \"name\": \"shipper\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"commodity\",\n",
      "                ],\n",
      "                \"description\": \"Type of commodity\",\n",
      "                \"name\": \"commodity\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"quantity(tonnes)\",\n",
      "                ],\n",
      "                \"description\": \"Quantity in metric tonnes\",\n",
      "                \"name\": \"tons\",\n",
      "                \"type\": \"int\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"date of eta of ship to\",\n",
      "                ],\n",
      "                \"description\": \"Estimated time of arrival\",\n",
      "                \"name\": \"eta\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"Status\",\n",
      "                    \"loading ' commenced' or ' completed'\",\n",
      "                ],\n",
      "                \"description\": \"Loading status\",\n",
      "                \"name\": \"status\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "        ],\n",
      "        \"description\": \"Shipping stem vessel loading records\",\n",
      "    }\n",
      "    \n",
      "    Confidence\n",
      "    ----\n",
      "    - High: Direct column match by name or alias\n",
      "    - Medium: Inferred from context with reasonable certainty (section header, title, etc.)\n",
      "    - Low: Best guess — ambiguous source or weak contextual signal\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Mapped data records conforming to the canonical schema\n",
      "      records: [\n",
      "        {\n",
      "          load_port: string or null,\n",
      "          vessel_name: string or null,\n",
      "          unique_shipping_slot_id: string or null,\n",
      "          shipper: string or null,\n",
      "          commodity: string or null,\n",
      "          tons: int or null,\n",
      "          eta: string or null,\n",
      "          status: string or null,\n",
      "        }\n",
      "      ],\n",
      "      // Source columns that could not be mapped to any canonical column\n",
      "      unmapped_columns: string[],\n",
      "      // Notes about the mapping process, e.g. ambiguous matches or type coercion issues\n",
      "      mapping_notes: string or null,\n",
      "      // Metadata about the interpretation: model used, per-field mapping rationale, detected sections\n",
      "      metadata: {\n",
      "        // Model that produced this result, e.g. 'openai/gpt-4o'\n",
      "        model: string,\n",
      "        // One entry per canonical column, explaining how it was resolved\n",
      "        field_mappings: [\n",
      "          {\n",
      "            // Canonical column name from the schema\n",
      "            column_name: string,\n",
      "            // Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\n",
      "            source: string,\n",
      "            // Brief explanation of why this mapping was chosen\n",
      "            rationale: string,\n",
      "            confidence: Confidence,\n",
      "          }\n",
      "        ],\n",
      "        // Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\n",
      "        sections_detected: string[] or null,\n",
      "      },\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB3582536041\",\n",
      "          \"shipper\": \"Louis Dreyfus Company\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-12-30\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB1566785655\",\n",
      "          \"shipper\": \"ADM Trading Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2026-01-15\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date Nomination Received\",\n",
      "        \"Time Nomination Received\",\n",
      "        \"Date Nomination Accepted\",\n",
      "        \"Time Nomination Accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Some columns such as loading status could not be fully mapped as there wasn't enough information. Coerced quantity to int type.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match by alias and description.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of Ship\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match by both name and alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity (tonnes)\",\n",
      "            \"rationale\": \"Direct match by name, using value coercion from string.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: Loading Status\",\n",
      "            \"rationale\": \"Not applicable as there was no data present.\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class MappedTable)---\u001b[0m\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB3582536041\",\n",
      "          \"shipper\": \"Louis Dreyfus Company\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-12-30\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB1566785655\",\n",
      "          \"shipper\": \"ADM Trading Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2026-01-15\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date Nomination Received\",\n",
      "        \"Time Nomination Received\",\n",
      "        \"Date Nomination Accepted\",\n",
      "        \"Time Nomination Accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Some columns such as loading status could not be fully mapped as there wasn't enough information. Coerced quantity to int type.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match by alias and description.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of Ship\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match by both name and alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity (tonnes)\",\n",
      "            \"rationale\": \"Direct match by name, using value coercion from string.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match by alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: Loading Status\",\n",
      "            \"rationale\": \"Not applicable as there was no data present.\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "2026-02-02T19:11:05.605 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction MapToCanonicalSchema\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 12359ms. StopReason: stop. Tokens(in/out): 1698/749\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a data mapper. Given a parsed table and a canonical schema, map each data row\n",
      "    to the canonical schema columns.\n",
      "    \n",
      "    Mapping rules:\n",
      "    1. Match source columns to canonical columns using name, aliases, and description.\n",
      "    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n",
      "    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n",
      "    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n",
      "    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n",
      "    6. List any source columns that could not be mapped in unmapped_columns.\n",
      "    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n",
      "       (especially when its aliases list is empty), look for its value in the\n",
      "       surrounding context:\n",
      "       - Section headers or group labels that appear above or between data groups\n",
      "       - Document title, subtitle, or metadata lines\n",
      "       - Repeated contextual values that apply to all rows in a group\n",
      "       When a value is inferred from context, apply it to ALL rows in that section.\n",
      "       The parsed_table's notes field may contain section boundary information.\n",
      "    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n",
      "       metadata explaining:\n",
      "       - Where the value came from (source)\n",
      "       - Why this mapping was chosen (rationale)\n",
      "       - How confident you are (High = direct name/alias match,\n",
      "         Medium = inferred from context with reasonable certainty,\n",
      "         Low = best guess or ambiguous)\n",
      "    9. Set metadata.model to \"openai/gpt-4o\" (it will be provided).\n",
      "    10. If the text had section labels, list them in metadata.sections_detected.\n",
      "    \n",
      "    Parsed table:\n",
      "    {\n",
      "        \"aggregations\": null,\n",
      "        \"data_rows\": [\n",
      "            [\n",
      "                \"QB2061036115\",\n",
      "                \"DARYA DIYA\",\n",
      "                \"04-07-2025\",\n",
      "                \"03:17:00 PM\",\n",
      "                \"04-07-2025\",\n",
      "                \"03:30:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"15-09-2025\",\n",
      "                \"02:53:00 PM\",\n",
      "                \"30-09-2025\",\n",
      "                \"02:54:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Arrow Commodities Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Wheat\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Last updated on:: 30-09-2025 06:00 AM\",\n",
      "            ],\n",
      "            [\n",
      "                \"QB3126604877\",\n",
      "                \"MH ADAGIO\",\n",
      "                \"03-06-2025\",\n",
      "                \"02:23:00 PM\",\n",
      "                \"03-06-2025\",\n",
      "                \"02:36:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"21-07-2025\",\n",
      "                \"11:43:00 AM\",\n",
      "                \"31-07-2025\",\n",
      "                \"11:43:00 AM\",\n",
      "                \"24-07-2025\",\n",
      "                \"12:55:00 AM\",\n",
      "                \"26-07-2025\",\n",
      "                \"11:00:00 AM\",\n",
      "                \"Arrow Commodities Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Wheat\",\n",
      "                \"Completed\",\n",
      "                \"25-07-2025\",\n",
      "                \"09:13:00 PM\",\n",
      "                \"Last updated on:: 30-09-2025 06:00 AM\",\n",
      "            ],\n",
      "        ],\n",
      "        \"headers\": {\n",
      "            \"levels\": 1,\n",
      "            \"names\": [\n",
      "                [\n",
      "                    \"Unique Slot Reference Number\",\n",
      "                    \"Name of ship\",\n",
      "                    \"Date at which nomination was received\",\n",
      "                    \"Time at which nomination was received\",\n",
      "                    \"Date at which nomination was accepted\",\n",
      "                    \"Time at which nomination was accepted\",\n",
      "                    \"Port\",\n",
      "                    \"Date of ETA of Ship From\",\n",
      "                    \"Time of ETA of Ship From\",\n",
      "                    \"Date of ETA of Ship To\",\n",
      "                    \"Time of ETA of Ship To\",\n",
      "                    \"Date ETA of Grain Loading Commencement\",\n",
      "                    \"Time ETA of Grain Loading Commencement\",\n",
      "                    \"Date of ETD of Ship\",\n",
      "                    \"Time of ETD of Ship\",\n",
      "                    \"Exporter\",\n",
      "                    \"Quantity(tonnes)\",\n",
      "                    \"Commodity\",\n",
      "                    \"\\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "                    \"Date Loading Completed\",\n",
      "                    \"Time Loading Completed\",\n",
      "                    \"Notes\",\n",
      "                ],\n",
      "            ],\n",
      "        },\n",
      "        \"notes\": null,\n",
      "        \"table_type\": FlatHeader,\n",
      "    }\n",
      "    \n",
      "    Canonical schema:\n",
      "    {\n",
      "        \"columns\": [\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"port\",\n",
      "                ],\n",
      "                \"description\": \"Loading port name\",\n",
      "                \"name\": \"load_port\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"name of ship\",\n",
      "                ],\n",
      "                \"description\": \"Name of the vessel\",\n",
      "                \"name\": \"vessel_name\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"unique slot reference number\",\n",
      "                ],\n",
      "                \"description\": \"Reference number\",\n",
      "                \"name\": \"unique_shipping_slot_id\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"exporter\",\n",
      "                ],\n",
      "                \"description\": \"Exporting company\",\n",
      "                \"name\": \"shipper\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"commodity\",\n",
      "                ],\n",
      "                \"description\": \"Type of commodity\",\n",
      "                \"name\": \"commodity\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"quantity(tonnes)\",\n",
      "                ],\n",
      "                \"description\": \"Quantity in metric tonnes\",\n",
      "                \"name\": \"tons\",\n",
      "                \"type\": \"int\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"date of eta of ship to\",\n",
      "                ],\n",
      "                \"description\": \"Estimated time of arrival\",\n",
      "                \"name\": \"eta\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"Status\",\n",
      "                    \"loading ' commenced' or ' completed'\",\n",
      "                ],\n",
      "                \"description\": \"Loading status\",\n",
      "                \"name\": \"status\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "        ],\n",
      "        \"description\": \"Shipping stem vessel loading records\",\n",
      "    }\n",
      "    \n",
      "    Confidence\n",
      "    ----\n",
      "    - High: Direct column match by name or alias\n",
      "    - Medium: Inferred from context with reasonable certainty (section header, title, etc.)\n",
      "    - Low: Best guess — ambiguous source or weak contextual signal\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Mapped data records conforming to the canonical schema\n",
      "      records: [\n",
      "        {\n",
      "          load_port: string or null,\n",
      "          vessel_name: string or null,\n",
      "          unique_shipping_slot_id: string or null,\n",
      "          shipper: string or null,\n",
      "          commodity: string or null,\n",
      "          tons: int or null,\n",
      "          eta: string or null,\n",
      "          status: string or null,\n",
      "        }\n",
      "      ],\n",
      "      // Source columns that could not be mapped to any canonical column\n",
      "      unmapped_columns: string[],\n",
      "      // Notes about the mapping process, e.g. ambiguous matches or type coercion issues\n",
      "      mapping_notes: string or null,\n",
      "      // Metadata about the interpretation: model used, per-field mapping rationale, detected sections\n",
      "      metadata: {\n",
      "        // Model that produced this result, e.g. 'openai/gpt-4o'\n",
      "        model: string,\n",
      "        // One entry per canonical column, explaining how it was resolved\n",
      "        field_mappings: [\n",
      "          {\n",
      "            // Canonical column name from the schema\n",
      "            column_name: string,\n",
      "            // Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\n",
      "            source: string,\n",
      "            // Brief explanation of why this mapping was chosen\n",
      "            rationale: string,\n",
      "            confidence: Confidence,\n",
      "          }\n",
      "        ],\n",
      "        // Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\n",
      "        sections_detected: string[] or null,\n",
      "      },\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"DARYA DIYA\",\n",
      "          \"unique_shipping_slot_id\": \"QB2061036115\",\n",
      "          \"shipper\": \"Arrow Commodities Pty Ltd\",\n",
      "          \"commodity\": \"QBT Wheat\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-09-30\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"MH ADAGIO\",\n",
      "          \"unique_shipping_slot_id\": \"QB3126604877\",\n",
      "          \"shipper\": \"Arrow Commodities Pty Ltd\",\n",
      "          \"commodity\": \"QBT Wheat\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-07-31\",\n",
      "          \"status\": \"Completed\"\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Status mapping is ambiguous due to column encoding issues.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Alias match with 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Exact match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Exact match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Alias match with 'quantity(tonnes)'. Value coerced to int from string.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Exact match with alias 'date of eta of ship to'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: \\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "            \"rationale\": \"Closest match to ambiguously encoded loading status.\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class MappedTable)---\u001b[0m\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"DARYA DIYA\",\n",
      "          \"unique_shipping_slot_id\": \"QB2061036115\",\n",
      "          \"shipper\": \"Arrow Commodities Pty Ltd\",\n",
      "          \"commodity\": \"QBT Wheat\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-09-30\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"MH ADAGIO\",\n",
      "          \"unique_shipping_slot_id\": \"QB3126604877\",\n",
      "          \"shipper\": \"Arrow Commodities Pty Ltd\",\n",
      "          \"commodity\": \"QBT Wheat\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-07-31\",\n",
      "          \"status\": \"Completed\"\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Status mapping is ambiguous due to column encoding issues.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Alias match with 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Exact match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Exact match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Alias match with 'quantity(tonnes)'. Value coerced to int from string.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Exact match with alias 'date of eta of ship to'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: \\\"Loading \\\"\\\"commenced\\\"\\\" or \\\"\\\"completed\\\"\\\"\\\"\",\n",
      "            \"rationale\": \"Closest match to ambiguously encoded loading status.\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "2026-02-02T19:11:05.712 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction MapToCanonicalSchema\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 12468ms. StopReason: stop. Tokens(in/out): 1612/721\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a data mapper. Given a parsed table and a canonical schema, map each data row\n",
      "    to the canonical schema columns.\n",
      "    \n",
      "    Mapping rules:\n",
      "    1. Match source columns to canonical columns using name, aliases, and description.\n",
      "    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n",
      "    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n",
      "    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n",
      "    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n",
      "    6. List any source columns that could not be mapped in unmapped_columns.\n",
      "    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n",
      "       (especially when its aliases list is empty), look for its value in the\n",
      "       surrounding context:\n",
      "       - Section headers or group labels that appear above or between data groups\n",
      "       - Document title, subtitle, or metadata lines\n",
      "       - Repeated contextual values that apply to all rows in a group\n",
      "       When a value is inferred from context, apply it to ALL rows in that section.\n",
      "       The parsed_table's notes field may contain section boundary information.\n",
      "    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n",
      "       metadata explaining:\n",
      "       - Where the value came from (source)\n",
      "       - Why this mapping was chosen (rationale)\n",
      "       - How confident you are (High = direct name/alias match,\n",
      "         Medium = inferred from context with reasonable certainty,\n",
      "         Low = best guess or ambiguous)\n",
      "    9. Set metadata.model to \"openai/gpt-4o\" (it will be provided).\n",
      "    10. If the text had section labels, list them in metadata.sections_detected.\n",
      "    \n",
      "    Parsed table:\n",
      "    {\n",
      "        \"aggregations\": null,\n",
      "        \"data_rows\": [\n",
      "            [\n",
      "                \"QB5345742564\",\n",
      "                \"TBA\",\n",
      "                \"30-04-2025\",\n",
      "                \"08:14:00 PM\",\n",
      "                \"02-05-2025\",\n",
      "                \"02:30:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"01-12-2025\",\n",
      "                \"04:04:00 PM\",\n",
      "                \"15-12-2025\",\n",
      "                \"04:05:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"ADM Trading Australia Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Chickpeas\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "            ],\n",
      "            [\n",
      "                \"QB2687807116\",\n",
      "                \"TBA\",\n",
      "                \"30-04-2025\",\n",
      "                \"08:14:00 PM\",\n",
      "                \"02-05-2025\",\n",
      "                \"02:30:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"15-11-2025\",\n",
      "                \"04:04:00 PM\",\n",
      "                \"30-11-2025\",\n",
      "                \"04:04:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"ADM Trading Australia Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Chickpeas\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "            ],\n",
      "        ],\n",
      "        \"headers\": {\n",
      "            \"levels\": 1,\n",
      "            \"names\": [\n",
      "                [\n",
      "                    \"Unique Slot Reference Number\",\n",
      "                    \"Name of ship\",\n",
      "                    \"Date at which nomination was received\",\n",
      "                    \"Time at which nomination was received\",\n",
      "                    \"Date at which nomination was accepted\",\n",
      "                    \"Time at which nomination was accepted\",\n",
      "                    \"Port\",\n",
      "                    \"Date of ETA of Ship From\",\n",
      "                    \"Time of ETA of Ship From\",\n",
      "                    \"Date of ETA of Ship To\",\n",
      "                    \"Time of ETA of Ship To\",\n",
      "                    \"Date ETA of Grain Loading Commencement\",\n",
      "                    \"Time ETA of Grain Loading Commencement\",\n",
      "                    \"Date of ETD of Ship\",\n",
      "                    \"Time of ETD of Ship\",\n",
      "                    \"Exporter\",\n",
      "                    \"Quantity(tonnes)\",\n",
      "                    \"Commodity\",\n",
      "                    \"Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "                    \"Date Loading Completed\",\n",
      "                    \"Time Loading Completed\",\n",
      "                    \"Notes\",\n",
      "                ],\n",
      "            ],\n",
      "        },\n",
      "        \"notes\": null,\n",
      "        \"table_type\": FlatHeader,\n",
      "    }\n",
      "    \n",
      "    Canonical schema:\n",
      "    {\n",
      "        \"columns\": [\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"port\",\n",
      "                ],\n",
      "                \"description\": \"Loading port name\",\n",
      "                \"name\": \"load_port\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"name of ship\",\n",
      "                ],\n",
      "                \"description\": \"Name of the vessel\",\n",
      "                \"name\": \"vessel_name\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"unique slot reference number\",\n",
      "                ],\n",
      "                \"description\": \"Reference number\",\n",
      "                \"name\": \"unique_shipping_slot_id\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"exporter\",\n",
      "                ],\n",
      "                \"description\": \"Exporting company\",\n",
      "                \"name\": \"shipper\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"commodity\",\n",
      "                ],\n",
      "                \"description\": \"Type of commodity\",\n",
      "                \"name\": \"commodity\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"quantity(tonnes)\",\n",
      "                ],\n",
      "                \"description\": \"Quantity in metric tonnes\",\n",
      "                \"name\": \"tons\",\n",
      "                \"type\": \"int\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"date of eta of ship to\",\n",
      "                ],\n",
      "                \"description\": \"Estimated time of arrival\",\n",
      "                \"name\": \"eta\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"Status\",\n",
      "                    \"loading ' commenced' or ' completed'\",\n",
      "                ],\n",
      "                \"description\": \"Loading status\",\n",
      "                \"name\": \"status\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "        ],\n",
      "        \"description\": \"Shipping stem vessel loading records\",\n",
      "    }\n",
      "    \n",
      "    Confidence\n",
      "    ----\n",
      "    - High: Direct column match by name or alias\n",
      "    - Medium: Inferred from context with reasonable certainty (section header, title, etc.)\n",
      "    - Low: Best guess — ambiguous source or weak contextual signal\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Mapped data records conforming to the canonical schema\n",
      "      records: [\n",
      "        {\n",
      "          load_port: string or null,\n",
      "          vessel_name: string or null,\n",
      "          unique_shipping_slot_id: string or null,\n",
      "          shipper: string or null,\n",
      "          commodity: string or null,\n",
      "          tons: int or null,\n",
      "          eta: string or null,\n",
      "          status: string or null,\n",
      "        }\n",
      "      ],\n",
      "      // Source columns that could not be mapped to any canonical column\n",
      "      unmapped_columns: string[],\n",
      "      // Notes about the mapping process, e.g. ambiguous matches or type coercion issues\n",
      "      mapping_notes: string or null,\n",
      "      // Metadata about the interpretation: model used, per-field mapping rationale, detected sections\n",
      "      metadata: {\n",
      "        // Model that produced this result, e.g. 'openai/gpt-4o'\n",
      "        model: string,\n",
      "        // One entry per canonical column, explaining how it was resolved\n",
      "        field_mappings: [\n",
      "          {\n",
      "            // Canonical column name from the schema\n",
      "            column_name: string,\n",
      "            // Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\n",
      "            source: string,\n",
      "            // Brief explanation of why this mapping was chosen\n",
      "            rationale: string,\n",
      "            confidence: Confidence,\n",
      "          }\n",
      "        ],\n",
      "        // Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\n",
      "        sections_detected: string[] or null,\n",
      "      },\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB5345742564\",\n",
      "          \"shipper\": \"ADM Trading Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-12-15\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB2687807116\",\n",
      "          \"shipper\": \"ADM Trading Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-11-30\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"The 'Status' field could not be mapped as there are no explicit matches or context to infer its value. 'Tons' value was coerced from the formatted string to integer. Dates were normalized to the ISO 8601 format.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct name match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Alias match with coercion from string to integer\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Alias match with date normalization\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"None\",\n",
      "            \"rationale\": \"No applicable column or context available\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class MappedTable)---\u001b[0m\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB5345742564\",\n",
      "          \"shipper\": \"ADM Trading Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-12-15\",\n",
      "          \"status\": null\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB2687807116\",\n",
      "          \"shipper\": \"ADM Trading Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-11-30\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Time of ETA of Ship To\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"The 'Status' field could not be mapped as there are no explicit matches or context to infer its value. 'Tons' value was coerced from the formatted string to integer. Dates were normalized to the ISO 8601 format.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct name match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Alias match\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Alias match with coercion from string to integer\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Alias match with date normalization\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"None\",\n",
      "            \"rationale\": \"No applicable column or context available\",\n",
      "            \"confidence\": \"Low\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "2026-02-02T19:11:06.137 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction MapToCanonicalSchema\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 12892ms. StopReason: stop. Tokens(in/out): 1705/770\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a data mapper. Given a parsed table and a canonical schema, map each data row\n",
      "    to the canonical schema columns.\n",
      "    \n",
      "    Mapping rules:\n",
      "    1. Match source columns to canonical columns using name, aliases, and description.\n",
      "    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n",
      "    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n",
      "    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n",
      "    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n",
      "    6. List any source columns that could not be mapped in unmapped_columns.\n",
      "    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n",
      "       (especially when its aliases list is empty), look for its value in the\n",
      "       surrounding context:\n",
      "       - Section headers or group labels that appear above or between data groups\n",
      "       - Document title, subtitle, or metadata lines\n",
      "       - Repeated contextual values that apply to all rows in a group\n",
      "       When a value is inferred from context, apply it to ALL rows in that section.\n",
      "       The parsed_table's notes field may contain section boundary information.\n",
      "    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n",
      "       metadata explaining:\n",
      "       - Where the value came from (source)\n",
      "       - Why this mapping was chosen (rationale)\n",
      "       - How confident you are (High = direct name/alias match,\n",
      "         Medium = inferred from context with reasonable certainty,\n",
      "         Low = best guess or ambiguous)\n",
      "    9. Set metadata.model to \"openai/gpt-4o\" (it will be provided).\n",
      "    10. If the text had section labels, list them in metadata.sections_detected.\n",
      "    \n",
      "    Parsed table:\n",
      "    {\n",
      "        \"aggregations\": null,\n",
      "        \"data_rows\": [\n",
      "            [\n",
      "                \"QB1148678055\",\n",
      "                \"MONOCEROS\",\n",
      "                \"05-06-2025\",\n",
      "                \"04:49:00 PM\",\n",
      "                \"05-06-2025\",\n",
      "                \"05:00:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"21-07-2025\",\n",
      "                \"11:41:00 AM\",\n",
      "                \"31-07-2025\",\n",
      "                \"11:41:00 AM\",\n",
      "                \"27-07-2025\",\n",
      "                \"10:21:00 PM\",\n",
      "                \"31-07-2025\",\n",
      "                \"02:54:00 AM\",\n",
      "                \"Robinson Grain\",\n",
      "                \"30,000\",\n",
      "                \"QBT Sorghum\",\n",
      "                \"Completed\",\n",
      "                \"30-07-2025\",\n",
      "                \"01:56:00 PM\",\n",
      "                \"\",\n",
      "            ],\n",
      "            [\n",
      "                \"QB5305788574\",\n",
      "                \"CETUS SEI\",\n",
      "                \"16-06-2025\",\n",
      "                \"02:59:00 PM\",\n",
      "                \"16-06-2025\",\n",
      "                \"02:59:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"30-06-2025\",\n",
      "                \"02:59:00 PM\",\n",
      "                \"05-07-2025\",\n",
      "                \"03:00:00 PM\",\n",
      "                \"01-07-2025\",\n",
      "                \"09:35:00 AM\",\n",
      "                \"03-07-2025\",\n",
      "                \"03:20:00 PM\",\n",
      "                \"Wilmar Trading Australia\",\n",
      "                \"30,000\",\n",
      "                \"QBT Sorghum\",\n",
      "                \"Completed\",\n",
      "                \"03-07-2025\",\n",
      "                \"03:28:00 AM\",\n",
      "                \"\",\n",
      "            ],\n",
      "        ],\n",
      "        \"headers\": {\n",
      "            \"levels\": 1,\n",
      "            \"names\": [\n",
      "                [\n",
      "                    \"Unique Slot Reference Number\",\n",
      "                    \"Name of Ship\",\n",
      "                    \"Date at which nomination was received\",\n",
      "                    \"Time at which nomination was received\",\n",
      "                    \"Date at which nomination was accepted\",\n",
      "                    \"Time at which nomination was accepted\",\n",
      "                    \"Port\",\n",
      "                    \"Date of ETA of Ship From\",\n",
      "                    \"Time of ETA of Ship From\",\n",
      "                    \"Date of ETA of Ship To\",\n",
      "                    \"Time of ETA of Ship To\",\n",
      "                    \"Date ETA of Grain Loading Commencement\",\n",
      "                    \"Time ETA of Grain Loading Commencement\",\n",
      "                    \"Date of ETD of Ship\",\n",
      "                    \"Time of ETD of Ship\",\n",
      "                    \"Exporter\",\n",
      "                    \"Quantity(tonnes)\",\n",
      "                    \"Commodity\",\n",
      "                    \"\\\"Loading \\\"commenced\\\" or \\\"completed\\\"\\\"\",\n",
      "                    \"Date Loading Completed\",\n",
      "                    \"Time Loading Completed\",\n",
      "                    \"Notes\",\n",
      "                ],\n",
      "            ],\n",
      "        },\n",
      "        \"notes\": null,\n",
      "        \"table_type\": FlatHeader,\n",
      "    }\n",
      "    \n",
      "    Canonical schema:\n",
      "    {\n",
      "        \"columns\": [\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"port\",\n",
      "                ],\n",
      "                \"description\": \"Loading port name\",\n",
      "                \"name\": \"load_port\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"name of ship\",\n",
      "                ],\n",
      "                \"description\": \"Name of the vessel\",\n",
      "                \"name\": \"vessel_name\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"unique slot reference number\",\n",
      "                ],\n",
      "                \"description\": \"Reference number\",\n",
      "                \"name\": \"unique_shipping_slot_id\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"exporter\",\n",
      "                ],\n",
      "                \"description\": \"Exporting company\",\n",
      "                \"name\": \"shipper\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"commodity\",\n",
      "                ],\n",
      "                \"description\": \"Type of commodity\",\n",
      "                \"name\": \"commodity\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"quantity(tonnes)\",\n",
      "                ],\n",
      "                \"description\": \"Quantity in metric tonnes\",\n",
      "                \"name\": \"tons\",\n",
      "                \"type\": \"int\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"date of eta of ship to\",\n",
      "                ],\n",
      "                \"description\": \"Estimated time of arrival\",\n",
      "                \"name\": \"eta\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"Status\",\n",
      "                    \"loading ' commenced' or ' completed'\",\n",
      "                ],\n",
      "                \"description\": \"Loading status\",\n",
      "                \"name\": \"status\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "        ],\n",
      "        \"description\": \"Shipping stem vessel loading records\",\n",
      "    }\n",
      "    \n",
      "    Confidence\n",
      "    ----\n",
      "    - High: Direct column match by name or alias\n",
      "    - Medium: Inferred from context with reasonable certainty (section header, title, etc.)\n",
      "    - Low: Best guess — ambiguous source or weak contextual signal\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Mapped data records conforming to the canonical schema\n",
      "      records: [\n",
      "        {\n",
      "          load_port: string or null,\n",
      "          vessel_name: string or null,\n",
      "          unique_shipping_slot_id: string or null,\n",
      "          shipper: string or null,\n",
      "          commodity: string or null,\n",
      "          tons: int or null,\n",
      "          eta: string or null,\n",
      "          status: string or null,\n",
      "        }\n",
      "      ],\n",
      "      // Source columns that could not be mapped to any canonical column\n",
      "      unmapped_columns: string[],\n",
      "      // Notes about the mapping process, e.g. ambiguous matches or type coercion issues\n",
      "      mapping_notes: string or null,\n",
      "      // Metadata about the interpretation: model used, per-field mapping rationale, detected sections\n",
      "      metadata: {\n",
      "        // Model that produced this result, e.g. 'openai/gpt-4o'\n",
      "        model: string,\n",
      "        // One entry per canonical column, explaining how it was resolved\n",
      "        field_mappings: [\n",
      "          {\n",
      "            // Canonical column name from the schema\n",
      "            column_name: string,\n",
      "            // Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\n",
      "            source: string,\n",
      "            // Brief explanation of why this mapping was chosen\n",
      "            rationale: string,\n",
      "            confidence: Confidence,\n",
      "          }\n",
      "        ],\n",
      "        // Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\n",
      "        sections_detected: string[] or null,\n",
      "      },\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"MONOCEROS\",\n",
      "          \"unique_shipping_slot_id\": \"QB1148678055\",\n",
      "          \"shipper\": \"Robinson Grain\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-07-31\",\n",
      "          \"status\": \"Completed\"\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"CETUS SEI\",\n",
      "          \"unique_shipping_slot_id\": \"QB5305788574\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-07-05\",\n",
      "          \"status\": \"Completed\"\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"The 'tons' value was coerced from a string to an integer after removing commas. Dates were normalized to ISO 8601 format.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of Ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match with alias 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Direct match with alias 'quantity(tonnes)'. Converted from string with commas to integer.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match with alias 'date of eta of ship to'. Dates reformatted to ISO 8601.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"rationale\": \"Direct match with an alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class MappedTable)---\u001b[0m\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"MONOCEROS\",\n",
      "          \"unique_shipping_slot_id\": \"QB1148678055\",\n",
      "          \"shipper\": \"Robinson Grain\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-07-31\",\n",
      "          \"status\": \"Completed\"\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"CETUS SEI\",\n",
      "          \"unique_shipping_slot_id\": \"QB5305788574\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-07-05\",\n",
      "          \"status\": \"Completed\"\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Date of ETD of Ship\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"The 'tons' value was coerced from a string to an integer after removing commas. Dates were normalized to ISO 8601 format.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct match with alias 'port'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of Ship\",\n",
      "            \"rationale\": \"Direct match with alias 'name of ship'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct match with alias 'unique slot reference number'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct match with alias 'exporter'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct match with alias 'commodity'.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Direct match with alias 'quantity(tonnes)'. Converted from string with commas to integer.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct match with alias 'date of eta of ship to'. Dates reformatted to ISO 8601.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: Loading \\\"commenced\\\" or \\\"completed\\\"\",\n",
      "            \"rationale\": \"Direct match with an alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "2026-02-02T19:11:06.974 [BAML \u001b[92mINFO\u001b[0m] \u001b[35mFunction MapToCanonicalSchema\u001b[0m:\n",
      "    \u001b[33mClient: openai/gpt-4o (gpt-4o-2024-08-06) - 13728ms. StopReason: stop. Tokens(in/out): 1693/784\u001b[0m\n",
      "    \u001b[34m---PROMPT---\u001b[0m\n",
      "    \u001b[2m\u001b[43msystem: \u001b[0m\u001b[2mYou are a data mapper. Given a parsed table and a canonical schema, map each data row\n",
      "    to the canonical schema columns.\n",
      "    \n",
      "    Mapping rules:\n",
      "    1. Match source columns to canonical columns using name, aliases, and description.\n",
      "    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n",
      "    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n",
      "    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n",
      "    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n",
      "    6. List any source columns that could not be mapped in unmapped_columns.\n",
      "    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n",
      "       (especially when its aliases list is empty), look for its value in the\n",
      "       surrounding context:\n",
      "       - Section headers or group labels that appear above or between data groups\n",
      "       - Document title, subtitle, or metadata lines\n",
      "       - Repeated contextual values that apply to all rows in a group\n",
      "       When a value is inferred from context, apply it to ALL rows in that section.\n",
      "       The parsed_table's notes field may contain section boundary information.\n",
      "    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n",
      "       metadata explaining:\n",
      "       - Where the value came from (source)\n",
      "       - Why this mapping was chosen (rationale)\n",
      "       - How confident you are (High = direct name/alias match,\n",
      "         Medium = inferred from context with reasonable certainty,\n",
      "         Low = best guess or ambiguous)\n",
      "    9. Set metadata.model to \"openai/gpt-4o\" (it will be provided).\n",
      "    10. If the text had section labels, list them in metadata.sections_detected.\n",
      "    \n",
      "    Parsed table:\n",
      "    {\n",
      "        \"aggregations\": null,\n",
      "        \"data_rows\": [\n",
      "            [\n",
      "                \"QB7157365064\",\n",
      "                \"SOUTHGATE\",\n",
      "                \"16-04-2025\",\n",
      "                \"08:05:00 PM\",\n",
      "                \"17-04-2025\",\n",
      "                \"05:36:00 AM\",\n",
      "                \"Brisbane\",\n",
      "                \"05-05-2025\",\n",
      "                \"01:40:00 PM\",\n",
      "                \"12-05-2025\",\n",
      "                \"01:40:00 PM\",\n",
      "                \"09-05-2025\",\n",
      "                \"10:47:00 AM\",\n",
      "                \"13-05-2025\",\n",
      "                \"09:00:00 AM\",\n",
      "                \"Wilmar Trading Australia\",\n",
      "                \"30,000\",\n",
      "                \"QBT Sorghum\",\n",
      "                \"Completed\",\n",
      "                \"13-05-2025\",\n",
      "                \"04:35:00 AM\",\n",
      "                \"Last updated on:: 30-09-2025 06:00 AM\",\n",
      "            ],\n",
      "            [\n",
      "                \"QB5815500230\",\n",
      "                \"TBA\",\n",
      "                \"29-04-2025\",\n",
      "                \"01:00:00 PM\",\n",
      "                \"02-05-2025\",\n",
      "                \"02:59:00 PM\",\n",
      "                \"Brisbane\",\n",
      "                \"10-11-2025\",\n",
      "                \"04:00:00 PM\",\n",
      "                \"20-11-2025\",\n",
      "                \"04:00:00 PM\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Louis Dreyfus Company Grains Australia Pty Ltd\",\n",
      "                \"30,000\",\n",
      "                \"QBT Chickpeas\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"\",\n",
      "                \"Last updated on:: 30-09-2025 06:00 AM\",\n",
      "            ],\n",
      "        ],\n",
      "        \"headers\": {\n",
      "            \"levels\": 1,\n",
      "            \"names\": [\n",
      "                [\n",
      "                    \"Unique Slot Reference Number\",\n",
      "                    \"Name of ship\",\n",
      "                    \"Date at which nomination was received\",\n",
      "                    \"Time at which nomination was received\",\n",
      "                    \"Date at which nomination was accepted\",\n",
      "                    \"Time at which nomination was accepted\",\n",
      "                    \"Port\",\n",
      "                    \"Date of ETA of Ship From\",\n",
      "                    \"Time of ETA of Ship From\",\n",
      "                    \"Date of ETA of Ship To\",\n",
      "                    \"Time of ETA of Ship To\",\n",
      "                    \"Date ETA of Grain Loading Commencement\",\n",
      "                    \"Time ETA of Grain Loading Commencement\",\n",
      "                    \"Date of ETD of Ship\",\n",
      "                    \"Time of ETD of Ship\",\n",
      "                    \"Exporter\",\n",
      "                    \"Quantity(tonnes)\",\n",
      "                    \"Commodity\",\n",
      "                    \"\\\"Loading commenced or completed\\\"\",\n",
      "                    \"Date Loading Completed\",\n",
      "                    \"Time Loading Completed\",\n",
      "                    \"Notes\",\n",
      "                ],\n",
      "            ],\n",
      "        },\n",
      "        \"notes\": null,\n",
      "        \"table_type\": FlatHeader,\n",
      "    }\n",
      "    \n",
      "    Canonical schema:\n",
      "    {\n",
      "        \"columns\": [\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"port\",\n",
      "                ],\n",
      "                \"description\": \"Loading port name\",\n",
      "                \"name\": \"load_port\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"name of ship\",\n",
      "                ],\n",
      "                \"description\": \"Name of the vessel\",\n",
      "                \"name\": \"vessel_name\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"unique slot reference number\",\n",
      "                ],\n",
      "                \"description\": \"Reference number\",\n",
      "                \"name\": \"unique_shipping_slot_id\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"exporter\",\n",
      "                ],\n",
      "                \"description\": \"Exporting company\",\n",
      "                \"name\": \"shipper\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"commodity\",\n",
      "                ],\n",
      "                \"description\": \"Type of commodity\",\n",
      "                \"name\": \"commodity\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"quantity(tonnes)\",\n",
      "                ],\n",
      "                \"description\": \"Quantity in metric tonnes\",\n",
      "                \"name\": \"tons\",\n",
      "                \"type\": \"int\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"date of eta of ship to\",\n",
      "                ],\n",
      "                \"description\": \"Estimated time of arrival\",\n",
      "                \"name\": \"eta\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "            {\n",
      "                \"aliases\": [\n",
      "                    \"Status\",\n",
      "                    \"loading ' commenced' or ' completed'\",\n",
      "                ],\n",
      "                \"description\": \"Loading status\",\n",
      "                \"name\": \"status\",\n",
      "                \"type\": \"string\",\n",
      "            },\n",
      "        ],\n",
      "        \"description\": \"Shipping stem vessel loading records\",\n",
      "    }\n",
      "    \n",
      "    Confidence\n",
      "    ----\n",
      "    - High: Direct column match by name or alias\n",
      "    - Medium: Inferred from context with reasonable certainty (section header, title, etc.)\n",
      "    - Low: Best guess — ambiguous source or weak contextual signal\n",
      "    \n",
      "    Answer in JSON using this schema:\n",
      "    {\n",
      "      // Mapped data records conforming to the canonical schema\n",
      "      records: [\n",
      "        {\n",
      "          load_port: string or null,\n",
      "          vessel_name: string or null,\n",
      "          unique_shipping_slot_id: string or null,\n",
      "          shipper: string or null,\n",
      "          commodity: string or null,\n",
      "          tons: int or null,\n",
      "          eta: string or null,\n",
      "          status: string or null,\n",
      "        }\n",
      "      ],\n",
      "      // Source columns that could not be mapped to any canonical column\n",
      "      unmapped_columns: string[],\n",
      "      // Notes about the mapping process, e.g. ambiguous matches or type coercion issues\n",
      "      mapping_notes: string or null,\n",
      "      // Metadata about the interpretation: model used, per-field mapping rationale, detected sections\n",
      "      metadata: {\n",
      "        // Model that produced this result, e.g. 'openai/gpt-4o'\n",
      "        model: string,\n",
      "        // One entry per canonical column, explaining how it was resolved\n",
      "        field_mappings: [\n",
      "          {\n",
      "            // Canonical column name from the schema\n",
      "            column_name: string,\n",
      "            // Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\n",
      "            source: string,\n",
      "            // Brief explanation of why this mapping was chosen\n",
      "            rationale: string,\n",
      "            confidence: Confidence,\n",
      "          }\n",
      "        ],\n",
      "        // Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\n",
      "        sections_detected: string[] or null,\n",
      "      },\n",
      "    }\n",
      "    \u001b[0m\n",
      "    \u001b[34m---LLM REPLY---\u001b[0m\n",
      "    \u001b[2m```json\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"SOUTHGATE\",\n",
      "          \"unique_shipping_slot_id\": \"QB7157365064\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-05-12\",\n",
      "          \"status\": \"Completed\"\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB5815500230\",\n",
      "          \"shipper\": \"Louis Dreyfus Company Grains Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-11-20\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Status column mapping was ambiguous as the provided data did not have a direct column match for 'Status'.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct column match with 'port', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Direct column match with 'Name of ship', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct column match with 'Unique Slot Reference Number', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct column match with 'Exporter', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct column match with 'Commodity', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Direct column match with 'Quantity(tonnes)', a recognized alias and value coerced to int.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct column match with 'Date of ETA of Ship To', a recognized alias. Date normalized to ISO 8601 format.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: \\\"Loading commenced or completed\\\"\",\n",
      "            \"rationale\": \"Mapped from ambiguously named 'Loading commenced or completed', which aligns with the expected status.\",\n",
      "            \"confidence\": \"Medium\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "    ```\u001b[0m\n",
      "    \u001b[34m---Parsed Response (class MappedTable)---\u001b[0m\n",
      "    {\n",
      "      \"records\": [\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"SOUTHGATE\",\n",
      "          \"unique_shipping_slot_id\": \"QB7157365064\",\n",
      "          \"shipper\": \"Wilmar Trading Australia\",\n",
      "          \"commodity\": \"QBT Sorghum\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-05-12\",\n",
      "          \"status\": \"Completed\"\n",
      "        },\n",
      "        {\n",
      "          \"load_port\": \"Brisbane\",\n",
      "          \"vessel_name\": \"TBA\",\n",
      "          \"unique_shipping_slot_id\": \"QB5815500230\",\n",
      "          \"shipper\": \"Louis Dreyfus Company Grains Australia Pty Ltd\",\n",
      "          \"commodity\": \"QBT Chickpeas\",\n",
      "          \"tons\": 30000,\n",
      "          \"eta\": \"2025-11-20\",\n",
      "          \"status\": null\n",
      "        }\n",
      "      ],\n",
      "      \"unmapped_columns\": [\n",
      "        \"Date at which nomination was received\",\n",
      "        \"Time at which nomination was received\",\n",
      "        \"Date at which nomination was accepted\",\n",
      "        \"Time at which nomination was accepted\",\n",
      "        \"Date of ETA of Ship From\",\n",
      "        \"Time of ETA of Ship From\",\n",
      "        \"Date ETA of Grain Loading Commencement\",\n",
      "        \"Time ETA of Grain Loading Commencement\",\n",
      "        \"Time of ETD of Ship\",\n",
      "        \"Date Loading Completed\",\n",
      "        \"Time Loading Completed\",\n",
      "        \"Notes\"\n",
      "      ],\n",
      "      \"mapping_notes\": \"Status column mapping was ambiguous as the provided data did not have a direct column match for 'Status'.\",\n",
      "      \"metadata\": {\n",
      "        \"model\": \"openai/gpt-4o\",\n",
      "        \"field_mappings\": [\n",
      "          {\n",
      "            \"column_name\": \"load_port\",\n",
      "            \"source\": \"column: Port\",\n",
      "            \"rationale\": \"Direct column match with 'port', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"vessel_name\",\n",
      "            \"source\": \"column: Name of ship\",\n",
      "            \"rationale\": \"Direct column match with 'Name of ship', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"unique_shipping_slot_id\",\n",
      "            \"source\": \"column: Unique Slot Reference Number\",\n",
      "            \"rationale\": \"Direct column match with 'Unique Slot Reference Number', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"shipper\",\n",
      "            \"source\": \"column: Exporter\",\n",
      "            \"rationale\": \"Direct column match with 'Exporter', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"commodity\",\n",
      "            \"source\": \"column: Commodity\",\n",
      "            \"rationale\": \"Direct column match with 'Commodity', a recognized alias.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"tons\",\n",
      "            \"source\": \"column: Quantity(tonnes)\",\n",
      "            \"rationale\": \"Direct column match with 'Quantity(tonnes)', a recognized alias and value coerced to int.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"eta\",\n",
      "            \"source\": \"column: Date of ETA of Ship To\",\n",
      "            \"rationale\": \"Direct column match with 'Date of ETA of Ship To', a recognized alias. Date normalized to ISO 8601 format.\",\n",
      "            \"confidence\": \"High\"\n",
      "          },\n",
      "          {\n",
      "            \"column_name\": \"status\",\n",
      "            \"source\": \"column: \\\"Loading commenced or completed\\\"\",\n",
      "            \"rationale\": \"Mapped from ambiguously named 'Loading commenced or completed', which aligns with the expected status.\",\n",
      "            \"confidence\": \"Medium\"\n",
      "          }\n",
      "        ],\n",
      "        \"sections_detected\": null\n",
      "      }\n",
      "    }\n",
      "Records extracted (vision): 14\n",
      "Page 1: 2 records, unmapped=['Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "Page 2: 2 records, unmapped=['Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "Page 3: 2 records, unmapped=['Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Date Loading Completed', 'Time Loading Completed']\n",
      "Page 4: 2 records, unmapped=['Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Time of ETD of Ship', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "Page 5: 2 records, unmapped=['Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "Page 6: 2 records, unmapped=['Date Nomination Received', 'Time Nomination Received', 'Date Nomination Accepted', 'Time Nomination Accepted', 'Date of ETA of Ship From', 'Time of ETA of Ship From', 'Time of ETA of Ship To', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "Page 7: 2 records, unmapped=['Date at which nomination was received', 'Time at which nomination was received', 'Date at which nomination was accepted', 'Time at which nomination was accepted', 'Time of ETA of Ship From', 'Date ETA of Grain Loading Commencement', 'Time ETA of Grain Loading Commencement', 'Date of ETD of Ship', 'Time of ETD of Ship', 'Time of ETA of Ship To', 'Date Loading Completed', 'Time Loading Completed', 'Notes']\n",
      "\n",
      "--- First 5 records ---\n",
      "\n",
      "[1] {'load_port': 'Brisbane', 'vessel_name': 'DARYA DIYA', 'unique_shipping_slot_id': 'QB2061036115', 'shipper': 'Arrow Commodities Pty Ltd', 'commodity': 'QBT Wheat', 'tons': 30000, 'eta': '2025-09-30', 'status': None}\n",
      "[2] {'load_port': 'Brisbane', 'vessel_name': 'MH ADAGIO', 'unique_shipping_slot_id': 'QB3126604877', 'shipper': 'Arrow Commodities Pty Ltd', 'commodity': 'QBT Wheat', 'tons': 30000, 'eta': '2025-07-31', 'status': 'Completed'}\n",
      "[3] {'load_port': 'Brisbane', 'vessel_name': 'MONOCEROS', 'unique_shipping_slot_id': 'QB1148678055', 'shipper': 'Robinson Grain', 'commodity': 'QBT Sorghum', 'tons': 30000, 'eta': '2025-07-31', 'status': 'Completed'}\n",
      "[4] {'load_port': 'Brisbane', 'vessel_name': 'CETUS SEI', 'unique_shipping_slot_id': 'QB5305788574', 'shipper': 'Wilmar Trading Australia', 'commodity': 'QBT Sorghum', 'tons': 30000, 'eta': '2025-07-05', 'status': 'Completed'}\n",
      "[5] {'load_port': 'Brisbane', 'vessel_name': 'TOMINI OROSHI', 'unique_shipping_slot_id': 'QB0357578736', 'shipper': 'Wilmar Trading Australia', 'commodity': 'QBT Sorghum', 'tons': 30000, 'eta': '2025-06-22', 'status': 'Completed'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'records': [{'load_port': 'Brisbane',\n",
       "    'vessel_name': 'DARYA DIYA',\n",
       "    'unique_shipping_slot_id': 'QB2061036115',\n",
       "    'shipper': 'Arrow Commodities Pty Ltd',\n",
       "    'commodity': 'QBT Wheat',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-09-30',\n",
       "    'status': None},\n",
       "   {'load_port': 'Brisbane',\n",
       "    'vessel_name': 'MH ADAGIO',\n",
       "    'unique_shipping_slot_id': 'QB3126604877',\n",
       "    'shipper': 'Arrow Commodities Pty Ltd',\n",
       "    'commodity': 'QBT Wheat',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-07-31',\n",
       "    'status': 'Completed'}],\n",
       "  'unmapped_columns': ['Date at which nomination was received',\n",
       "   'Time at which nomination was received',\n",
       "   'Date at which nomination was accepted',\n",
       "   'Time at which nomination was accepted',\n",
       "   'Date of ETA of Ship From',\n",
       "   'Time of ETA of Ship From',\n",
       "   'Date ETA of Grain Loading Commencement',\n",
       "   'Time ETA of Grain Loading Commencement',\n",
       "   'Date of ETD of Ship',\n",
       "   'Time of ETD of Ship',\n",
       "   'Date Loading Completed',\n",
       "   'Time Loading Completed',\n",
       "   'Notes'],\n",
       "  'mapping_notes': 'Status mapping is ambiguous due to column encoding issues.',\n",
       "  'metadata': {'model': 'openai/gpt-4o',\n",
       "   'field_mappings': [{'column_name': 'load_port',\n",
       "     'source': 'column: Port',\n",
       "     'rationale': \"Direct match with alias 'port'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'vessel_name',\n",
       "     'source': 'column: Name of ship',\n",
       "     'rationale': \"Direct match with alias 'name of ship'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'unique_shipping_slot_id',\n",
       "     'source': 'column: Unique Slot Reference Number',\n",
       "     'rationale': \"Alias match with 'unique slot reference number'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'shipper',\n",
       "     'source': 'column: Exporter',\n",
       "     'rationale': \"Exact match with alias 'exporter'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'commodity',\n",
       "     'source': 'column: Commodity',\n",
       "     'rationale': \"Exact match with alias 'commodity'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'tons',\n",
       "     'source': 'column: Quantity(tonnes)',\n",
       "     'rationale': \"Alias match with 'quantity(tonnes)'. Value coerced to int from string.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'eta',\n",
       "     'source': 'column: Date of ETA of Ship To',\n",
       "     'rationale': \"Exact match with alias 'date of eta of ship to'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'status',\n",
       "     'source': 'column: \"Loading \"\"commenced\"\" or \"\"completed\"\"\"',\n",
       "     'rationale': 'Closest match to ambiguously encoded loading status.',\n",
       "     'confidence': <Confidence.Low: 'Low'>}],\n",
       "   'sections_detected': None}},\n",
       " 2: {'records': [{'load_port': 'Brisbane',\n",
       "    'vessel_name': 'MONOCEROS',\n",
       "    'unique_shipping_slot_id': 'QB1148678055',\n",
       "    'shipper': 'Robinson Grain',\n",
       "    'commodity': 'QBT Sorghum',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-07-31',\n",
       "    'status': 'Completed'},\n",
       "   {'load_port': 'Brisbane',\n",
       "    'vessel_name': 'CETUS SEI',\n",
       "    'unique_shipping_slot_id': 'QB5305788574',\n",
       "    'shipper': 'Wilmar Trading Australia',\n",
       "    'commodity': 'QBT Sorghum',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-07-05',\n",
       "    'status': 'Completed'}],\n",
       "  'unmapped_columns': ['Date at which nomination was received',\n",
       "   'Time at which nomination was received',\n",
       "   'Date at which nomination was accepted',\n",
       "   'Time at which nomination was accepted',\n",
       "   'Date of ETA of Ship From',\n",
       "   'Time of ETA of Ship From',\n",
       "   'Date ETA of Grain Loading Commencement',\n",
       "   'Time ETA of Grain Loading Commencement',\n",
       "   'Date of ETD of Ship',\n",
       "   'Time of ETD of Ship',\n",
       "   'Date Loading Completed',\n",
       "   'Time Loading Completed',\n",
       "   'Notes'],\n",
       "  'mapping_notes': \"The 'tons' value was coerced from a string to an integer after removing commas. Dates were normalized to ISO 8601 format.\",\n",
       "  'metadata': {'model': 'openai/gpt-4o',\n",
       "   'field_mappings': [{'column_name': 'load_port',\n",
       "     'source': 'column: Port',\n",
       "     'rationale': \"Direct match with alias 'port'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'vessel_name',\n",
       "     'source': 'column: Name of Ship',\n",
       "     'rationale': \"Direct match with alias 'name of ship'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'unique_shipping_slot_id',\n",
       "     'source': 'column: Unique Slot Reference Number',\n",
       "     'rationale': \"Direct match with alias 'unique slot reference number'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'shipper',\n",
       "     'source': 'column: Exporter',\n",
       "     'rationale': \"Direct match with alias 'exporter'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'commodity',\n",
       "     'source': 'column: Commodity',\n",
       "     'rationale': \"Direct match with alias 'commodity'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'tons',\n",
       "     'source': 'column: Quantity(tonnes)',\n",
       "     'rationale': \"Direct match with alias 'quantity(tonnes)'. Converted from string with commas to integer.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'eta',\n",
       "     'source': 'column: Date of ETA of Ship To',\n",
       "     'rationale': \"Direct match with alias 'date of eta of ship to'. Dates reformatted to ISO 8601.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'status',\n",
       "     'source': 'column: Loading \"commenced\" or \"completed\"',\n",
       "     'rationale': 'Direct match with an alias.',\n",
       "     'confidence': <Confidence.High: 'High'>}],\n",
       "   'sections_detected': None}},\n",
       " 3: {'records': [{'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TOMINI OROSHI',\n",
       "    'unique_shipping_slot_id': 'QB0357578736',\n",
       "    'shipper': 'Wilmar Trading Australia',\n",
       "    'commodity': 'QBT Sorghum',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-06-22',\n",
       "    'status': 'Completed'},\n",
       "   {'load_port': 'Brisbane',\n",
       "    'vessel_name': 'UBC TAKORADI',\n",
       "    'unique_shipping_slot_id': 'QB7412357677',\n",
       "    'shipper': 'Wilmar Trading Australia',\n",
       "    'commodity': 'QBT Sorghum',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-06-15',\n",
       "    'status': 'Completed'}],\n",
       "  'unmapped_columns': ['Date at which nomination was received',\n",
       "   'Time at which nomination was received',\n",
       "   'Date at which nomination was accepted',\n",
       "   'Time at which nomination was accepted',\n",
       "   'Date of ETA of Ship From',\n",
       "   'Time of ETA of Ship From',\n",
       "   'Time of ETA of Ship To',\n",
       "   'Date ETA of Grain Loading Commencement',\n",
       "   'Time ETA of Grain Loading Commencement',\n",
       "   'Date of ETD of Ship',\n",
       "   'Time of ETD of Ship',\n",
       "   'Date Loading Completed',\n",
       "   'Time Loading Completed'],\n",
       "  'mapping_notes': 'Date values for ETA normalized to ISO format. Tons coerced from string to int.',\n",
       "  'metadata': {'model': 'openai/gpt-4o',\n",
       "   'field_mappings': [{'column_name': 'load_port',\n",
       "     'source': 'column: Port',\n",
       "     'rationale': \"Direct match with alias 'port'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'vessel_name',\n",
       "     'source': 'column: Name of ship',\n",
       "     'rationale': \"Direct match with alias 'name of ship'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'unique_shipping_slot_id',\n",
       "     'source': 'column: Unique Slot Reference Number',\n",
       "     'rationale': \"Direct match with alias 'unique slot reference number'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'shipper',\n",
       "     'source': 'column: Exporter',\n",
       "     'rationale': \"Direct match with alias 'exporter'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'commodity',\n",
       "     'source': 'column: Commodity',\n",
       "     'rationale': \"Direct match with alias 'commodity'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'tons',\n",
       "     'source': 'column: Quantity(tonnes)',\n",
       "     'rationale': \"Direct match with alias 'quantity(tonnes)'. Value coerced to integer.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'eta',\n",
       "     'source': 'column: Date of ETA of Ship To',\n",
       "     'rationale': \"Direct match with alias 'date of eta of ship to'. Date normalized.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'status',\n",
       "     'source': 'column: Loading \"commenced\" or \"completed\"',\n",
       "     'rationale': 'Direct match with alias \\'loading \"commenced\" or \"completed\"\\'.',\n",
       "     'confidence': <Confidence.High: 'High'>}],\n",
       "   'sections_detected': None}},\n",
       " 4: {'records': [{'load_port': 'Brisbane',\n",
       "    'vessel_name': 'SOUTHGATE',\n",
       "    'unique_shipping_slot_id': 'QB7157365064',\n",
       "    'shipper': 'Wilmar Trading Australia',\n",
       "    'commodity': 'QBT Sorghum',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-05-12',\n",
       "    'status': 'Completed'},\n",
       "   {'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TBA',\n",
       "    'unique_shipping_slot_id': 'QB5815500230',\n",
       "    'shipper': 'Louis Dreyfus Company Grains Australia Pty Ltd',\n",
       "    'commodity': 'QBT Chickpeas',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-11-20',\n",
       "    'status': None}],\n",
       "  'unmapped_columns': ['Date at which nomination was received',\n",
       "   'Time at which nomination was received',\n",
       "   'Date at which nomination was accepted',\n",
       "   'Time at which nomination was accepted',\n",
       "   'Date of ETA of Ship From',\n",
       "   'Time of ETA of Ship From',\n",
       "   'Date ETA of Grain Loading Commencement',\n",
       "   'Time ETA of Grain Loading Commencement',\n",
       "   'Time of ETD of Ship',\n",
       "   'Date Loading Completed',\n",
       "   'Time Loading Completed',\n",
       "   'Notes'],\n",
       "  'mapping_notes': \"Status column mapping was ambiguous as the provided data did not have a direct column match for 'Status'.\",\n",
       "  'metadata': {'model': 'openai/gpt-4o',\n",
       "   'field_mappings': [{'column_name': 'load_port',\n",
       "     'source': 'column: Port',\n",
       "     'rationale': \"Direct column match with 'port', a recognized alias.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'vessel_name',\n",
       "     'source': 'column: Name of ship',\n",
       "     'rationale': \"Direct column match with 'Name of ship', a recognized alias.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'unique_shipping_slot_id',\n",
       "     'source': 'column: Unique Slot Reference Number',\n",
       "     'rationale': \"Direct column match with 'Unique Slot Reference Number', a recognized alias.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'shipper',\n",
       "     'source': 'column: Exporter',\n",
       "     'rationale': \"Direct column match with 'Exporter', a recognized alias.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'commodity',\n",
       "     'source': 'column: Commodity',\n",
       "     'rationale': \"Direct column match with 'Commodity', a recognized alias.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'tons',\n",
       "     'source': 'column: Quantity(tonnes)',\n",
       "     'rationale': \"Direct column match with 'Quantity(tonnes)', a recognized alias and value coerced to int.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'eta',\n",
       "     'source': 'column: Date of ETA of Ship To',\n",
       "     'rationale': \"Direct column match with 'Date of ETA of Ship To', a recognized alias. Date normalized to ISO 8601 format.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'status',\n",
       "     'source': 'column: \"Loading commenced or completed\"',\n",
       "     'rationale': \"Mapped from ambiguously named 'Loading commenced or completed', which aligns with the expected status.\",\n",
       "     'confidence': <Confidence.Medium: 'Medium'>}],\n",
       "   'sections_detected': None}},\n",
       " 5: {'records': [{'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TBA',\n",
       "    'unique_shipping_slot_id': 'QB2771655637',\n",
       "    'shipper': 'Louis Dreyfus Company\\nGrains Australia Pty Ltd',\n",
       "    'commodity': 'QBT Chickpeas',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-11-30',\n",
       "    'status': None},\n",
       "   {'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TBA',\n",
       "    'unique_shipping_slot_id': 'QB1541470610',\n",
       "    'shipper': 'Louis Dreyfus Company\\nGrains Australia Pty Ltd',\n",
       "    'commodity': 'QBT Chickpeas',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-12-15',\n",
       "    'status': None}],\n",
       "  'unmapped_columns': ['Date at which nomination was received',\n",
       "   'Time at which nomination was received',\n",
       "   'Date at which nomination was accepted',\n",
       "   'Time at which nomination was accepted',\n",
       "   'Date of ETA of Ship From',\n",
       "   'Time of ETA of Ship From',\n",
       "   'Time of ETA of Ship To',\n",
       "   'Date ETA of Grain Loading Commencement',\n",
       "   'Time ETA of Grain Loading Commencement',\n",
       "   'Date of ETD of Ship',\n",
       "   'Time of ETD of Ship',\n",
       "   'Date Loading Completed',\n",
       "   'Time Loading Completed',\n",
       "   'Notes'],\n",
       "  'mapping_notes': \"The column 'Status' could not be mapped as there is no available data matching its description.\",\n",
       "  'metadata': {'model': 'openai/gpt-4o',\n",
       "   'field_mappings': [{'column_name': 'load_port',\n",
       "     'source': 'column: Port',\n",
       "     'rationale': \"Direct match with alias 'port'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'vessel_name',\n",
       "     'source': 'column: Name of Ship',\n",
       "     'rationale': \"Direct match with alias 'name of ship'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'unique_shipping_slot_id',\n",
       "     'source': 'column: Unique Slot Reference Number',\n",
       "     'rationale': \"Direct match with alias 'unique slot reference number'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'shipper',\n",
       "     'source': 'column: Exporter',\n",
       "     'rationale': \"Direct match with alias 'exporter'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'commodity',\n",
       "     'source': 'column: Commodity',\n",
       "     'rationale': \"Direct match with alias 'commodity'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'tons',\n",
       "     'source': 'column: Quantity (tonnes)',\n",
       "     'rationale': \"Match with 'quantity (tonnes)' after removing parenthesis.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'eta',\n",
       "     'source': 'column: Date of ETA of Ship To',\n",
       "     'rationale': \"Direct match with alias 'date of eta of ship to'.\",\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'status',\n",
       "     'source': 'N/A',\n",
       "     'rationale': \"No matching column or context clue for 'Loading status'.\",\n",
       "     'confidence': <Confidence.Low: 'Low'>}],\n",
       "   'sections_detected': None}},\n",
       " 6: {'records': [{'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TBA',\n",
       "    'unique_shipping_slot_id': 'QB3582536041',\n",
       "    'shipper': 'Louis Dreyfus Company',\n",
       "    'commodity': 'QBT Chickpeas',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-12-30',\n",
       "    'status': None},\n",
       "   {'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TBA',\n",
       "    'unique_shipping_slot_id': 'QB1566785655',\n",
       "    'shipper': 'ADM Trading Australia Pty Ltd',\n",
       "    'commodity': 'QBT Chickpeas',\n",
       "    'tons': 30000,\n",
       "    'eta': '2026-01-15',\n",
       "    'status': None}],\n",
       "  'unmapped_columns': ['Date Nomination Received',\n",
       "   'Time Nomination Received',\n",
       "   'Date Nomination Accepted',\n",
       "   'Time Nomination Accepted',\n",
       "   'Date of ETA of Ship From',\n",
       "   'Time of ETA of Ship From',\n",
       "   'Time of ETA of Ship To',\n",
       "   'Date ETA of Grain Loading Commencement',\n",
       "   'Time ETA of Grain Loading Commencement',\n",
       "   'Date of ETD of Ship',\n",
       "   'Time of ETD of Ship',\n",
       "   'Date Loading Completed',\n",
       "   'Time Loading Completed',\n",
       "   'Notes'],\n",
       "  'mapping_notes': \"Some columns such as loading status could not be fully mapped as there wasn't enough information. Coerced quantity to int type.\",\n",
       "  'metadata': {'model': 'openai/gpt-4o',\n",
       "   'field_mappings': [{'column_name': 'load_port',\n",
       "     'source': 'column: Port',\n",
       "     'rationale': 'Direct match by alias and description.',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'vessel_name',\n",
       "     'source': 'column: Name of Ship',\n",
       "     'rationale': 'Direct match by alias.',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'unique_shipping_slot_id',\n",
       "     'source': 'column: Unique Slot Reference Number',\n",
       "     'rationale': 'Direct match by alias.',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'shipper',\n",
       "     'source': 'column: Exporter',\n",
       "     'rationale': 'Direct match by alias.',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'commodity',\n",
       "     'source': 'column: Commodity',\n",
       "     'rationale': 'Direct match by both name and alias.',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'tons',\n",
       "     'source': 'column: Quantity (tonnes)',\n",
       "     'rationale': 'Direct match by name, using value coercion from string.',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'eta',\n",
       "     'source': 'column: Date of ETA of Ship To',\n",
       "     'rationale': 'Direct match by alias.',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'status',\n",
       "     'source': 'column: Loading Status',\n",
       "     'rationale': 'Not applicable as there was no data present.',\n",
       "     'confidence': <Confidence.Low: 'Low'>}],\n",
       "   'sections_detected': None}},\n",
       " 7: {'records': [{'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TBA',\n",
       "    'unique_shipping_slot_id': 'QB5345742564',\n",
       "    'shipper': 'ADM Trading Australia Pty Ltd',\n",
       "    'commodity': 'QBT Chickpeas',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-12-15',\n",
       "    'status': None},\n",
       "   {'load_port': 'Brisbane',\n",
       "    'vessel_name': 'TBA',\n",
       "    'unique_shipping_slot_id': 'QB2687807116',\n",
       "    'shipper': 'ADM Trading Australia Pty Ltd',\n",
       "    'commodity': 'QBT Chickpeas',\n",
       "    'tons': 30000,\n",
       "    'eta': '2025-11-30',\n",
       "    'status': None}],\n",
       "  'unmapped_columns': ['Date at which nomination was received',\n",
       "   'Time at which nomination was received',\n",
       "   'Date at which nomination was accepted',\n",
       "   'Time at which nomination was accepted',\n",
       "   'Time of ETA of Ship From',\n",
       "   'Date ETA of Grain Loading Commencement',\n",
       "   'Time ETA of Grain Loading Commencement',\n",
       "   'Date of ETD of Ship',\n",
       "   'Time of ETD of Ship',\n",
       "   'Time of ETA of Ship To',\n",
       "   'Date Loading Completed',\n",
       "   'Time Loading Completed',\n",
       "   'Notes'],\n",
       "  'mapping_notes': \"The 'Status' field could not be mapped as there are no explicit matches or context to infer its value. 'Tons' value was coerced from the formatted string to integer. Dates were normalized to the ISO 8601 format.\",\n",
       "  'metadata': {'model': 'openai/gpt-4o',\n",
       "   'field_mappings': [{'column_name': 'load_port',\n",
       "     'source': 'column: Port',\n",
       "     'rationale': 'Direct name match',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'vessel_name',\n",
       "     'source': 'column: Name of ship',\n",
       "     'rationale': 'Alias match',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'unique_shipping_slot_id',\n",
       "     'source': 'column: Unique Slot Reference Number',\n",
       "     'rationale': 'Alias match',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'shipper',\n",
       "     'source': 'column: Exporter',\n",
       "     'rationale': 'Alias match',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'commodity',\n",
       "     'source': 'column: Commodity',\n",
       "     'rationale': 'Alias match',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'tons',\n",
       "     'source': 'column: Quantity(tonnes)',\n",
       "     'rationale': 'Alias match with coercion from string to integer',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'eta',\n",
       "     'source': 'column: Date of ETA of Ship To',\n",
       "     'rationale': 'Alias match with date normalization',\n",
       "     'confidence': <Confidence.High: 'High'>},\n",
       "    {'column_name': 'status',\n",
       "     'source': 'None',\n",
       "     'rationale': 'No applicable column or context available',\n",
       "     'confidence': <Confidence.Low: 'Low'>}],\n",
       "   'sections_detected': None}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vision-enabled pipeline on the Bunge PDF (garbled stacked headers).\n",
    "\n",
    "queensland_pdf = \"inputs/document (1).pdf\"\n",
    "compressed_queensland = compress_spatial_text(queensland_pdf)\n",
    "print(f\"Compressed chars: {len(compressed_queensland)}\")\n",
    "print(compressed_queensland[:500])\n",
    "print(\"...\")\n",
    "\n",
    "# Define a schema suitable for Bunge loading statements\n",
    "queensland_schema_dict = {\n",
    "    \"description\": \"Shipping stem vessel loading records\",\n",
    "    \"columns\": [\n",
    "        {\"name\": \"load_port\", \"type\": \"string\", \"description\": \"Loading port name\", \"aliases\": [\"port\"]},\n",
    "        {\"name\": \"vessel_name\", \"type\": \"string\", \"description\": \"Name of the vessel\", \"aliases\": [\"name of ship\"]},\n",
    "        {\"name\": \"unique_shipping_slot_id\", \"type\": \"string\", \"description\": \"Reference number\", \"aliases\": [\"unique slot reference number\"]},\n",
    "        {\"name\": \"shipper\", \"type\": \"string\", \"description\": \"Exporting company\", \"aliases\": [\"exporter\"]},\n",
    "        {\"name\": \"commodity\", \"type\": \"string\", \"description\": \"Type of commodity\", \"aliases\": [\"commodity\"]},\n",
    "        {\"name\": \"tons\", \"type\": \"int\",    \"description\": \"Quantity in metric tonnes\", \"aliases\": [\"quantity(tonnes)\"]},\n",
    "        {\"name\": \"eta\", \"type\": \"string\", \"description\": \"Estimated time of arrival\", \"aliases\": [\"date of eta of ship to\"]},\n",
    "        {\"name\": \"status\", \"type\": \"string\", \"description\": \"Loading status\", \"aliases\": [\"Status\", \"loading ' commenced' or ' completed'\"]},\n",
    "    ],\n",
    "}\n",
    "\n",
    "queensland_schema = CanonicalSchema.from_dict(queensland_schema_dict)\n",
    "\n",
    "# Run WITH vision (pdf_path= enables step 0)\n",
    "result_queensland = interpret_table(\n",
    "    compressed_queensland,\n",
    "    queensland_schema,\n",
    "    model=\"openai/gpt-4o\",\n",
    "    pdf_path=queensland_pdf,\n",
    ")\n",
    "\n",
    "# Result is dict[int, MappedTable] — one entry per page\n",
    "records_queensland = to_records(result_queensland)\n",
    "print(f\"Records extracted (vision): {len(records_queensland)}\")\n",
    "for page, mt in sorted(result_queensland.items()):\n",
    "    print(f\"Page {page}: {len(mt.records)} records, unmapped={mt.unmapped_columns}\")\n",
    "print(f\"\\n--- First 5 records ---\\n\")\n",
    "for i, rec in enumerate(records_queensland[:5], 1):\n",
    "    print(f\"[{i}] {rec}\")\n",
    "\n",
    "# Inspect per-page structure: each page has its own records, unmapped_columns, metadata\n",
    "{page: mt.model_dump() for page, mt in result_queensland.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
