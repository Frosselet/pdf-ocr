# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Constant\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\n// client<llm> CustomGemini {\n//   provider google-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     api_key env.GOOGLE_API_KEY\n//   }\n// }\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "compress.baml": "// Compress pipeline: LLM table detection fallback for the spatial text compressor.\n// Header refinement is now handled deterministically by _build_stacked_headers().\n\n// ─── Types ──────────────────────────────────────────────────────────────────\n\nclass DetectedTable {\n  layout TableLayout\n    @description(\"Geometric arrangement of records and fields in the table.\")\n  header_structure HeaderStructure\n    @description(\"Vertical organization of the column labels.\")\n  column_names string[]\n    @description(\"Column headers, one per data column.\")\n  data_rows string[][]\n    @description(\"Data rows. Each inner array has one cell value per column.\")\n  notes string?\n    @description(\"Observations: sections found, aggregation rows excluded, etc.\")\n}\n\n// ─── Functions ──────────────────────────────────────────────────────────────\n\nfunction DetectAndStructureTable(spatial_text: string) -> DetectedTable {\n  client CustomGPT4oMini\n  prompt #\"\n    You are a table-detection analyst. You receive the full monospace spatial text of\n    a PDF page where automated heuristics found NO tables. Your job is to determine\n    if there IS a table on this page, and if so, classify and extract it.\n\n    SPATIAL TEXT (monospace — positions matter):\n    {{ spatial_text }}\n\n    STEPS:\n    1. DETECT: Look for tabular data — rows of values aligned in columns, with or\n       without visible headers, separators, or borders.\n    2. CLASSIFY: If a table is found, determine layout and header_structure using the\n       enum definitions and KEY SIGNS in the output schema below.\n    3. EXTRACT:\n       - Produce clean column names using the structure-specific strategy:\n         SingleRow=direct, Stacked=concatenate, Hierarchical=compound paths.\n       - Extract all data rows (exclude header rows and aggregation/total rows).\n       - Each data row must have the same number of cells as column_names.\n       - Use empty string \"\" for missing/empty cells.\n       - Keep cell values as strings exactly as they appear.\n    4. If there is NO table on this page, return layout=Standard,\n       header_structure=SingleRow, empty column_names [] and empty data_rows [].\n    5. If the page contains non-table text (headings, paragraphs, metadata),\n       ignore it — only extract tabular content.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"go\", \"rust\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.218.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "interpret.baml": "// Table interpretation: extract structured tabular data from compressed PDF text\n// and map it to a user-defined canonical schema.\n\n// ─── Enums ───────────────────────────────────────────────────────────────────\n\nenum TableType {\n  FlatHeader @description(\"Standard table: headers in top row(s), data in subsequent rows. Each column is independent (no spanning parent cells). Header text may wrap across multiple rows vertically but each column stands alone. 1:1 row-to-record mapping. Key sign: first column contains different values per row (IDs, names, categories).\")\n  HierarchicalHeader @description(\"Tree-structured headers where parent cells span horizontally across multiple child columns (e.g. 'Group A' spanning 'Metric 1' and 'Metric 2'). Column names become compound paths (e.g. 'Group A / Metric 1'). Mapping may produce 1:1 records or require unpivoting depending on the canonical schema. Key sign: header row has FEWER cells than data rows because parents span multiple children. Note: stacked/multiline headers with no horizontal spanning are FlatHeader, not this.\")\n  PivotedTable @description(\"Cross-tabulation: row labels are categories, column headers are time periods or attributes, cells are values. Requires unpivoting: each source row produces multiple output records (one per value column). Key sign: column headers are dates, periods, or repeated attribute names; first column contains category labels; cells contain numeric values.\")\n  TransposedTable @description(\"Property sheet layout: field NAMES as rows (left column), field VALUES as columns. Each column (after the label column) represents a complete record. Requires transposition: each column becomes one output record, each row provides one field. Key signs: (1) first column contains field names like 'Name', 'Date', 'Status', 'Total'; (2) subsequent columns contain the corresponding values; (3) rows are heterogeneous (mix of dates, numbers, text) because each row is a different field type.\")\n  Unknown @description(\"Ambiguous structure — use best judgment based on content\")\n}\n\nenum AggregationType {\n  Total\n  Sum\n  Min\n  Max\n  Average\n  Count\n  NoAggregation @alias(\"None\")\n}\n\nenum Confidence {\n  High   @description(\"Direct column match by name or alias\")\n  Medium @description(\"Inferred from context with reasonable certainty (section header, title, etc.)\")\n  Low    @description(\"Best guess — ambiguous source or weak contextual signal\")\n}\n\n// ─── Intermediate pipeline types ─────────────────────────────────────────────\n\nclass HeaderInfo {\n  levels int @description(\"Number of header rows.\")\n  names string[][] @description(\"Header names per level, outer = level, inner = columns.\")\n}\n\nclass AggregationInfo {\n  type AggregationType\n  axis string @description(\"'row' or 'column' — the axis along which aggregation runs\")\n  labels string[] @description(\"Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\")\n}\n\nclass ParsedTable {\n  table_type TableType\n  headers HeaderInfo\n  aggregations AggregationInfo? @description(\"Present only if the table contains aggregation rows/columns\")\n  data_rows string[][] @description(\"All data rows. Each inner array is one row of cell values as strings.\")\n  notes string? @description(\"Any caveats or observations about the table structure\")\n}\n\n// ─── Canonical schema + output types ─────────────────────────────────────────\n\nclass ColumnDef {\n  name string @description(\"Canonical column name\")\n  type string @description(\"Expected type: string, int, float, bool, date\")\n  description string @description(\"What this column represents\")\n  aliases string[] @description(\"Alternative names this column may appear as in source tables\")\n  format string? @description(\"Output format specification. For dates: YYYY-MM-DD, YYYY-MM, HH:mm:ss, etc. For numbers: #,###.## (thousands + decimals), +# (explicit sign), #% (percentage). For strings: uppercase, lowercase, titlecase, camelCase, PascalCase, snake_case, kebab-case, trim.\")\n}\n\nclass CanonicalSchema {\n  columns ColumnDef[]\n  description string? @description(\"Optional description of what this schema represents\")\n}\n\nclass MappedRecord {\n  @@dynamic\n}\n\nclass FieldMapping {\n  column_name string  @description(\"Canonical column name from the schema\")\n  source string       @description(\"Where the value came from, e.g. 'column: Field A', 'section header', 'document title', 'inferred from context'\")\n  rationale string    @description(\"Brief explanation of why this mapping was chosen\")\n  confidence Confidence\n}\n\nclass TableTypeInference {\n  table_type TableType          @description(\"Table type from Step 1 (do not re-classify)\")\n  mapping_strategy_used string  @description(\"Which mapping strategy was applied: '1:1 row mapping', 'unpivot', 'transpose'\")\n}\n\nclass InterpretationMetadata {\n  model string                  @description(\"Model that produced this result, e.g. 'openai/gpt-4o'\")\n  table_type_inference TableTypeInference @description(\"The table type from Step 1 and which mapping strategy was applied\")\n  field_mappings FieldMapping[] @description(\"One entry per canonical column, explaining how it was resolved\")\n  sections_detected string[]?   @description(\"Section/group labels found in the text, if any (e.g. ['GROUP A', 'GROUP B'])\")\n  section_role string?          @description(\"Role of section labels: 'context' or 'grouping'\")\n}\n\nclass MappedTable {\n  records MappedRecord[] @description(\"Mapped data records conforming to the canonical schema\")\n  unmapped_columns string[] @description(\"Source columns that could not be mapped to any canonical column\")\n  mapping_notes string? @description(\"Notes about the mapping process, e.g. ambiguous matches or type coercion issues\")\n  metadata InterpretationMetadata @description(\"Metadata about the interpretation: model used, per-field mapping rationale, detected sections\")\n}\n\n// ─── Vision-based schema inference ──────────────────────────────────────────\n\nclass InferredTableSchema {\n  column_names string[] @description(\"Column headers as they visually appear in the table, left to right. One entry per data column.\")\n  column_count int @description(\"Total number of data columns\")\n  header_levels int @description(\"Number of header rows (1 for single-row, >1 for stacked/multiline or hierarchical)\")\n  has_spanning_headers bool @description(\"True if parent cells span multiple child columns (hierarchical). False otherwise.\")\n  notes string? @description(\"Observations about the header structure: merged cells, stacked labels, spanning parent cells, visual groupings, etc.\")\n}\n\n// ─── Functions ───────────────────────────────────────────────────────────────\n\nfunction AnalyzeAndParseTable(compressed_text: string) -> ParsedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a table-structure analyst. Given compressed text extracted from a PDF,\n    identify the table structure and parse all data rows.\n\n    === DATA-FIRST APPROACH ===\n\n    The data rows are the ground truth for column structure. Analyze them FIRST:\n\n    STEP 1: COUNT DATA COLUMNS\n    - Find the pipe table (rows with | delimiters)\n    - Count cells in the FIRST data row (after |---|---| separator)\n    - This is your AUTHORITATIVE column count\n\n    STEP 2: IDENTIFY DATA TYPES PER COLUMN\n    - Look at values in each column position across multiple data rows\n    - Identify: dates, times, numbers, text, codes, status words, etc.\n    - Note any concatenated values (e.g. \"1500 Category A\" = number + text = 2 columns)\n\n    STEP 3: MAP HEADERS TO DATA COLUMNS\n    - Look at the header lines ABOVE the pipe table\n    - For stacked/multiline headers, combine vertically aligned text:\n      \"Unique Slot\" / \"Reference\" / \"Number\" → \"Unique Slot Reference Number\"\n    - You MUST produce exactly as many header names as data columns\n\n    === TABLE TYPE CLASSIFICATION ===\n\n    Classify using the TableType enum definitions (provided in the output schema).\n    Quick decision tree:\n    - Header row has FEWER cells than data rows (horizontal spanning)? → HierarchicalHeader\n    - Column headers are repeated categories (dates, periods, attributes)? → PivotedTable\n    - Field names in left column, values across columns? → TransposedTable\n    - Otherwise → FlatHeader (including stacked/multiline headers with no spanning)\n\n    === PARSING RULES ===\n\n    1. headers.names MUST have exactly column_count entries (one per data column)\n    2. Each data_row MUST have exactly column_count cells\n    3. If a pipe cell contains concatenated values that span multiple columns,\n       SPLIT them to maintain consistent column count\n    4. Exclude aggregation rows (totals, subtotals) from data_rows\n    5. Keep cell values as strings exactly as they appear\n    6. Include ALL data rows even with empty cells, dashes, \"N/A\", or zeros\n\n    SECTION LABELS:\n    If the text has sections (e.g. data grouped by region, category, etc.),\n    record in notes: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n\n    Compressed text:\n    ---\n    {{ compressed_text }}\n    ---\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction InferTableSchemaFromImage(page_img: image, compressed_text: string) -> InferredTableSchema {\n  client CustomGPT4o\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a table structure analyst. You are given:\n    1. An image of a PDF page containing a table\n    2. Compressed text extracted from the same page (which may have parsing errors)\n\n    Your task: determine the COMPLETE table column structure. Use a DATA-FIRST\n    approach — the data rows are the ground truth for column count.\n\n    === STEP 1: ANALYZE DATA ROWS (Ground Truth) ===\n\n    Look at the DATA ROWS in the image (below the headers):\n    1. Pick a complete data row and count the distinct columns visually\n    2. Note column boundaries — where values end and new values begin\n    3. Identify the DATA TYPE in each column:\n       - Dates (DD/MM/YYYY, YYYY-MM-DD, etc.)\n       - Times (HH:MM, HH:MM:SS AM/PM)\n       - Numbers (quantities, IDs, codes)\n       - Text (names, descriptions, status words)\n       - Mixed (e.g. \"1500 Category A\" = number + text = likely 2 columns concatenated)\n\n    The number of distinct data columns is your AUTHORITATIVE column_count.\n\n    === STEP 2: VALIDATE WITH COMPRESSED TEXT ===\n\n    Count pipe-separated cells in the FIRST data row of the compressed text\n    (the row after |---|---|). Compare to your visual count:\n    - If text has FEWER cells → some values are concatenated in text\n    - If text has MORE cells → you may have missed narrow columns visually\n    - Note any concatenations (e.g. \"7:00 PM Company X\" = time + text = 2 columns)\n\n    === STEP 3: MAP HEADERS TO DATA COLUMNS ===\n\n    Now look at the header area and assign a name to EACH data column:\n    1. For stacked/multiline headers, combine vertically aligned text into one name\n       (e.g. \"Unique Slot\" / \"Reference\" / \"Number\" → \"Unique Slot Reference Number\")\n    2. For hierarchical headers with horizontal spanning, use compound paths\n       (e.g. \"Date\" spanning \"Nominated\" and \"Accepted\" → \"Date / Nominated\", \"Date / Accepted\")\n    3. If a header is unclear, infer from the data type (e.g. column with dates\n       and no clear header might be \"Date\" or \"ETA\")\n\n    CRITICAL: column_names array length MUST equal column_count from Step 1.\n\n    === STEP 4: DETERMINE HEADER STRUCTURE ===\n\n    Set has_spanning_headers based on visual header structure:\n    - FALSE (stacked/multiline): Column dividers run continuously top-to-bottom,\n      each column independent even if header text spans multiple rows vertically\n    - TRUE (hierarchical): Parent cells span horizontally across multiple child\n      columns, column dividers only appear in lower rows under the spanning cell\n\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }}\n    {{ page_img }}\n\n    Compressed text (for reference — may contain errors):\n    ---\n    {{ compressed_text }}\n    ---\n  \"#\n}\n\nfunction AnalyzeAndParseTableGuided(compressed_text: string, visual_schema: InferredTableSchema) -> ParsedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a table-structure analyst. Given compressed text extracted from a PDF\n    AND a visual schema describing the correct column structure (inferred from the\n    page image), parse the table data rows.\n\n    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n    and header names):\n    {{ visual_schema }}\n\n    The compressed text below may have parsing artifacts: column headers may be\n    garbled or values from adjacent columns may be concatenated into a single\n    cell. Use the visual schema's column_names and column_count to:\n    - Correctly identify which part of the text corresponds to which column\n    - Split concatenated values when the column count in a row doesn't match\n      the expected count (e.g. \"1500 Category A\" should become two cells: \"1500\"\n      and \"Category A\" if they map to separate columns)\n    - Use the visual schema's column names as the authoritative header names\n\n    Steps:\n    1. Use the visual schema to set the correct headers (column_names →\n       headers.names, header_levels → headers.levels).\n    2. Determine the table type based on has_spanning_headers:\n       - If has_spanning_headers is true → HierarchicalHeader (parent cells span\n         multiple child columns in a tree structure)\n       - If has_spanning_headers is false → FlatHeader (even with stacked/multiline\n         headers, each column is independent)\n    3. Identify any aggregation rows/columns and separate them.\n    4. Parse every data row into an array of string cell values — the array\n       length MUST equal visual_schema.column_count for each row.\n    5. If the text contains multiple table sections separated by labels or headers\n       (e.g. data grouped by category, region, time period, or any other dimension),\n       record each section label and which data rows belong to it in the notes field.\n       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n\n    Important:\n    - Keep cell values as strings exactly as they appear (do not reformat).\n    - Exclude header rows and aggregation rows from data_rows.\n    - Include ALL data rows regardless of cell content.\n    - If a row has fewer tokens than expected columns, split concatenated\n      values to reach the correct column count.\n    - If the table has merged cells or spans, repeat the value for each\n      spanned column.\n\n    Compressed text:\n    ---\n    {{ compressed_text }}\n    ---\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction MapToCanonicalSchema(parsed_table: ParsedTable, schema: CanonicalSchema, model_name: string) -> MappedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a data mapper. Given a parsed table and a canonical schema, map data rows\n    to the canonical schema columns using a strategy appropriate for the table type.\n\n    TABLE TYPE: {{ parsed_table.table_type }}\n\n    Mapping strategy by table type:\n    - FlatHeader: Map each data row directly to one output record.\n    - HierarchicalHeader: Check if canonical column aliases match PARTS of compound\n      column names (e.g. \"Group A / Metric 1\"):\n      - If canonical columns have aliases that match the parent/child parts of compound headers\n        (e.g., \"group\" aliases [\"Group A\", \"Group B\"] and \"metric\" aliases [\"Metric 1\", \"Metric 2\"]\n        match parts of \"Group A / Metric 1\", \"Group B / Metric 2\"), you must UNPIVOT:\n        Each data row produces MULTIPLE records (one per value column).\n        The parent and child parts of each compound header become field values.\n        CRITICAL: Only unpivot columns where ALL header parts match dimension aliases.\n        If a column's header part does NOT match any alias, SKIP that column entirely —\n        do not create a record for it. This includes:\n        - Derived/calculated columns (e.g., \"% change\" when metric aliases are [\"Revenue\", \"Costs\"])\n        - Aggregation columns (e.g., \"Total\" or \"TOTAL\" when category aliases are [\"Type A\", \"Type B\"])\n        Common aggregation labels to skip: \"Total\", \"TOTAL\", \"Subtotal\", \"All\", \"Grand Total\", \"Sum\".\n        Unless an aggregation label is explicitly listed in aliases, skip columns containing it.\n        ALSO: Skip rows where the row label (first column value) represents an aggregation,\n        using the same aggregation labels above.\n        Example: row \"Region A | 100 | 200 | +50% | 150 | 180 | -10%\" with columns\n        \"Label | Q1 / Revenue | Q1 / Costs | Q1 / % change | Q2 / Revenue | Q2 / Costs | Q2 / % change\"\n        and schema {label, category (aliases: Q1, Q2), metric (aliases: Revenue, Costs), value}\n        becomes FOUR records (% change columns skipped because \"% change\" is not in metric aliases):\n        - {label: \"Region A\", category: \"Q1\", metric: \"Revenue\", value: 100}\n        - {label: \"Region A\", category: \"Q1\", metric: \"Costs\", value: 200}\n        - {label: \"Region A\", category: \"Q2\", metric: \"Revenue\", value: 150}\n        - {label: \"Region A\", category: \"Q2\", metric: \"Costs\", value: 180}\n        IMPORTANT: Each record's dimension values must come from THAT SPECIFIC column's header.\n        Do NOT use the same value for all records — \"Q1\" columns produce \"Q1\", \"Q2\" columns produce \"Q2\".\n      - If no canonical aliases match parts of compound headers, match the full compound name\n        against aliases and produce one record per data row.\n    - PivotedTable: UNPIVOT — for each data row, produce ONE OUTPUT RECORD PER VALUE COLUMN.\n      The column header becomes a field value (e.g. column \"Period A\" → the \"period\" field gets value \"Period A\").\n      Example: a row \"Item X | 100 | 200\" with columns \"Category | Period A | Period B\"\n      becomes TWO records: {category: \"Item X\", period: \"Period A\", value: 100} and\n      {category: \"Item X\", period: \"Period B\", value: 200}.\n    - TransposedTable: TRANSPOSE before mapping:\n      1. The first column contains field names — these become your \"headers\" for alias matching\n      2. Each subsequent column is ONE COMPLETE RECORD\n      3. Match each row's first-column label against canonical column aliases\n      4. Example: If rows are \"Name | Alice | Bob\" and \"Status | Active | Inactive\",\n         produce TWO records: {name: \"Alice\", status: \"Active\"} and {name: \"Bob\", status: \"Inactive\"}\n      5. EVERY row label must be checked against ALL canonical column aliases\n    - Unknown: Use best judgment based on the data structure.\n\n    General mapping rules:\n    1. Match source columns to canonical columns using name, aliases, and description.\n       - If aliases are provided, match against them literally.\n       - If aliases are EMPTY, use the description to infer what values should match:\n         * For date/time fields: match any value that looks like a year (4 digits), month,\n           date, or time period (e.g., \"YYYY\", \"Mon\", \"Q1\", \"Month Year\")\n         * For category fields: match based on semantic similarity to the description\n       This allows schemas to be robust without hardcoding specific values.\n    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n    4. FORMAT OUTPUT VALUES: If a column has a `format` field, apply it to the output:\n       - Dates: Use the specified pattern (YYYY-MM-DD, YYYY-MM, HH:mm, etc.)\n       - Numbers: Apply formatting (#,### for thousands, #.## for decimals, +# for sign, #% for percentage)\n       - Strings: Apply case transformation (uppercase, lowercase, titlecase, camelCase, PascalCase, snake_case, kebab-case, trim)\n       If no format is specified, use sensible defaults (ISO 8601 for dates, plain numbers, original case for strings).\n    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n    6. List any source columns that could not be mapped in unmapped_columns.\n    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n       (especially when its aliases list is empty), look for its value in the\n       surrounding context:\n       - Section headers or group labels that appear above or between data groups\n       - Document title, subtitle, or metadata lines\n       - Repeated contextual values that apply to all rows in a group\n       When a value is inferred from context, apply it to ALL rows in that section.\n       The parsed_table's notes field may contain section boundary information.\n    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n       metadata explaining:\n       - Where the value came from (source)\n       - Why this mapping was chosen (rationale)\n       - How confident you are (see Confidence enum criteria)\n    9. Set metadata.model to \"{{ model_name }}\" (it will be provided).\n    10. If the text had section labels, list them in metadata.sections_detected and set\n        metadata.section_role to:\n        - \"context\" if there is only ONE section label that applies to all rows\n        - \"grouping\" if there are MULTIPLE section labels that partition rows into groups\n    11. Populate metadata.table_type_inference with:\n        - table_type: {{ parsed_table.table_type }} (use this exact value, do not re-classify)\n        - mapping_strategy_used: Describe which strategy you applied (e.g., \"1:1 row mapping for FlatHeader\", \"unpivot for PivotedTable\")\n    12. EXTRACT ALL DATA — DO NOT FILTER: Schema descriptions are metadata about what the field\n        represents, NOT filtering instructions. Extract ALL data rows and ALL relevant columns\n        from the source table. If a table contains data for multiple time periods, extract\n        records for ALL periods. Never skip data because a description mentions \"latest\",\n        \"current\", \"recent\", etc. — the user will filter downstream if needed.\n\n    Parsed table:\n    {{ parsed_table }}\n\n    Canonical schema:\n    {{ schema }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction InterpretTable(compressed_text: string, schema: CanonicalSchema, model_name: string) -> MappedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a table interpreter. Given compressed text from a PDF and a canonical schema,\n    extract and map tabular data in a single pass.\n\n    DETECTING HEADER STRUCTURE:\n\n    KEY TEST: Does a header row have FEWER cells than data rows because parent\n    cells span horizontally across multiple children?\n    - YES → HierarchicalHeader (use compound 'Parent / Child' names)\n    - NO → FlatHeader (even if header text is stacked across multiple rows —\n      combine stacked text into single column names)\n\n    See the TableType enum definitions in the output schema for full criteria.\n\n    Steps:\n    1. Identify the table structure using the header structure tests above and apply the\n       appropriate mapping strategy:\n       - FlatHeader: Combine stacked/multiline header text into single column names.\n         Map each row to one record.\n       - HierarchicalHeader: Column names are compound 'Parent / Child' paths.\n         Check if canonical column aliases match PARTS of compound headers. If so, UNPIVOT:\n         each data row produces multiple records (one per value column), with parent/child parts\n         becoming field values. CRITICAL: Only unpivot columns where ALL header parts match dimension\n         aliases. Skip columns where any header part does NOT match aliases — this includes derived\n         columns (e.g., \"% change\") AND aggregation columns (e.g., \"Total\", \"TOTAL\", \"Subtotal\").\n         Also skip rows where the row label is an aggregation. Unless explicitly in aliases, skip it.\n         If no aliases match parts, map each row to one record.\n       - PivotedTable: UNPIVOT — for each data row, produce ONE RECORD PER VALUE COLUMN. The column header becomes\n         a field value. Example: \"Item X | 100 | 200\" with columns \"Category | Period A | Period B\"\n         becomes TWO records: {category: \"Item X\", period: \"Period A\", value: 100} and\n         {category: \"Item X\", period: \"Period B\", value: 200}.\n       - TransposedTable: TRANSPOSE — each subsequent column (after the label column) is\n         ONE COMPLETE RECORD, each row provides one field.\n         (1) First column labels become \"headers\" for alias matching\n         (2) Match each row label against canonical column aliases\n         (3) Example: rows \"Name | Alice | Bob\" and \"Status | Active | Inactive\" →\n             TWO records: {name: \"Alice\", status: \"Active\"}, {name: \"Bob\", status: \"Inactive\"}\n    2. Extract all data rows (exclude headers and aggregation rows like totals).\n    3. Match source columns to canonical columns using names, aliases, and descriptions.\n       When aliases are EMPTY, use the description to infer matches — e.g., a date field\n       with empty aliases should match any year (4 digits), month name, or time period.\n       IMPORTANT: When unpivoting, each record's dimension value must come from THAT column's\n       header — e.g., \"Period A\" columns → \"Period A\", \"Period B\" columns → \"Period B\". Do NOT\n       use the same value for all records.\n    4. Coerce values to expected types and FORMAT OUTPUT VALUES per column's `format` field:\n       - Dates: Use specified pattern (YYYY-MM-DD, YYYY-MM, HH:mm, etc.)\n       - Numbers: Apply formatting (#,### for thousands, #.## for decimals, +# for sign, #% for percentage)\n       - Strings: Apply case transformation (uppercase, lowercase, titlecase, camelCase, PascalCase, snake_case, kebab-case, trim)\n       If no format specified, use defaults (ISO 8601 for dates, plain numbers, original case).\n    5. List any source columns that could not be mapped.\n    6. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n       (especially when its aliases list is empty), look for its value in the\n       surrounding context:\n       - Section headers or group labels that appear above or between data groups\n       - Document title, subtitle, or metadata lines\n       - Repeated contextual values that apply to all rows in a group\n       When a value is inferred from context, apply it to ALL rows in that section.\n    7. For EVERY canonical column in the schema, produce a FieldMapping in the\n       metadata explaining:\n       - Where the value came from (source)\n       - Why this mapping was chosen (rationale)\n       - How confident you are (see Confidence enum criteria)\n    8. Set metadata.model to \"{{ model_name }}\" (it will be provided).\n    9. If the text had section labels, list them in metadata.sections_detected and set\n       metadata.section_role to:\n       - \"context\" if there is only ONE section label that applies to all rows\n       - \"grouping\" if there are MULTIPLE section labels that partition rows into groups\n    10. Populate metadata.table_type_inference with:\n        - table_type: The table structure type you identified in step 1\n        - mapping_strategy_used: Describe which strategy you applied (e.g., \"1:1 row mapping for FlatHeader\", \"unpivot for PivotedTable\")\n    11. EXTRACT ALL DATA — DO NOT FILTER: Schema descriptions are metadata about what the field\n        represents, NOT filtering instructions. Extract ALL data rows and ALL relevant columns\n        from the source table. If a table contains data for multiple time periods, extract\n        records for ALL periods. Never skip data because a description mentions \"latest\",\n        \"current\", \"recent\", etc. — the user will filter downstream if needed.\n\n    Important:\n    - Keep values faithful to the source; only reformat for type coercion.\n    - If a canonical column has no match, omit it from the record.\n    - Note any ambiguities or issues in mapping_notes.\n\n    Compressed text:\n    ---\n    {{ compressed_text }}\n    ---\n\n    Canonical schema:\n    {{ schema }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// ─── Test cases ──────────────────────────────────────────────────────────────\n\ntest flat_shipping_stem {\n  functions [AnalyzeAndParseTable]\n  args {\n    compressed_text #\"\n      | Port | Vessel | Commodity | Quantity (MT) | ETA | Status |\n      |------|--------|-----------|---------------|-----|--------|\n      | Portland | MV Ocean Star | Wheat | 52,000 | 2025-10-15 | Loading |\n      | Geelong | MV Pacific Tide | Barley | 38,500 | 2025-10-18 | Scheduled |\n      | Kwinana | MV Iron Wind | Canola | 41,200 | 2025-10-20 | Scheduled |\n      | Total | | | 131,700 | | |\n    \"#\n  }\n}\n\ntest hierarchical_header {\n  functions [AnalyzeAndParseTable]\n  args {\n    compressed_text #\"\n      | | Q1 2025 | Q1 2025 | Q2 2025 | Q2 2025 |\n      | Region | Revenue | Costs | Revenue | Costs |\n      |--------|---------|-------|---------|-------|\n      | North | 1,200 | 800 | 1,350 | 850 |\n      | South | 980 | 650 | 1,100 | 700 |\n      | East | 1,500 | 950 | 1,600 | 1,000 |\n    \"#\n  }\n}\n\ntest pivoted_with_totals {\n  functions [InterpretTable]\n  args {\n    compressed_text #\"\n      | Commodity | Oct 2025 | Nov 2025 | Dec 2025 | Total |\n      |-----------|----------|----------|----------|-------|\n      | Wheat | 52,000 | 48,000 | 55,000 | 155,000 |\n      | Barley | 38,500 | 42,000 | 39,500 | 120,000 |\n      | Canola | 41,200 | 37,800 | 43,000 | 122,000 |\n      | Grand Total | 131,700 | 127,800 | 137,500 | 397,000 |\n    \"#\n    schema {\n      description \"Monthly commodity shipment volumes\"\n      columns [\n        {\n          name \"commodity\"\n          type \"string\"\n          description \"Type of commodity\"\n          aliases [\"Commodity\", \"Product\"]\n        },\n        {\n          name \"month\"\n          type \"string\"\n          description \"Month and year\"\n          aliases [\"Period\", \"Month\"]\n        },\n        {\n          name \"volume_mt\"\n          type \"int\"\n          description \"Volume in metric tonnes\"\n          aliases [\"Quantity\", \"Volume\", \"MT\"]\n        }\n      ]\n    }\n    model_name \"openai/gpt-4o\"\n  }\n}\n\ntest sectioned_table_context_inference {\n  functions [InterpretTable]\n  args {\n    compressed_text #\"\n      ## WAREHOUSE A\n\n      | Item | Qty | Unit Price |\n      |------|-----|------------|\n      | Widget Alpha | 150 | 12.50 |\n      | Widget Beta  | 300 | 8.75  |\n\n      ## WAREHOUSE B\n\n      | Item | Qty | Unit Price |\n      |------|-----|------------|\n      | Widget Alpha | 80  | 12.50 |\n      | Gadget Gamma | 200 | 22.00 |\n    \"#\n    schema {\n      description \"Inventory records by warehouse\"\n      columns [\n        {\n          name \"warehouse\"\n          type \"string\"\n          description \"Warehouse or location where the inventory is stored — may appear as a section header rather than a table column\"\n          aliases []\n        },\n        {\n          name \"item_name\"\n          type \"string\"\n          description \"Name of the inventory item\"\n          aliases [\"Item\", \"Product\", \"SKU\"]\n        },\n        {\n          name \"quantity\"\n          type \"int\"\n          description \"Number of units in stock\"\n          aliases [\"Qty\", \"Quantity\", \"Count\"]\n        },\n        {\n          name \"unit_price\"\n          type \"float\"\n          description \"Price per unit\"\n          aliases [\"Unit Price\", \"Price\"]\n        }\n      ]\n    }\n    model_name \"openai/gpt-4o\"\n  }\n}\n\n// Test: HierarchicalHeader with unpivoting to normalized schema\n// This is a common pattern: compound column headers (Category / Period / Metric)\n// that need to be unpivoted into a normalized schema with separate columns for\n// the category, period, and value.\n// IMPORTANT: The \"% change\" columns should be SKIPPED because \"% change\" does not\n// match any alias for the \"period\" dimension (which only has [\"Period 1\", \"Period 2\"]).\n// Expected output: 8 records (2 rows × 2 categories × 2 periods), NOT 12 records.\ntest hierarchical_header_unpivot {\n  functions [MapToCanonicalSchema]\n  args {\n    parsed_table {\n      table_type HierarchicalHeader\n      headers {\n        levels 2\n        names [[\n          \"Label\",\n          \"Category A / Period 1\",\n          \"Category A / Period 2\",\n          \"Category A / % change\",\n          \"Category B / Period 1\",\n          \"Category B / Period 2\",\n          \"Category B / % change\"\n        ]]\n      }\n      aggregations null\n      data_rows [\n        [\"Item X\", \"25,000\", \"22,000\", \"+13.6\", \"45,000\", \"52,000\", \"-13.5\"],\n        [\"Item Y\", \"48,000\", \"41,000\", \"+17.1\", \"62,000\", \"71,000\", \"-12.7\"]\n      ]\n      notes \"Sections: GROUP 1 (rows 0-1)\"\n    }\n    schema {\n      description \"Normalized data with category and period dimensions\"\n      columns [\n        {\n          name \"label\"\n          type \"string\"\n          description \"Row label or identifier\"\n          aliases [\"Label\", \"Name\"]\n        },\n        {\n          name \"category\"\n          type \"string\"\n          description \"Category type (extracted from compound column header)\"\n          aliases [\"Category A\", \"Category B\", \"Category C\"]\n        },\n        {\n          name \"period\"\n          type \"string\"\n          description \"Time period (extracted from compound column header)\"\n          aliases [\"Period 1\", \"Period 2\"]\n        },\n        {\n          name \"value\"\n          type \"int\"\n          description \"Numeric value\"\n          aliases []\n        }\n      ]\n    }\n    model_name \"openai/gpt-4o\"\n  }\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string @description(\"Full name of the person\")\n  email string @description(\"Email address\")\n  experience string[] @description(\"List of work experience entries (e.g. role and company)\")\n  skills string[] @description(\"List of technical or professional skills\")\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like \"client CustomGPT5\" or \"client CustomSonnet4\"\n  client \"openai-responses/gpt-5-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
    "types.baml": "// Formal type system for PDF table structure classification.\n// Shared vocabulary for both compress and interpret pipelines.\n// All descriptions are domain-agnostic — abstract structural terms only.\n\n// ─── TableLayout ─────────────────────────────────────────────────────────────\n// Geometry of records vs fields. Orthogonal to header structure.\n\nenum TableLayout {\n  Standard\n    @description(#\"\n      Each row is one record, each column is one field. The most common layout.\n      Records flow top-to-bottom. One-to-one row mapping.\n      KEY SIGNS: Uniform cell count across data rows. First column values are\n      distinct identifiers (names, codes, dates). Headers sit above data.\n    \"#)\n  Transposed\n    @description(#\"\n      Field names run down the left column, field values run across columns.\n      Each value column is one complete record. Requires transposition.\n      KEY SIGNS: Left column reads like form labels (Label A, Label B, Label C).\n      Rows have mixed types. Multiple value columns hold parallel data for\n      different entities.\n    \"#)\n  CrossTab\n    @description(#\"\n      Cross-tabulation: row labels are one dimension, column headers are\n      another dimension, cells contain measure values. Requires unpivoting —\n      each cell becomes its own record with row label + column label + value.\n      KEY SIGNS: Column headers are dates/periods/repeated attributes. First\n      column has category labels. Cells are numeric/percentage values.\n    \"#)\n}\n\n// ─── HeaderStructure ─────────────────────────────────────────────────────────\n// Vertical organization of column labels.\n// Critical distinction: same cell count = Stacked, fewer cells = Hierarchical.\n\nenum HeaderStructure {\n  SingleRow\n    @description(#\"\n      One row of complete column labels. Each cell is a full, readable name.\n      KEY SIGNS: Header row cell count equals data row cell count. No\n      vertically split words. No spanning parents above.\n    \"#)\n  Stacked\n    @description(#\"\n      Labels split across 2+ rows vertically. Each column is independent —\n      no horizontal spanning. Fragments must be concatenated top-to-bottom.\n      Example: 'Field' (row 1) + 'Name' (row 2) + 'Here' (row 3)\n      at the same column position → 'Field Name Here'.\n      KEY SIGNS: Multiple header rows with the SAME cell count as data rows.\n      Individual cells contain word fragments. Vertical concatenation produces\n      sensible names. Typically 2-9 header rows.\n      CRITICAL: Same cell count across header rows = Stacked, NOT Hierarchical.\n    \"#)\n  Hierarchical\n    @description(#\"\n      Tree-structured headers where parent labels span horizontally across\n      multiple child columns. Column names become compound paths: 'Parent / Child'.\n      Example: 'Category A' spans 'Period 1' and 'Period 2'.\n      KEY SIGNS: A header row has FEWER cells than the row below it. Parent\n      cells centered above children. Compound path names needed.\n      CRITICAL: FEWER cells in upper rows than lower rows = Hierarchical.\n    \"#)\n}\n\n// ─── HeaderOrientation ───────────────────────────────────────────────────────\n// Reading direction for headers.\n\nenum HeaderOrientation {\n  Top\n    @description(\"Headers above data. Records read top-to-bottom. Default for Standard and CrossTab layouts.\")\n  Left\n    @description(\"Headers in leftmost column. Records read left-to-right. Co-occurs with Transposed layout. Left column contains field-name labels.\")\n}\n\n// ─── PageSectionType ─────────────────────────────────────────────────────────\n// What spatial text reveals about a region on the page.\n\nenum PageSectionType {\n  TableHeader\n    @description(#\"\n      Column labels vertically aligned with data columns below. Defines the\n      schema of the table that follows. May be SingleRow, Stacked, or\n      Hierarchical. Contains label-like text: short words, field names, units.\n      KEY SIGNS: Horizontally spaced labels aligned with data columns below.\n      Precedes a DataGrid section. No numeric data values.\n    \"#)\n  DataGrid\n    @description(#\"\n      Dense rectangular grid of data values with consistent column positions\n      across rows. The body of a table.\n      KEY SIGNS: Uniform cell count. Consistent column alignment within 3-5\n      char tolerance. Data-value content (numbers, dates, text, codes).\n    \"#)\n  SectionHeading\n    @description(#\"\n      Standalone text naming a group or section. NOT part of a table — labels\n      the table block that follows. In multi-table pages, separates blocks\n      and provides context (group names, category names).\n      KEY SIGNS: Short isolated text, often uppercase. Not aligned with table\n      columns. Precedes a table block.\n    \"#)\n  Metadata\n    @description(#\"\n      Document-level information: titles, dates, key-value pairs. Found at\n      page top/bottom, outside the main table area.\n      KEY SIGNS: 'Label: Value' format. Page header/footer position.\n    \"#)\n  Prose\n    @description(#\"\n      Flowing paragraph text — sentences, not structured data. Should NOT be\n      parsed as table data.\n      KEY SIGNS: Full sentences with grammar and punctuation. No column\n      alignment. Text wraps at page margin. Single span per row.\n    \"#)\n  AggregationRow\n    @description(#\"\n      Summary row with computed values (totals, subtotals). Same column\n      alignment as table data but contains aggregate values, not records.\n      Should be excluded from data extraction.\n      KEY SIGNS: Contains 'Total', 'Subtotal', or similar label. At end of\n      table block or section. Values sum the column above.\n    \"#)\n  Footnote\n    @description(#\"\n      Explanatory text, disclaimers, source attributions below main content.\n      KEY SIGNS: Bottom of page. Reference markers. Qualifying language.\n      Full-width text below tables.\n    \"#)\n}\n\n// ─── MultiRowPattern ─────────────────────────────────────────────────────────\n// Whether a single record spans multiple rows.\n\nenum MultiRowPattern {\n  SingleRow\n    @description(\"Each row is a complete record. No merging needed. KEY SIGNS: Uniform rows, no alternating row types.\")\n  RepeatingGroup\n    @description(#\"\n      A single record spans 2-4 consecutive rows following a repeating pattern.\n      Example: type-A values on row 1, type-B values on row 2, type-C values\n      on row 3 (period=3). Sub-rows at the same column position must be merged.\n      KEY SIGNS: Repeating span-count sequence. Alternating row types with\n      different value kinds per row. At least 2 complete cycles.\n    \"#)\n}\n\n// ─── TableStructure ──────────────────────────────────────────────────────────\n// Bundled classification output for a single table.\n\nclass TableStructure {\n  layout TableLayout\n    @description(\"Geometric arrangement of records and fields.\")\n  header_structure HeaderStructure\n    @description(\"How column labels are organized vertically.\")\n  header_orientation HeaderOrientation\n    @description(\"Whether labels are above (Top) or left of (Left) data.\")\n  header_row_count int\n    @description(\"Number of rows occupied by headers. Data begins after this count.\")\n  multi_row_pattern MultiRowPattern\n    @description(\"Whether records span multiple rows.\")\n  multi_row_period int?\n    @description(\"Rows per record when multi_row_pattern is RepeatingGroup. Null otherwise.\")\n  data_column_count int\n    @description(\"Number of data columns in the table body.\")\n  column_names string[]\n    @description(\"Resolved column names, one per data column. For Stacked headers, these are the vertically concatenated names. For Hierarchical, these are compound 'Parent / Child' paths.\")\n  notes string?\n    @description(\"Observations about structure: ambiguities, confidence, unusual patterns.\")\n}\n\n// ─── PageSection ─────────────────────────────────────────────────────────────\n// Section-level characterization of a page region.\n\nclass PageSection {\n  type PageSectionType\n    @description(\"What kind of content this section contains.\")\n  label string?\n    @description(\"Text label for this section (e.g. heading text, group name). Null for unlabeled sections.\")\n  row_range string?\n    @description(\"Row range in the spatial grid, e.g. '0-3' or '4-35'.\")\n}\n",
}

def get_baml_files():
    return _file_map