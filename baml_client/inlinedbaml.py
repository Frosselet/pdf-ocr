# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\n// client<llm> CustomGemini {\n//   provider google-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     api_key env.GOOGLE_API_KEY\n//   }\n// }\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"go\", \"rust\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.218.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "interpret.baml": "// Table interpretation: extract structured tabular data from compressed PDF text\n// and map it to a user-defined canonical schema.\n\n// ─── Enums ───────────────────────────────────────────────────────────────────\n\nenum TableType {\n  FlatHeader @description(\"Independent columns with no spanning parent cells. Header text may span multiple rows (stacked/multiline labels) but each column stands alone — combine stacked text into one name per column. 1:1 row-to-record mapping.\")\n  HierarchicalHeader @description(\"Tree-structured headers where parent cells span multiple child columns (e.g. 'Q1 2025' spanning 'Revenue' and 'Costs'). Column names are compound paths (e.g. 'Q1 2025 / Revenue'). 1:1 row-to-record mapping. Note: multiline headers with no spanning are FlatHeader, not this.\")\n  PivotedTable @description(\"Categories as rows, time periods or attributes as columns — requires unpivoting: each source row produces multiple output records, one per value column\")\n  TransposedTable @description(\"Fields as rows, records as columns — requires transposition: each column becomes a record, each row becomes a field\")\n  Unknown @description(\"Ambiguous structure — use best judgment based on content\")\n}\n\nenum AggregationType {\n  Total\n  Sum\n  Min\n  Max\n  Average\n  Count\n  NoAggregation @alias(\"None\")\n}\n\nenum Confidence {\n  High   @description(\"Direct column match by name or alias\")\n  Medium @description(\"Inferred from context with reasonable certainty (section header, title, etc.)\")\n  Low    @description(\"Best guess — ambiguous source or weak contextual signal\")\n}\n\n// ─── Intermediate pipeline types ─────────────────────────────────────────────\n\nclass HeaderInfo {\n  levels int @description(\"Number of header rows. For FlatHeader with stacked/multiline labels, this counts the text rows but names[][] should contain the combined column names. For HierarchicalHeader, this counts the hierarchy depth.\")\n  names string[][] @description(\"Header names per level, outer = level, inner = columns. For FlatHeader (even with multiline labels), use a single level with combined names. For HierarchicalHeader, each level represents a tier in the tree.\")\n}\n\nclass AggregationInfo {\n  type AggregationType\n  axis string @description(\"'row' or 'column' — the axis along which aggregation runs\")\n  labels string[] @description(\"Labels identifying aggregation rows/columns, e.g. ['Total', 'Grand Total']\")\n}\n\nclass ParsedTable {\n  table_type TableType\n  headers HeaderInfo\n  aggregations AggregationInfo? @description(\"Present only if the table contains aggregation rows/columns\")\n  data_rows string[][] @description(\"All data rows (excluding headers and aggregation rows). Each inner array is one row of cell values as strings.\")\n  notes string? @description(\"Any caveats or observations about the table structure\")\n}\n\n// ─── Canonical schema + output types ─────────────────────────────────────────\n\nclass ColumnDef {\n  name string @description(\"Canonical column name\")\n  type string @description(\"Expected type: string, int, float, bool, date\")\n  description string @description(\"What this column represents\")\n  aliases string[] @description(\"Alternative names this column may appear as in source tables\")\n}\n\nclass CanonicalSchema {\n  columns ColumnDef[]\n  description string? @description(\"Optional description of what this schema represents\")\n}\n\nclass MappedRecord {\n  @@dynamic\n}\n\nclass FieldMapping {\n  column_name string  @description(\"Canonical column name from the schema\")\n  source string       @description(\"Where the value came from, e.g. 'column: Vessel Name', 'section header', 'document title', 'inferred from context'\")\n  rationale string    @description(\"Brief explanation of why this mapping was chosen\")\n  confidence Confidence\n}\n\nclass TableTypeInference {\n  table_type TableType          @description(\"The inferred table structure type\")\n  rationale string              @description(\"Brief explanation of why this table type was chosen, citing specific structural evidence\")\n  confidence Confidence         @description(\"How confident the inference is based on structural clarity\")\n}\n\nclass InterpretationMetadata {\n  model string                  @description(\"Model that produced this result, e.g. 'openai/gpt-4o'\")\n  table_type_inference TableTypeInference @description(\"The inferred table type with rationale explaining the classification\")\n  field_mappings FieldMapping[] @description(\"One entry per canonical column, explaining how it was resolved\")\n  sections_detected string[]?   @description(\"Section/group labels found in the text, if any (e.g. ['GERALDTON', 'KWINANA'])\")\n  section_role string?          @description(\"'context' if a single section label applies to all rows, 'grouping' if multiple labels partition rows into groups\")\n}\n\nclass MappedTable {\n  records MappedRecord[] @description(\"Mapped data records conforming to the canonical schema\")\n  unmapped_columns string[] @description(\"Source columns that could not be mapped to any canonical column\")\n  mapping_notes string? @description(\"Notes about the mapping process, e.g. ambiguous matches or type coercion issues\")\n  metadata InterpretationMetadata @description(\"Metadata about the interpretation: model used, per-field mapping rationale, detected sections\")\n}\n\n// ─── Vision-based schema inference ──────────────────────────────────────────\n\nclass InferredTableSchema {\n  column_names string[] @description(\"Column headers as they visually appear in the table, left to right. For stacked/multiline headers, combine the vertically stacked labels into a single name per column (e.g. 'Unique Slot Reference Number'). For hierarchical headers with spanning parents, use compound paths (e.g. 'Q1 2025 / Revenue').\")\n  column_count int @description(\"Total number of data columns\")\n  header_levels int @description(\"Number of header rows (1 for single-row, >1 for stacked/multiline or hierarchical)\")\n  has_spanning_headers bool @description(\"True if parent cells span multiple child columns (hierarchical). False if headers are just stacked text with no spanning (multiline flat).\")\n  notes string? @description(\"Observations about the header structure: merged cells, stacked labels, spanning parent cells, visual groupings, etc.\")\n}\n\n// ─── Functions ───────────────────────────────────────────────────────────────\n\nfunction AnalyzeAndParseTable(compressed_text: string) -> ParsedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a table-structure analyst. Given compressed text extracted from a PDF,\n    identify the table structure and parse all data rows.\n\n    DETECTING HEADER STRUCTURE:\n\n    Before classifying, examine the header rows carefully:\n\n    1. STACKED/MULTILINE (→ FlatHeader):\n       - Each column has text that wraps across multiple rows vertically\n       - BUT each column is independent — no cell spans multiple columns horizontally\n       - Example: \"Unique Slot\" / \"Reference\" / \"Number\" stacked vertically = one column\n         named \"Unique Slot Reference Number\"\n       - Key sign: The number of text fragments per row equals the number of columns\n\n    2. GROUPED/SPANNING (→ HierarchicalHeader):\n       - A parent header cell spans HORIZONTALLY across multiple child columns\n       - Children are sibling columns that share a common parent cell above them\n       - Example: \"Date\" spanning over \"Nominated\" and \"Accepted\" = compound names\n         \"Date / Nominated\" and \"Date / Accepted\"\n       - Key sign: A header row has FEWER cells than the data rows because parents span\n\n    KEY TEST: Do sibling columns share a common parent cell above them that spans\n    horizontally? If YES → HierarchicalHeader. If NO → FlatHeader (even with multiline text).\n\n    Steps:\n    1. Determine the table type using the header structure tests above:\n       - FlatHeader: Each column has its own independent header. This includes tables with\n         stacked/multiline headers where text is split across multiple rows but each column\n         stands alone (combine the stacked text into one name per column).\n       - HierarchicalHeader: Parent header cells SPAN multiple child columns in a tree\n         structure (e.g. \"Q1 2025\" spanning over \"Revenue\" and \"Costs\" columns beneath it).\n         The key distinction is HORIZONTAL SPANNING — siblings share a common parent cell.\n       - PivotedTable: Row labels are categories, column headers are time periods or\n         attributes — requires unpivoting.\n       - TransposedTable: Field names as rows, records as columns — requires transposition.\n       - Unknown: Ambiguous structure.\n    2. Extract headers — for hierarchical tables, capture each level separately. For flat\n       tables with stacked/multiline headers, combine the text into single column names.\n    3. Identify any aggregation rows/columns (totals, subtotals, averages, etc.) and separate them.\n    4. Parse every data row into an array of string cell values, preserving the original order.\n    5. If the text contains multiple table sections separated by labels or headers\n       (e.g. data grouped by category, region, time period, or any other dimension),\n       record each section label and which data rows belong to it in the notes field.\n       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n\n    Important:\n    - Keep cell values as strings exactly as they appear (do not reformat numbers or dates).\n    - Exclude header rows and aggregation rows from data_rows.\n    - Include ALL other rows, even if they have empty cells, dashes, \"N/A\", zero or\n      missing values, or unusual-looking content. If a row occupies a data position in\n      the table it is a data row — do not filter based on cell content.\n    - If the table has merged cells or spans, repeat the value for each spanned column.\n    - Multiline/stacked headers (where column names wrap across rows but each column is\n      independent) should be classified as FlatHeader, NOT HierarchicalHeader.\n\n    Compressed text:\n    ---\n    {{ compressed_text }}\n    ---\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction InferTableSchemaFromImage(page_img: image, compressed_text: string) -> InferredTableSchema {\n  client CustomGPT4o\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a table structure analyst. You are given:\n    1. An image of a PDF page containing a table\n    2. Compressed text extracted from the same page (which may have parsing errors)\n\n    Your task: determine the COMPLETE table column structure by combining\n    evidence from BOTH the image and the compressed text.\n\n    DETECTING HEADER STRUCTURE:\n\n    Before setting has_spanning_headers, examine the header area carefully:\n\n    1. STACKED/MULTILINE (→ has_spanning_headers=false):\n       - Each column has text that wraps across multiple rows vertically\n       - BUT each column is independent — no cell spans multiple columns horizontally\n       - Example: \"Unique Slot\" / \"Reference\" / \"Number\" stacked vertically = one column\n         named \"Unique Slot Reference Number\"\n       - Key visual sign: Column dividers run continuously from top to bottom of header\n\n    2. GROUPED/SPANNING (→ has_spanning_headers=true):\n       - A parent header cell spans HORIZONTALLY across multiple child columns\n       - Children are sibling columns that share a common parent cell above them\n       - Example: \"Date\" spanning over \"Nominated\" and \"Accepted\" = compound names\n         \"Date / Nominated\" and \"Date / Accepted\"\n       - Key visual sign: A cell in an upper row is wider than cells below it,\n         with column dividers only appearing in the lower rows\n\n    KEY TEST: Do sibling columns share a common parent cell above them that spans\n    horizontally? If YES → has_spanning_headers=true. If NO → false (even with multiline text).\n\n    CRITICAL: Dense tables with small fonts often have narrow columns that are\n    easy to miss visually. You MUST cross-validate your column list against the\n    data rows in the compressed text.\n\n    Steps:\n    1. Count the pipe-separated cells in the FIRST data row of the compressed\n       text (the row after the |---|---| separator). This gives you the MINIMUM\n       number of columns — some cells may be concatenated (two values joined\n       into one cell), so the actual column count may be HIGHER.\n    2. Find the table header area in the image. Read EVERY column header left\n       to right. Pay special attention to narrow single-word columns between\n       wider multi-word columns — these are commonly missed.\n       - For stacked/multiline headers (text split across rows but each column\n         independent), combine the vertically stacked labels into one name\n         (e.g. \"Unique Slot\" + \"Reference\" + \"Number\" → \"Unique Slot Reference Number\").\n       - For hierarchical headers (parent cells spanning horizontally across\n         multiple child columns), use compound paths (e.g. \"Q1 2025 / Revenue\").\n    3. Apply the header structure test above to set has_spanning_headers.\n    4. Cross-reference with the garbled header lines in the compressed text\n       (the lines above the pipe table). Header fragments like individual\n       words (e.g. \"ID\", \"STATUS\", \"CODE\") often correspond to real\n       columns that may appear narrow in the image.\n    5. Verify: your column_count MUST be >= the number of pipe-separated cells\n       in the data rows. If it is less, you have missed columns — re-examine\n       the image and text headers.\n    6. Note how many header rows exist and any structural observations,\n       including which data cells appear concatenated (e.g. \"42 Smith\"\n       containing values for two columns).\n\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }}\n    {{ page_img }}\n\n    Compressed text (for reference — may contain errors):\n    ---\n    {{ compressed_text }}\n    ---\n  \"#\n}\n\nfunction AnalyzeAndParseTableGuided(compressed_text: string, visual_schema: InferredTableSchema) -> ParsedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a table-structure analyst. Given compressed text extracted from a PDF\n    AND a visual schema describing the correct column structure (inferred from the\n    page image), parse the table data rows.\n\n    VISUAL SCHEMA (from image analysis — treat as ground truth for column count\n    and header names):\n    {{ visual_schema }}\n\n    The compressed text below may have parsing artifacts: column headers may be\n    garbled or values from adjacent columns may be concatenated into a single\n    cell. Use the visual schema's column_names and column_count to:\n    - Correctly identify which part of the text corresponds to which column\n    - Split concatenated values when the column count in a row doesn't match\n      the expected count (e.g. \"33020 WHEAT\" should become two cells: \"33020\"\n      and \"WHEAT\" if they map to separate columns)\n    - Use the visual schema's column names as the authoritative header names\n\n    Steps:\n    1. Use the visual schema to set the correct headers (column_names →\n       headers.names, header_levels → headers.levels).\n    2. Determine the table type based on has_spanning_headers:\n       - If has_spanning_headers is true → HierarchicalHeader (parent cells span\n         multiple child columns in a tree structure)\n       - If has_spanning_headers is false → FlatHeader (even with stacked/multiline\n         headers, each column is independent)\n    3. Identify any aggregation rows/columns and separate them.\n    4. Parse every data row into an array of string cell values — the array\n       length MUST equal visual_schema.column_count for each row.\n    5. If the text contains multiple table sections separated by labels or headers\n       (e.g. data grouped by category, region, time period, or any other dimension),\n       record each section label and which data rows belong to it in the notes field.\n       Format: \"Sections: <label1> (rows 0-N), <label2> (rows N+1-M), ...\"\n\n    Important:\n    - Keep cell values as strings exactly as they appear (do not reformat).\n    - Exclude header rows and aggregation rows from data_rows.\n    - Include ALL data rows regardless of cell content.\n    - If a row has fewer tokens than expected columns, split concatenated\n      values to reach the correct column count.\n    - If the table has merged cells or spans, repeat the value for each\n      spanned column.\n\n    Compressed text:\n    ---\n    {{ compressed_text }}\n    ---\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction MapToCanonicalSchema(parsed_table: ParsedTable, schema: CanonicalSchema, model_name: string) -> MappedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a data mapper. Given a parsed table and a canonical schema, map data rows\n    to the canonical schema columns using a strategy appropriate for the table type.\n\n    TABLE TYPE: {{ parsed_table.table_type }}\n\n    Mapping strategy by table type:\n    - FlatHeader: Map each data row directly to one output record. Columns align 1:1.\n    - HierarchicalHeader: Column names may be compound from merged headers (e.g. \"Q1 / Revenue\").\n      Match the full compound name against aliases. Each data row produces one record.\n    - PivotedTable: Categories are rows, time periods or attributes are columns. You must UNPIVOT:\n      for each data row, produce ONE OUTPUT RECORD PER VALUE COLUMN. The column header becomes\n      a field value (e.g. column \"Period A\" → the \"period\" field gets value \"Period A\").\n      Example: a row \"Item X | 100 | 200\" with columns \"Category | Period A | Period B\"\n      becomes TWO records: {category: \"Item X\", period: \"Period A\", value: 100} and\n      {category: \"Item X\", period: \"Period B\", value: 200}.\n    - TransposedTable: Fields are rows, records are columns. Transpose before mapping:\n      each column (after the first) is a separate record, each row label is a field name.\n    - Unknown: Use best judgment based on the data structure.\n\n    General mapping rules:\n    1. Match source columns to canonical columns using name, aliases, and description.\n    2. If a source column matches multiple canonical columns, pick the best match and note the ambiguity.\n    3. Coerce values to the expected type where possible (e.g. \"1,234\" -> 1234 for int columns).\n    4. For date columns, normalize to ISO 8601 format (YYYY-MM-DD) when the date is unambiguous.\n    5. If a canonical column has no matching source column, omit it from the record (it will be null).\n    6. List any source columns that could not be mapped in unmapped_columns.\n    7. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n       (especially when its aliases list is empty), look for its value in the\n       surrounding context:\n       - Section headers or group labels that appear above or between data groups\n       - Document title, subtitle, or metadata lines\n       - Repeated contextual values that apply to all rows in a group\n       When a value is inferred from context, apply it to ALL rows in that section.\n       The parsed_table's notes field may contain section boundary information.\n    8. For EVERY canonical column in the schema, produce a FieldMapping in the\n       metadata explaining:\n       - Where the value came from (source)\n       - Why this mapping was chosen (rationale)\n       - How confident you are (High = direct name/alias match,\n         Medium = inferred from context with reasonable certainty,\n         Low = best guess or ambiguous)\n    9. Set metadata.model to \"{{ model_name }}\" (it will be provided).\n    10. If the text had section labels, list them in metadata.sections_detected and set\n        metadata.section_role to:\n        - \"context\" if there is only ONE section label that applies to all rows\n        - \"grouping\" if there are MULTIPLE section labels that partition rows into groups\n    11. Populate metadata.table_type_inference with:\n        - table_type: Use the table type from parsed_table ({{ parsed_table.table_type }})\n        - rationale: Explain why this classification applies based on the table structure.\n          For FlatHeader vs HierarchicalHeader, explicitly state whether parent cells span\n          horizontally across multiple child columns or not.\n        - confidence: High if structure is unambiguous, Medium if some irregularities, Low if uncertain\n\n    Parsed table:\n    {{ parsed_table }}\n\n    Canonical schema:\n    {{ schema }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction InterpretTable(compressed_text: string, schema: CanonicalSchema, model_name: string) -> MappedTable {\n  client CustomGPT4o\n  prompt #\"\n    You are a table interpreter. Given compressed text from a PDF and a canonical schema,\n    extract and map tabular data in a single pass.\n\n    DETECTING HEADER STRUCTURE:\n\n    Before classifying, examine the header rows carefully:\n\n    1. STACKED/MULTILINE (→ FlatHeader):\n       - Each column has text that wraps across multiple rows vertically\n       - BUT each column is independent — no cell spans multiple columns horizontally\n       - Example: \"Unique Slot\" / \"Reference\" / \"Number\" stacked vertically = one column\n         named \"Unique Slot Reference Number\"\n       - Key sign: The number of text fragments per row equals the number of columns\n\n    2. GROUPED/SPANNING (→ HierarchicalHeader):\n       - A parent header cell spans HORIZONTALLY across multiple child columns\n       - Children are sibling columns that share a common parent cell above them\n       - Example: \"Date\" spanning over \"Nominated\" and \"Accepted\" = compound names\n         \"Date / Nominated\" and \"Date / Accepted\"\n       - Key sign: A header row has FEWER cells than the data rows because parents span\n\n    KEY TEST: Do sibling columns share a common parent cell above them that spans\n    horizontally? If YES → HierarchicalHeader. If NO → FlatHeader (even with multiline text).\n\n    Steps:\n    1. Identify the table structure using the header structure tests above and apply the\n       appropriate mapping strategy:\n       - FlatHeader: Each column has its own independent header. This includes tables with\n         stacked/multiline headers where text is split across multiple rows but each column\n         stands alone — combine the stacked text into one column name. Map each row to one record.\n       - HierarchicalHeader: Parent header cells SPAN HORIZONTALLY across multiple child columns\n         in a tree structure (e.g. \"Q1 2025\" spanning over \"Revenue\" and \"Costs\" columns beneath it).\n         Column names are compound paths (e.g. \"Q1 2025 / Revenue\"). Map each row to one record.\n         NOTE: Multiline/stacked headers with no horizontal spanning are FlatHeader, not this.\n       - PivotedTable: Categories as rows, time periods or attributes as columns. UNPIVOT:\n         for each data row, produce ONE RECORD PER VALUE COLUMN. The column header becomes\n         a field value. Example: \"Item X | 100 | 200\" with columns \"Category | Period A | Period B\"\n         becomes TWO records: {category: \"Item X\", period: \"Period A\", value: 100} and\n         {category: \"Item X\", period: \"Period B\", value: 200}.\n       - TransposedTable: Fields as rows, records as columns. Transpose: each column is a\n         record, each row label is a field name.\n    2. Extract all data rows (exclude headers and aggregation rows like totals).\n    3. Match source columns to canonical columns using names, aliases, and descriptions.\n    4. Coerce values to expected types (e.g. \"1,234\" -> 1234 for int, dates to ISO 8601).\n    5. List any source columns that could not be mapped.\n    6. CONTEXT INFERENCE: If a canonical column cannot be matched to any source column\n       (especially when its aliases list is empty), look for its value in the\n       surrounding context:\n       - Section headers or group labels that appear above or between data groups\n       - Document title, subtitle, or metadata lines\n       - Repeated contextual values that apply to all rows in a group\n       When a value is inferred from context, apply it to ALL rows in that section.\n    7. For EVERY canonical column in the schema, produce a FieldMapping in the\n       metadata explaining:\n       - Where the value came from (source)\n       - Why this mapping was chosen (rationale)\n       - How confident you are (High = direct name/alias match,\n         Medium = inferred from context with reasonable certainty,\n         Low = best guess or ambiguous)\n    8. Set metadata.model to \"{{ model_name }}\" (it will be provided).\n    9. If the text had section labels, list them in metadata.sections_detected and set\n       metadata.section_role to:\n       - \"context\" if there is only ONE section label that applies to all rows\n       - \"grouping\" if there are MULTIPLE section labels that partition rows into groups\n    10. Populate metadata.table_type_inference with:\n        - table_type: The table structure type you identified in step 1\n        - rationale: Explain why this classification applies, citing specific structural evidence.\n          For FlatHeader vs HierarchicalHeader, explicitly state whether parent cells span\n          horizontally across multiple child columns or not.\n        - confidence: High if structure is unambiguous, Medium if some irregularities, Low if uncertain\n\n    Important:\n    - Keep values faithful to the source; only reformat for type coercion.\n    - If a canonical column has no match, omit it from the record.\n    - Note any ambiguities or issues in mapping_notes.\n\n    Compressed text:\n    ---\n    {{ compressed_text }}\n    ---\n\n    Canonical schema:\n    {{ schema }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// ─── Test cases ──────────────────────────────────────────────────────────────\n\ntest flat_shipping_stem {\n  functions [AnalyzeAndParseTable]\n  args {\n    compressed_text #\"\n      | Port | Vessel | Commodity | Quantity (MT) | ETA | Status |\n      |------|--------|-----------|---------------|-----|--------|\n      | Portland | MV Ocean Star | Wheat | 52,000 | 2025-10-15 | Loading |\n      | Geelong | MV Pacific Tide | Barley | 38,500 | 2025-10-18 | Scheduled |\n      | Kwinana | MV Iron Wind | Canola | 41,200 | 2025-10-20 | Scheduled |\n      | Total | | | 131,700 | | |\n    \"#\n  }\n}\n\ntest hierarchical_header {\n  functions [AnalyzeAndParseTable]\n  args {\n    compressed_text #\"\n      | | Q1 2025 | Q1 2025 | Q2 2025 | Q2 2025 |\n      | Region | Revenue | Costs | Revenue | Costs |\n      |--------|---------|-------|---------|-------|\n      | North | 1,200 | 800 | 1,350 | 850 |\n      | South | 980 | 650 | 1,100 | 700 |\n      | East | 1,500 | 950 | 1,600 | 1,000 |\n    \"#\n  }\n}\n\ntest pivoted_with_totals {\n  functions [InterpretTable]\n  args {\n    compressed_text #\"\n      | Commodity | Oct 2025 | Nov 2025 | Dec 2025 | Total |\n      |-----------|----------|----------|----------|-------|\n      | Wheat | 52,000 | 48,000 | 55,000 | 155,000 |\n      | Barley | 38,500 | 42,000 | 39,500 | 120,000 |\n      | Canola | 41,200 | 37,800 | 43,000 | 122,000 |\n      | Grand Total | 131,700 | 127,800 | 137,500 | 397,000 |\n    \"#\n    schema {\n      description \"Monthly commodity shipment volumes\"\n      columns [\n        {\n          name \"commodity\"\n          type \"string\"\n          description \"Type of commodity\"\n          aliases [\"Commodity\", \"Product\"]\n        },\n        {\n          name \"month\"\n          type \"string\"\n          description \"Month and year\"\n          aliases [\"Period\", \"Month\"]\n        },\n        {\n          name \"volume_mt\"\n          type \"int\"\n          description \"Volume in metric tonnes\"\n          aliases [\"Quantity\", \"Volume\", \"MT\"]\n        }\n      ]\n    }\n    model_name \"openai/gpt-4o\"\n  }\n}\n\ntest sectioned_table_context_inference {\n  functions [InterpretTable]\n  args {\n    compressed_text #\"\n      ## WAREHOUSE A\n\n      | Item | Qty | Unit Price |\n      |------|-----|------------|\n      | Widget Alpha | 150 | 12.50 |\n      | Widget Beta  | 300 | 8.75  |\n\n      ## WAREHOUSE B\n\n      | Item | Qty | Unit Price |\n      |------|-----|------------|\n      | Widget Alpha | 80  | 12.50 |\n      | Gadget Gamma | 200 | 22.00 |\n    \"#\n    schema {\n      description \"Inventory records by warehouse\"\n      columns [\n        {\n          name \"warehouse\"\n          type \"string\"\n          description \"Warehouse or location where the inventory is stored — may appear as a section header rather than a table column\"\n          aliases []\n        },\n        {\n          name \"item_name\"\n          type \"string\"\n          description \"Name of the inventory item\"\n          aliases [\"Item\", \"Product\", \"SKU\"]\n        },\n        {\n          name \"quantity\"\n          type \"int\"\n          description \"Number of units in stock\"\n          aliases [\"Qty\", \"Quantity\", \"Count\"]\n        },\n        {\n          name \"unit_price\"\n          type \"float\"\n          description \"Price per unit\"\n          aliases [\"Unit Price\", \"Price\"]\n        }\n      ]\n    }\n    model_name \"openai/gpt-4o\"\n  }\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like \"client CustomGPT5\" or \"client CustomSonnet4\"\n  client \"openai-responses/gpt-5-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return _file_map